{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "#Distribution of the training data\n",
    "class DataDistribution:\n",
    "    def __init__(self,mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "    def samples(self, N):\n",
    "        return np.random.normal(self.mu, self.sigma,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data_distribution():\n",
    "    distribution = DataDistribution(4,0.5)\n",
    "    samples = distribution.samples(1000)\n",
    "    samples = pd.Series(samples)\n",
    "    samples.plot(kind=\"density\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2426c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots the density curve of the training data that the generator tries to estimate\n",
    "plot_data_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Noisy signal which serves as an input to the generator\n",
    "class GeneratorNoiseDistribution:\n",
    "    def __init__(self,limit):\n",
    "        self.limit = limit\n",
    "    def sample_noise(self,N):\n",
    "        return np.linspace(-self.limit, self.limit,N) + np.random.random() * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_noise_distribution():\n",
    "    distribution = GeneratorNoiseDistribution(8)\n",
    "    samples = distribution.sample_noise(1000)\n",
    "    samples = pd.Series(samples)\n",
    "    samples.plot(kind = \"density\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkZT+P40Y1g2bPxWuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5f7f3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_noise_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def new_weights(self, shape, name):\n",
    "        return tf.Variable(tf.truncated_normal(shape, stddev = 1.0), name = name)\n",
    "    def new_biases(self, length, name):\n",
    "        return tf.Variable(tf.constant(0.0, shape = [length]), name = name)\n",
    "    def linear(self, data_input,weights, biases):\n",
    "        return tf.matmul(data_input, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self,num_input_neurons,num_hidden_neurons,num_output_neurons):\n",
    "        self.num_input_neurons = num_input_neurons\n",
    "        self.num_hidden_neurons = num_hidden_neurons\n",
    "        self.num_output_neurons = num_output_neurons\n",
    "    def get_output(self,x):\n",
    "        w1 = self.new_weights([self.num_input_neurons,self.num_hidden_neurons],\"w1\")\n",
    "        b1 = self.new_biases(self.num_hidden_neurons,\"b1\")\n",
    "        w2 = self.new_weights([self.num_hidden_neurons, self.num_output_neurons],\"w2\")\n",
    "        b2 = self.new_biases(self.num_output_neurons,\"b2\")   \n",
    "        layer_1 = tf.nn.softplus(self.linear(x, w1, b1))\n",
    "        layer_2 = self.linear(layer_1,w2,b2)\n",
    "        return layer_2              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self,num_input_neurons,num_hidden_neurons,num_output_neurons):\n",
    "        self.num_input_neurons = num_input_neurons\n",
    "        self.num_hidden_neurons = num_hidden_neurons\n",
    "        self.num_output_neurons = num_output_neurons\n",
    "    def get_output(self,x):\n",
    "        w1 = self.new_weights([self.num_input_neurons,self.num_hidden_neurons],\"w1\")\n",
    "        b1 = self.new_biases(self.num_hidden_neurons,\"b1\")\n",
    "        w2 = self.new_weights([self.num_hidden_neurons, self.num_hidden_neurons],\"w2\")\n",
    "        b2 = self.new_biases(self.num_hidden_neurons,\"b2\")\n",
    "        w3 = self.new_weights([self.num_hidden_neurons, self.num_hidden_neurons],\"w3\")\n",
    "        b3 = self.new_biases(self.num_hidden_neurons,\"b3\")\n",
    "        w4 = self.new_weights([self.num_hidden_neurons, self.num_output_neurons],\"w4\")\n",
    "        b4 = self.new_biases(self.num_output_neurons,\"b4\")\n",
    "        layer_1 = tf.nn.relu(self.linear(x, w1, b1))\n",
    "        layer_2 = tf.nn.relu(self.linear(layer_1,w2,b2))\n",
    "        layer_3 = tf.nn.relu(self.linear(layer_2,w3,b3))\n",
    "        layer_4 = tf.sigmoid(self.linear(layer_3,w4,b4))\n",
    "        return layer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return tf.log(tf.maximum(x,1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(1,8,1)\n",
    "D = Discriminator(1,8,1)\n",
    "x_d = tf.placeholder(tf.float32, [None,1])\n",
    "x_g = tf.placeholder(tf.float32, [None,1])\n",
    "g_output = G.get_output(x_g)\n",
    "d1 = D.get_output(x_d)\n",
    "d2 = D.get_output(g_output)\n",
    "loss_d = tf.reduce_mean(-log(d1) - (1 - d2))\n",
    "loss_g = tf.reduce_mean(-log(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.05\n",
    "decay = 0.95\n",
    "num_decay_steps = 1000\n",
    "global_step = tf.Variable(0, trainable = True)\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate,global_step,num_decay_steps, decay, staircase = True)\n",
    "train_d = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_d)\n",
    "train_g = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data_sample(batch_size):\n",
    "    return DataDistribution(0,1).samples(batch_size).reshape((-1,1))\n",
    "def gen_noise_sample(batch_size):\n",
    "    return GeneratorNoiseDistribution(8).sample_noise(batch_size).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "batch_size = 8\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(epoch, batch_size):\n",
    "    for i in xrange(epoch):\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        d_input = gen_data_sample(batch_size)\n",
    "        z_noise = gen_noise_sample(batch_size)\n",
    "       \n",
    "        session.run(train_d, { x_d: d_input,\n",
    "                                   x_g: z_noise})\n",
    "        z_noise = gen_noise_sample(batch_size)\n",
    "        session.run(train_g, {x_g: z_noise})\n",
    "        loss_discriminator, loss_generator = session.run([loss_d, loss_g], {\n",
    "                                                x_d: d_input,\n",
    "                                                x_g: z_noise})\n",
    "        print \"Epoch: {},Discriminator Loss: {}, Generator Loss: {}\".format(i, loss_discriminator, loss_generator)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,Discriminator Loss: -0.103443942964, Generator Loss: 0.47323474288\n",
      "Epoch: 1,Discriminator Loss: 0.826062619686, Generator Loss: 0.00231499806978\n",
      "Epoch: 2,Discriminator Loss: 8.68288516998, Generator Loss: 0.318146795034\n",
      "Epoch: 3,Discriminator Loss: 0.160373985767, Generator Loss: 1.49011668782e-07\n",
      "Epoch: 4,Discriminator Loss: 0.100334972143, Generator Loss: 0.0581748597324\n",
      "Epoch: 5,Discriminator Loss: 0.0410004928708, Generator Loss: 0.0161449573934\n",
      "Epoch: 6,Discriminator Loss: 0.430436432362, Generator Loss: 0.0853071957827\n",
      "Epoch: 7,Discriminator Loss: 1.32215774059, Generator Loss: 1.39480680446e-05\n",
      "Epoch: 8,Discriminator Loss: 0.418759167194, Generator Loss: 0.23075646162\n",
      "Epoch: 9,Discriminator Loss: 0.634169280529, Generator Loss: 3.20539808273\n",
      "Epoch: 10,Discriminator Loss: 0.136435344815, Generator Loss: 0.266071349382\n",
      "Epoch: 11,Discriminator Loss: -0.302047163248, Generator Loss: 0.545399069786\n",
      "Epoch: 12,Discriminator Loss: -0.582368373871, Generator Loss: 1.89215731621\n",
      "Epoch: 13,Discriminator Loss: 0.493572741747, Generator Loss: 0.00629770802334\n",
      "Epoch: 14,Discriminator Loss: 0.92381131649, Generator Loss: 0.000132348242914\n",
      "Epoch: 15,Discriminator Loss: 0.415827155113, Generator Loss: 0.0502451583743\n",
      "Epoch: 16,Discriminator Loss: 2.60401415825, Generator Loss: 0.00295469234698\n",
      "Epoch: 17,Discriminator Loss: 1.13258492947, Generator Loss: 0.689029991627\n",
      "Epoch: 18,Discriminator Loss: -0.303862273693, Generator Loss: 4.0253367424\n",
      "Epoch: 19,Discriminator Loss: 1.80209636688, Generator Loss: 10.2850236893\n",
      "Epoch: 20,Discriminator Loss: 0.633334338665, Generator Loss: 0.343121707439\n",
      "Epoch: 21,Discriminator Loss: 0.47248929739, Generator Loss: 0.0954402387142\n",
      "Epoch: 22,Discriminator Loss: 0.473799020052, Generator Loss: 1.62423691563e-06\n",
      "Epoch: 23,Discriminator Loss: -0.464480578899, Generator Loss: 6.130900383\n",
      "Epoch: 24,Discriminator Loss: 0.163274437189, Generator Loss: 5.32347548869e-05\n",
      "Epoch: 25,Discriminator Loss: 0.197089001536, Generator Loss: 0.163148134947\n",
      "Epoch: 26,Discriminator Loss: 0.469634473324, Generator Loss: 0.000386492203688\n",
      "Epoch: 27,Discriminator Loss: 0.465473562479, Generator Loss: 0.133452787995\n",
      "Epoch: 28,Discriminator Loss: -0.19020485878, Generator Loss: 0.909085273743\n",
      "Epoch: 29,Discriminator Loss: 0.755296230316, Generator Loss: 1.61849880219\n",
      "Epoch: 30,Discriminator Loss: 0.134851157665, Generator Loss: 11.1962490082\n",
      "Epoch: 31,Discriminator Loss: 1.77214968204, Generator Loss: 0.152272939682\n",
      "Epoch: 32,Discriminator Loss: -0.00522899068892, Generator Loss: 0.287677228451\n",
      "Epoch: 33,Discriminator Loss: -0.310603886843, Generator Loss: 6.46741199493\n",
      "Epoch: 34,Discriminator Loss: -0.104111306369, Generator Loss: 0.686838984489\n",
      "Epoch: 35,Discriminator Loss: 0.0158351361752, Generator Loss: 0.689165830612\n",
      "Epoch: 36,Discriminator Loss: 1.37102675438, Generator Loss: 0.00247655482963\n",
      "Epoch: 37,Discriminator Loss: -0.473607182503, Generator Loss: 1.97237098217\n",
      "Epoch: 38,Discriminator Loss: -0.176759213209, Generator Loss: 11.512925148\n",
      "Epoch: 39,Discriminator Loss: 0.495939165354, Generator Loss: 3.85795354843\n",
      "Epoch: 40,Discriminator Loss: 0.088789537549, Generator Loss: 0.451576173306\n",
      "Epoch: 41,Discriminator Loss: -0.387851029634, Generator Loss: 2.69804334641\n",
      "Epoch: 42,Discriminator Loss: 0.411322057247, Generator Loss: 0.635696530342\n",
      "Epoch: 43,Discriminator Loss: 2.30080938339, Generator Loss: 5.87852287292\n",
      "Epoch: 44,Discriminator Loss: 0.371051967144, Generator Loss: 0.0315416529775\n",
      "Epoch: 45,Discriminator Loss: -0.783580064774, Generator Loss: 10.1801156998\n",
      "Epoch: 46,Discriminator Loss: 0.167572557926, Generator Loss: 2.11937046051\n",
      "Epoch: 47,Discriminator Loss: 0.382182568312, Generator Loss: 0.0447302535176\n",
      "Epoch: 48,Discriminator Loss: -0.258433640003, Generator Loss: 0.605732858181\n",
      "Epoch: 49,Discriminator Loss: 1.45656251907, Generator Loss: 6.48697948456\n",
      "Epoch: 50,Discriminator Loss: 0.0755461156368, Generator Loss: 0.630216479301\n",
      "Epoch: 51,Discriminator Loss: 1.29706048965, Generator Loss: 0.105388656259\n",
      "Epoch: 52,Discriminator Loss: -0.456023663282, Generator Loss: 11.512925148\n",
      "Epoch: 53,Discriminator Loss: 0.300169974566, Generator Loss: 0.0444239526987\n",
      "Epoch: 54,Discriminator Loss: 1.00259041786, Generator Loss: 0.025339173153\n",
      "Epoch: 55,Discriminator Loss: 0.833538353443, Generator Loss: 0.336887866259\n",
      "Epoch: 56,Discriminator Loss: 1.83809804916, Generator Loss: 0.0665758103132\n",
      "Epoch: 57,Discriminator Loss: 0.243966192007, Generator Loss: 0.0176661610603\n",
      "Epoch: 58,Discriminator Loss: -0.544885516167, Generator Loss: 8.16072273254\n",
      "Epoch: 59,Discriminator Loss: 1.1143296957, Generator Loss: 0.242198973894\n",
      "Epoch: 60,Discriminator Loss: 0.635274410248, Generator Loss: 0.0376100763679\n",
      "Epoch: 61,Discriminator Loss: 0.649603664875, Generator Loss: 0.0506381653249\n",
      "Epoch: 62,Discriminator Loss: -0.351108491421, Generator Loss: 5.14212036133\n",
      "Epoch: 63,Discriminator Loss: 0.090332955122, Generator Loss: 0.00100933201611\n",
      "Epoch: 64,Discriminator Loss: 0.184187144041, Generator Loss: 0.0112630967051\n",
      "Epoch: 65,Discriminator Loss: 0.303034126759, Generator Loss: 0.000184182601515\n",
      "Epoch: 66,Discriminator Loss: 0.577565491199, Generator Loss: 0.0620776340365\n",
      "Epoch: 67,Discriminator Loss: 0.438142359257, Generator Loss: 0.000525860290509\n",
      "Epoch: 68,Discriminator Loss: 0.160905063152, Generator Loss: 0.00302668800578\n",
      "Epoch: 69,Discriminator Loss: 0.576233386993, Generator Loss: 0.0578500181437\n",
      "Epoch: 70,Discriminator Loss: 0.160503670573, Generator Loss: 0.000423770630732\n",
      "Epoch: 71,Discriminator Loss: 1.14657998085, Generator Loss: 0.706279993057\n",
      "Epoch: 72,Discriminator Loss: 0.0627489760518, Generator Loss: 0.457342803478\n",
      "Epoch: 73,Discriminator Loss: 0.521800518036, Generator Loss: 0.0186653770506\n",
      "Epoch: 74,Discriminator Loss: 0.175706267357, Generator Loss: 0.101698592305\n",
      "Epoch: 75,Discriminator Loss: -0.494902014732, Generator Loss: 5.13930273056\n",
      "Epoch: 76,Discriminator Loss: -0.8367882967, Generator Loss: 5.0025100708\n",
      "Epoch: 77,Discriminator Loss: 0.878018260002, Generator Loss: 0.0076905679889\n",
      "Epoch: 78,Discriminator Loss: 3.31615900993, Generator Loss: 0.102969959378\n",
      "Epoch: 79,Discriminator Loss: -0.0972403734922, Generator Loss: 0.605590939522\n",
      "Epoch: 80,Discriminator Loss: 0.207474738359, Generator Loss: 1.66946136951\n",
      "Epoch: 81,Discriminator Loss: -0.920021653175, Generator Loss: 8.94862651825\n",
      "Epoch: 82,Discriminator Loss: 0.115858830512, Generator Loss: 4.53822231293\n",
      "Epoch: 83,Discriminator Loss: 0.0624538511038, Generator Loss: 0.0350303798914\n",
      "Epoch: 84,Discriminator Loss: 0.305084466934, Generator Loss: 10.7795848846\n",
      "Epoch: 85,Discriminator Loss: -0.757232189178, Generator Loss: 5.44511842728\n",
      "Epoch: 86,Discriminator Loss: 1.37220263481, Generator Loss: 10.6337814331\n",
      "Epoch: 87,Discriminator Loss: 0.987229526043, Generator Loss: 0.0105618285015\n",
      "Epoch: 88,Discriminator Loss: 0.553887844086, Generator Loss: 0.0\n",
      "Epoch: 89,Discriminator Loss: -0.396883606911, Generator Loss: 1.26364576817\n",
      "Epoch: 90,Discriminator Loss: 0.900874972343, Generator Loss: 0.0354668349028\n",
      "Epoch: 91,Discriminator Loss: -0.727840065956, Generator Loss: 11.512925148\n",
      "Epoch: 92,Discriminator Loss: 0.456612735987, Generator Loss: 8.41046524048\n",
      "Epoch: 93,Discriminator Loss: 0.493969559669, Generator Loss: 0.00087822356727\n",
      "Epoch: 94,Discriminator Loss: -0.311322808266, Generator Loss: 4.24189805984\n",
      "Epoch: 95,Discriminator Loss: -0.230056375265, Generator Loss: 11.4525527954\n",
      "Epoch: 96,Discriminator Loss: 0.21578656137, Generator Loss: 0.223602429032\n",
      "Epoch: 97,Discriminator Loss: 0.514514565468, Generator Loss: 0.0722378492355\n",
      "Epoch: 98,Discriminator Loss: 0.229635179043, Generator Loss: 0.00424036337063\n",
      "Epoch: 99,Discriminator Loss: 0.371941536665, Generator Loss: 0.923771381378\n",
      "Epoch: 100,Discriminator Loss: 0.209404557943, Generator Loss: 0.00109645840712\n",
      "Epoch: 101,Discriminator Loss: 1.02657222748, Generator Loss: 0.00113137648441\n",
      "Epoch: 102,Discriminator Loss: 0.18025188148, Generator Loss: 0.160349279642\n",
      "Epoch: 103,Discriminator Loss: -0.744058609009, Generator Loss: 5.68299674988\n",
      "Epoch: 104,Discriminator Loss: 1.52868688107, Generator Loss: 0.290785163641\n",
      "Epoch: 105,Discriminator Loss: 0.130572155118, Generator Loss: 0.0151139637455\n",
      "Epoch: 106,Discriminator Loss: 0.315351963043, Generator Loss: 0.0160168819129\n",
      "Epoch: 107,Discriminator Loss: -0.161563813686, Generator Loss: 0.683884859085\n",
      "Epoch: 108,Discriminator Loss: 0.598602414131, Generator Loss: 0.00532566709444\n",
      "Epoch: 109,Discriminator Loss: 0.746093988419, Generator Loss: 0.0107246888801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110,Discriminator Loss: -0.0428053811193, Generator Loss: 0.319925040007\n",
      "Epoch: 111,Discriminator Loss: 0.364428699017, Generator Loss: 0.040341027081\n",
      "Epoch: 112,Discriminator Loss: 0.0662605911493, Generator Loss: 0.0287735573947\n",
      "Epoch: 113,Discriminator Loss: -0.877304792404, Generator Loss: 11.512925148\n",
      "Epoch: 114,Discriminator Loss: 0.30825394392, Generator Loss: 0.318253546953\n",
      "Epoch: 115,Discriminator Loss: 1.39834880829, Generator Loss: 0.0838051363826\n",
      "Epoch: 116,Discriminator Loss: 0.898004710674, Generator Loss: 0.162837937474\n",
      "Epoch: 117,Discriminator Loss: 0.4044893682, Generator Loss: 0.296481609344\n",
      "Epoch: 118,Discriminator Loss: 0.298133194447, Generator Loss: 0.0\n",
      "Epoch: 119,Discriminator Loss: -0.0331244021654, Generator Loss: 0.112875364721\n",
      "Epoch: 120,Discriminator Loss: 0.339890986681, Generator Loss: 0.00255993171595\n",
      "Epoch: 121,Discriminator Loss: 0.168569266796, Generator Loss: 0.00348078063689\n",
      "Epoch: 122,Discriminator Loss: -0.424475193024, Generator Loss: 2.78365588188\n",
      "Epoch: 123,Discriminator Loss: 2.63683319092, Generator Loss: 0.345053911209\n",
      "Epoch: 124,Discriminator Loss: -0.0510830804706, Generator Loss: 1.00650238991\n",
      "Epoch: 125,Discriminator Loss: 0.000865902751684, Generator Loss: 1.60762214661\n",
      "Epoch: 126,Discriminator Loss: 3.8089838028, Generator Loss: 6.6209230423\n",
      "Epoch: 127,Discriminator Loss: 0.395469367504, Generator Loss: 4.47034871343e-08\n",
      "Epoch: 128,Discriminator Loss: -0.198904126883, Generator Loss: 6.11298561096\n",
      "Epoch: 129,Discriminator Loss: 0.59907579422, Generator Loss: 0.00466000055894\n",
      "Epoch: 130,Discriminator Loss: -0.930955767632, Generator Loss: 8.98545265198\n",
      "Epoch: 131,Discriminator Loss: -0.732308506966, Generator Loss: 6.5917801857\n",
      "Epoch: 132,Discriminator Loss: 0.323622107506, Generator Loss: 11.512925148\n",
      "Epoch: 133,Discriminator Loss: 0.236087590456, Generator Loss: 1.34415704451e-05\n",
      "Epoch: 134,Discriminator Loss: 0.846393704414, Generator Loss: 0.0527079738677\n",
      "Epoch: 135,Discriminator Loss: 0.214584425092, Generator Loss: 0.00505437701941\n",
      "Epoch: 136,Discriminator Loss: 0.121689721942, Generator Loss: 0.150912061334\n",
      "Epoch: 137,Discriminator Loss: 0.252887368202, Generator Loss: 0.357315450907\n",
      "Epoch: 138,Discriminator Loss: 0.34057289362, Generator Loss: 0.441811650991\n",
      "Epoch: 139,Discriminator Loss: -0.431883603334, Generator Loss: 9.03711128235\n",
      "Epoch: 140,Discriminator Loss: 0.016898419708, Generator Loss: 0.334624052048\n",
      "Epoch: 141,Discriminator Loss: 0.254983663559, Generator Loss: 4.47042839369e-06\n",
      "Epoch: 142,Discriminator Loss: 2.39036512375, Generator Loss: 3.60901165009\n",
      "Epoch: 143,Discriminator Loss: 0.92170882225, Generator Loss: 0.0170769840479\n",
      "Epoch: 144,Discriminator Loss: 0.798294663429, Generator Loss: 0.0782401561737\n",
      "Epoch: 145,Discriminator Loss: -0.0651260465384, Generator Loss: 0.162548705935\n",
      "Epoch: 146,Discriminator Loss: -0.0145671516657, Generator Loss: 6.71462917328\n",
      "Epoch: 147,Discriminator Loss: 0.02712854743, Generator Loss: 0.79686653614\n",
      "Epoch: 148,Discriminator Loss: 0.260948866606, Generator Loss: 0.000628514040727\n",
      "Epoch: 149,Discriminator Loss: 0.182639747858, Generator Loss: 0.0076875705272\n",
      "Epoch: 150,Discriminator Loss: 0.276813566685, Generator Loss: 0.00168674951419\n",
      "Epoch: 151,Discriminator Loss: 0.799696326256, Generator Loss: 0.0051758447662\n",
      "Epoch: 152,Discriminator Loss: 0.483463436365, Generator Loss: 0.0248630829155\n",
      "Epoch: 153,Discriminator Loss: 0.379617422819, Generator Loss: 8.22439906187e-05\n",
      "Epoch: 154,Discriminator Loss: 0.0604263395071, Generator Loss: 1.1696614027\n",
      "Epoch: 155,Discriminator Loss: 0.771523952484, Generator Loss: 0.014113958925\n",
      "Epoch: 156,Discriminator Loss: -0.0152712417766, Generator Loss: 0.0553653538227\n",
      "Epoch: 157,Discriminator Loss: 1.1883752346, Generator Loss: 0.0331968963146\n",
      "Epoch: 158,Discriminator Loss: 0.146263092756, Generator Loss: 0.357129752636\n",
      "Epoch: 159,Discriminator Loss: 0.292230129242, Generator Loss: 3.60613307748e-06\n",
      "Epoch: 160,Discriminator Loss: 0.318688899279, Generator Loss: 0.0575296133757\n",
      "Epoch: 161,Discriminator Loss: -0.479067325592, Generator Loss: 10.1922292709\n",
      "Epoch: 162,Discriminator Loss: 0.335068792105, Generator Loss: 0.560000360012\n",
      "Epoch: 163,Discriminator Loss: 0.0599827952683, Generator Loss: 0.091808103025\n",
      "Epoch: 164,Discriminator Loss: 2.57166838646, Generator Loss: 0.105871915817\n",
      "Epoch: 165,Discriminator Loss: 0.872001230717, Generator Loss: 0.0237894821912\n",
      "Epoch: 166,Discriminator Loss: 0.16829662025, Generator Loss: 0.140007585287\n",
      "Epoch: 167,Discriminator Loss: 0.466792285442, Generator Loss: 0.107258543372\n",
      "Epoch: 168,Discriminator Loss: -0.050058029592, Generator Loss: 10.3157510757\n",
      "Epoch: 169,Discriminator Loss: 0.430737674236, Generator Loss: 0.0185263007879\n",
      "Epoch: 170,Discriminator Loss: 0.265910148621, Generator Loss: 0.00625740224496\n",
      "Epoch: 171,Discriminator Loss: 0.491030424833, Generator Loss: 0.112790048122\n",
      "Epoch: 172,Discriminator Loss: 0.219607114792, Generator Loss: 0.686838984489\n",
      "Epoch: 173,Discriminator Loss: 0.0932313725352, Generator Loss: 3.57628380243e-07\n",
      "Epoch: 174,Discriminator Loss: -0.648728013039, Generator Loss: 5.76031303406\n",
      "Epoch: 175,Discriminator Loss: -0.0299888625741, Generator Loss: 0.0948927849531\n",
      "Epoch: 176,Discriminator Loss: -0.597384512424, Generator Loss: 8.91646099091\n",
      "Epoch: 177,Discriminator Loss: -0.249916955829, Generator Loss: 1.54810357094\n",
      "Epoch: 178,Discriminator Loss: -0.510087966919, Generator Loss: 2.02158999443\n",
      "Epoch: 179,Discriminator Loss: 1.68061470985, Generator Loss: 0.0365223586559\n",
      "Epoch: 180,Discriminator Loss: 0.327078998089, Generator Loss: 0.0829616785049\n",
      "Epoch: 181,Discriminator Loss: 1.2893447876, Generator Loss: 0.00121225102339\n",
      "Epoch: 182,Discriminator Loss: 0.324694037437, Generator Loss: 0.0491524487734\n",
      "Epoch: 183,Discriminator Loss: -0.537546634674, Generator Loss: 5.61668395996\n",
      "Epoch: 184,Discriminator Loss: 0.587270379066, Generator Loss: 0.00385359115899\n",
      "Epoch: 185,Discriminator Loss: 0.30882704258, Generator Loss: 0.000219283989281\n",
      "Epoch: 186,Discriminator Loss: 1.35919761658, Generator Loss: 0.176873475313\n",
      "Epoch: 187,Discriminator Loss: 0.101590253413, Generator Loss: 0.166157126427\n",
      "Epoch: 188,Discriminator Loss: -0.251749277115, Generator Loss: 0.607769668102\n",
      "Epoch: 189,Discriminator Loss: -0.41716709733, Generator Loss: 10.2343816757\n",
      "Epoch: 190,Discriminator Loss: 0.24586379528, Generator Loss: 0.532559454441\n",
      "Epoch: 191,Discriminator Loss: -0.500507712364, Generator Loss: 2.4247481823\n",
      "Epoch: 192,Discriminator Loss: 0.338227927685, Generator Loss: 0.0915142148733\n",
      "Epoch: 193,Discriminator Loss: 0.294326007366, Generator Loss: 0.0261033736169\n",
      "Epoch: 194,Discriminator Loss: 0.404602438211, Generator Loss: 0.388532519341\n",
      "Epoch: 195,Discriminator Loss: 0.611174345016, Generator Loss: 0.000219239213038\n",
      "Epoch: 196,Discriminator Loss: 0.0197114907205, Generator Loss: 0.0880617424846\n",
      "Epoch: 197,Discriminator Loss: 0.184548854828, Generator Loss: 0.0193985961378\n",
      "Epoch: 198,Discriminator Loss: 0.0278854630888, Generator Loss: 0.000102051162685\n",
      "Epoch: 199,Discriminator Loss: -0.156278863549, Generator Loss: 0.537414669991\n",
      "Epoch: 200,Discriminator Loss: 2.19780921936, Generator Loss: 0.0689159408212\n",
      "Epoch: 201,Discriminator Loss: -0.583371162415, Generator Loss: 6.79820966721\n",
      "Epoch: 202,Discriminator Loss: -0.289826363325, Generator Loss: 7.86995363235\n",
      "Epoch: 203,Discriminator Loss: 0.374515205622, Generator Loss: 0.408966362476\n",
      "Epoch: 204,Discriminator Loss: 0.216621756554, Generator Loss: 0.164654746652\n",
      "Epoch: 205,Discriminator Loss: -0.370697379112, Generator Loss: 4.6358795166\n",
      "Epoch: 206,Discriminator Loss: 0.132575392723, Generator Loss: 0.0\n",
      "Epoch: 207,Discriminator Loss: 0.164847075939, Generator Loss: 5.9984085965e-05\n",
      "Epoch: 208,Discriminator Loss: 0.671396017075, Generator Loss: 0.0299677979201\n",
      "Epoch: 209,Discriminator Loss: 0.33740362525, Generator Loss: 0.235315173864\n",
      "Epoch: 210,Discriminator Loss: 0.253471374512, Generator Loss: 0.0881750285625\n",
      "Epoch: 211,Discriminator Loss: -0.00064099393785, Generator Loss: 0.250388503075\n",
      "Epoch: 212,Discriminator Loss: 0.59267359972, Generator Loss: 0.340314149857\n",
      "Epoch: 213,Discriminator Loss: -0.0186644867063, Generator Loss: 4.95831298828\n",
      "Epoch: 214,Discriminator Loss: -0.79961335659, Generator Loss: 6.55152082443\n",
      "Epoch: 215,Discriminator Loss: -0.578611731529, Generator Loss: 1.11447238922\n",
      "Epoch: 216,Discriminator Loss: -0.0857653096318, Generator Loss: 0.623041749001\n",
      "Epoch: 217,Discriminator Loss: 0.919669747353, Generator Loss: 0.0712386369705\n",
      "Epoch: 218,Discriminator Loss: 0.927424132824, Generator Loss: 0.0436122529209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219,Discriminator Loss: 0.525106191635, Generator Loss: 0.000787662691437\n",
      "Epoch: 220,Discriminator Loss: 0.346666634083, Generator Loss: 0.0634604990482\n",
      "Epoch: 221,Discriminator Loss: 0.328684538603, Generator Loss: 0.109960898757\n",
      "Epoch: 222,Discriminator Loss: 2.22062468529, Generator Loss: 0.281028389931\n",
      "Epoch: 223,Discriminator Loss: 0.207620427012, Generator Loss: 0.0258869212121\n",
      "Epoch: 224,Discriminator Loss: 0.13297329843, Generator Loss: 0.000822722795419\n",
      "Epoch: 225,Discriminator Loss: -0.728822231293, Generator Loss: 5.47651386261\n",
      "Epoch: 226,Discriminator Loss: 0.401591718197, Generator Loss: 0.0133243240416\n",
      "Epoch: 227,Discriminator Loss: 1.90202641487, Generator Loss: 0.247815489769\n",
      "Epoch: 228,Discriminator Loss: -0.151395201683, Generator Loss: 5.84392261505\n",
      "Epoch: 229,Discriminator Loss: 2.86368989944, Generator Loss: 0.0680879279971\n",
      "Epoch: 230,Discriminator Loss: 1.2981607914, Generator Loss: 0.0238837487996\n",
      "Epoch: 231,Discriminator Loss: 0.0123840682209, Generator Loss: 0.24494086206\n",
      "Epoch: 232,Discriminator Loss: -0.0425877571106, Generator Loss: 2.16065597534\n",
      "Epoch: 233,Discriminator Loss: 0.225983083248, Generator Loss: 0.00253993016668\n",
      "Epoch: 234,Discriminator Loss: 0.292618691921, Generator Loss: 0.00396336521953\n",
      "Epoch: 235,Discriminator Loss: 0.169835150242, Generator Loss: 0.0709382519126\n",
      "Epoch: 236,Discriminator Loss: 0.58149266243, Generator Loss: 0.0587361454964\n",
      "Epoch: 237,Discriminator Loss: 0.303737401962, Generator Loss: 0.0389927588403\n",
      "Epoch: 238,Discriminator Loss: 0.0277387872338, Generator Loss: 0.340799659491\n",
      "Epoch: 239,Discriminator Loss: -0.0202864427119, Generator Loss: 0.053903978318\n",
      "Epoch: 240,Discriminator Loss: 0.171547949314, Generator Loss: 8.30029678345\n",
      "Epoch: 241,Discriminator Loss: 0.90466272831, Generator Loss: 4.91192245483\n",
      "Epoch: 242,Discriminator Loss: -0.35397619009, Generator Loss: 1.58120036125\n",
      "Epoch: 243,Discriminator Loss: 0.406352907419, Generator Loss: 0.359904408455\n",
      "Epoch: 244,Discriminator Loss: 0.934069991112, Generator Loss: 7.3378329277\n",
      "Epoch: 245,Discriminator Loss: 1.85499274731, Generator Loss: 0.00104225066025\n",
      "Epoch: 246,Discriminator Loss: 0.179872870445, Generator Loss: 1.46032232351e-06\n",
      "Epoch: 247,Discriminator Loss: 1.36729216576, Generator Loss: 0.0271075814962\n",
      "Epoch: 248,Discriminator Loss: 0.312601804733, Generator Loss: 0.00306762102991\n",
      "Epoch: 249,Discriminator Loss: 1.15970540047, Generator Loss: 0.063018091023\n",
      "Epoch: 250,Discriminator Loss: -0.60043233633, Generator Loss: 6.72398376465\n",
      "Epoch: 251,Discriminator Loss: 0.799590229988, Generator Loss: 0.00370959471911\n",
      "Epoch: 252,Discriminator Loss: 0.129812657833, Generator Loss: 0.244405806065\n",
      "Epoch: 253,Discriminator Loss: -0.0652727484703, Generator Loss: 0.185004904866\n",
      "Epoch: 254,Discriminator Loss: 0.0451721996069, Generator Loss: 0.281037926674\n",
      "Epoch: 255,Discriminator Loss: 0.34955444932, Generator Loss: 0.00847906433046\n",
      "Epoch: 256,Discriminator Loss: -0.300949573517, Generator Loss: 6.29294300079\n",
      "Epoch: 257,Discriminator Loss: 0.39014351368, Generator Loss: 8.61842490849e-05\n",
      "Epoch: 258,Discriminator Loss: 0.412623137236, Generator Loss: 0.016174197197\n",
      "Epoch: 259,Discriminator Loss: 0.0198087021708, Generator Loss: 0.138077348471\n",
      "Epoch: 260,Discriminator Loss: 0.271631121635, Generator Loss: 0.0480008460581\n",
      "Epoch: 261,Discriminator Loss: -0.481140077114, Generator Loss: 11.512925148\n",
      "Epoch: 262,Discriminator Loss: -0.0455756634474, Generator Loss: 0.235283970833\n",
      "Epoch: 263,Discriminator Loss: -0.778620839119, Generator Loss: 6.89692258835\n",
      "Epoch: 264,Discriminator Loss: 7.01980733871, Generator Loss: 0.710117816925\n",
      "Epoch: 265,Discriminator Loss: 0.443050503731, Generator Loss: 0.372992068529\n",
      "Epoch: 266,Discriminator Loss: 0.241203069687, Generator Loss: 0.946756660938\n",
      "Epoch: 267,Discriminator Loss: -0.306568801403, Generator Loss: 4.47132110596\n",
      "Epoch: 268,Discriminator Loss: 0.690951943398, Generator Loss: 0.0376669839025\n",
      "Epoch: 269,Discriminator Loss: 0.287271857262, Generator Loss: 3.21235747833e-05\n",
      "Epoch: 270,Discriminator Loss: 0.181822478771, Generator Loss: 0.0303209349513\n",
      "Epoch: 271,Discriminator Loss: -0.243548050523, Generator Loss: 3.19758248329\n",
      "Epoch: 272,Discriminator Loss: 0.209542542696, Generator Loss: 0.686599731445\n",
      "Epoch: 273,Discriminator Loss: 0.843634724617, Generator Loss: 0.0235290937126\n",
      "Epoch: 274,Discriminator Loss: 0.419273883104, Generator Loss: 2.55756592751\n",
      "Epoch: 275,Discriminator Loss: 0.376046746969, Generator Loss: 0.00299999676645\n",
      "Epoch: 276,Discriminator Loss: -0.173731833696, Generator Loss: 8.80254936218\n",
      "Epoch: 277,Discriminator Loss: 0.146332219243, Generator Loss: 0.384562075138\n",
      "Epoch: 278,Discriminator Loss: -0.0422558709979, Generator Loss: 0.155184715986\n",
      "Epoch: 279,Discriminator Loss: 0.26163187623, Generator Loss: 0.072049498558\n",
      "Epoch: 280,Discriminator Loss: 0.238516509533, Generator Loss: 0.585359096527\n",
      "Epoch: 281,Discriminator Loss: 0.0621831640601, Generator Loss: 0.0456262975931\n",
      "Epoch: 282,Discriminator Loss: 0.227568313479, Generator Loss: 0.295158326626\n",
      "Epoch: 283,Discriminator Loss: 0.458088517189, Generator Loss: 6.67715215683\n",
      "Epoch: 284,Discriminator Loss: 0.509299695492, Generator Loss: 0.001244291896\n",
      "Epoch: 285,Discriminator Loss: 0.327842593193, Generator Loss: 0.00120620755479\n",
      "Epoch: 286,Discriminator Loss: -0.156463772058, Generator Loss: 0.364860594273\n",
      "Epoch: 287,Discriminator Loss: 0.0354687869549, Generator Loss: 0.290800571442\n",
      "Epoch: 288,Discriminator Loss: -0.954859256744, Generator Loss: 10.5591125488\n",
      "Epoch: 289,Discriminator Loss: 0.559819936752, Generator Loss: 0.00418165558949\n",
      "Epoch: 290,Discriminator Loss: 0.0335188955069, Generator Loss: 2.46243000031\n",
      "Epoch: 291,Discriminator Loss: -0.489328086376, Generator Loss: 6.7006983757\n",
      "Epoch: 292,Discriminator Loss: -0.158137366176, Generator Loss: 0.686838984489\n",
      "Epoch: 293,Discriminator Loss: 2.16471982002, Generator Loss: 0.86380636692\n",
      "Epoch: 294,Discriminator Loss: 0.254599750042, Generator Loss: 0.0297236554325\n",
      "Epoch: 295,Discriminator Loss: 0.30528819561, Generator Loss: 0.0159181989729\n",
      "Epoch: 296,Discriminator Loss: 0.0366995446384, Generator Loss: 0.00349675118923\n",
      "Epoch: 297,Discriminator Loss: 0.311704516411, Generator Loss: 0.0805848687887\n",
      "Epoch: 298,Discriminator Loss: 4.77640533447, Generator Loss: 0.0253402851522\n",
      "Epoch: 299,Discriminator Loss: 0.412416398525, Generator Loss: 0.0904908031225\n",
      "Epoch: 300,Discriminator Loss: 0.469748228788, Generator Loss: 2.53319967669e-07\n",
      "Epoch: 301,Discriminator Loss: -0.0102779641747, Generator Loss: 0.232969149947\n",
      "Epoch: 302,Discriminator Loss: 0.150490239263, Generator Loss: 0.0064852302894\n",
      "Epoch: 303,Discriminator Loss: 0.165595084429, Generator Loss: 0.00435558380559\n",
      "Epoch: 304,Discriminator Loss: 0.240553051233, Generator Loss: 0.000919345882721\n",
      "Epoch: 305,Discriminator Loss: 0.632183790207, Generator Loss: 0.0154027407989\n",
      "Epoch: 306,Discriminator Loss: 0.0774914175272, Generator Loss: 0.841746330261\n",
      "Epoch: 307,Discriminator Loss: -0.0875450745225, Generator Loss: 0.226992294192\n",
      "Epoch: 308,Discriminator Loss: 0.897428750992, Generator Loss: 0.0311820618808\n",
      "Epoch: 309,Discriminator Loss: 0.515192687511, Generator Loss: 0.0381054393947\n",
      "Epoch: 310,Discriminator Loss: 1.49094700813, Generator Loss: 2.43862438202\n",
      "Epoch: 311,Discriminator Loss: 0.615954339504, Generator Loss: 0.000396401475882\n",
      "Epoch: 312,Discriminator Loss: -0.018967313692, Generator Loss: 0.108900889754\n",
      "Epoch: 313,Discriminator Loss: 0.510732769966, Generator Loss: 5.23490142822\n",
      "Epoch: 314,Discriminator Loss: 0.0300896894187, Generator Loss: 0.000294535711873\n",
      "Epoch: 315,Discriminator Loss: -0.166406780481, Generator Loss: 0.311814367771\n",
      "Epoch: 316,Discriminator Loss: -0.75684261322, Generator Loss: 10.6085796356\n",
      "Epoch: 317,Discriminator Loss: -0.153424799442, Generator Loss: 0.570530414581\n",
      "Epoch: 318,Discriminator Loss: 0.725737929344, Generator Loss: 0.53187841177\n",
      "Epoch: 319,Discriminator Loss: 1.82635116577, Generator Loss: 0.345003813505\n",
      "Epoch: 320,Discriminator Loss: 1.39488625526, Generator Loss: 0.0108756870031\n",
      "Epoch: 321,Discriminator Loss: 1.13693392277, Generator Loss: 0.00117507227696\n",
      "Epoch: 322,Discriminator Loss: 0.443621218204, Generator Loss: 0.0771215930581\n",
      "Epoch: 323,Discriminator Loss: 0.250833570957, Generator Loss: 2.06190371513\n",
      "Epoch: 324,Discriminator Loss: 0.560721099377, Generator Loss: 5.7606252085e-05\n",
      "Epoch: 325,Discriminator Loss: 1.42181384563, Generator Loss: 0.339241981506\n",
      "Epoch: 326,Discriminator Loss: 1.03692090511, Generator Loss: 0.233589529991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 327,Discriminator Loss: 0.108449503779, Generator Loss: 0.0546689033508\n",
      "Epoch: 328,Discriminator Loss: 1.0044580698, Generator Loss: 0.310255646706\n",
      "Epoch: 329,Discriminator Loss: 0.734769105911, Generator Loss: 0.0735514685512\n",
      "Epoch: 330,Discriminator Loss: 2.67952895164, Generator Loss: 0.226162865758\n",
      "Epoch: 331,Discriminator Loss: -0.858565449715, Generator Loss: 7.11862754822\n",
      "Epoch: 332,Discriminator Loss: 0.142666459084, Generator Loss: 6.72059968565e-06\n",
      "Epoch: 333,Discriminator Loss: 0.581153094769, Generator Loss: 0.022936180234\n",
      "Epoch: 334,Discriminator Loss: -0.0648639202118, Generator Loss: 0.287599682808\n",
      "Epoch: 335,Discriminator Loss: -0.682207405567, Generator Loss: 1.98038101196\n",
      "Epoch: 336,Discriminator Loss: -0.689247369766, Generator Loss: 5.44479179382\n",
      "Epoch: 337,Discriminator Loss: 0.852597415447, Generator Loss: 0.0100520066917\n",
      "Epoch: 338,Discriminator Loss: 1.27925610542, Generator Loss: 0.354826509953\n",
      "Epoch: 339,Discriminator Loss: 2.35044312477, Generator Loss: 0.214569672942\n",
      "Epoch: 340,Discriminator Loss: 0.632574677467, Generator Loss: 0.0143979229033\n",
      "Epoch: 341,Discriminator Loss: 0.0539823174477, Generator Loss: 0.272439628839\n",
      "Epoch: 342,Discriminator Loss: 0.457055091858, Generator Loss: 0.00048719055485\n",
      "Epoch: 343,Discriminator Loss: 0.500499427319, Generator Loss: 0.89750957489\n",
      "Epoch: 344,Discriminator Loss: -0.462450146675, Generator Loss: 6.00051307678\n",
      "Epoch: 345,Discriminator Loss: 2.04372811317, Generator Loss: 0.00118454988115\n",
      "Epoch: 346,Discriminator Loss: 0.559524178505, Generator Loss: 5.20144462585\n",
      "Epoch: 347,Discriminator Loss: 0.168890267611, Generator Loss: 0.157799199224\n",
      "Epoch: 348,Discriminator Loss: -0.129635512829, Generator Loss: 0.487506896257\n",
      "Epoch: 349,Discriminator Loss: -0.585352540016, Generator Loss: 11.512925148\n",
      "Epoch: 350,Discriminator Loss: -0.258314490318, Generator Loss: 0.769082665443\n",
      "Epoch: 351,Discriminator Loss: 0.832089602947, Generator Loss: 0.211156606674\n",
      "Epoch: 352,Discriminator Loss: 0.992151498795, Generator Loss: 0.696421682835\n",
      "Epoch: 353,Discriminator Loss: 0.276212930679, Generator Loss: 0.0\n",
      "Epoch: 354,Discriminator Loss: 0.151858150959, Generator Loss: 1.78586745262\n",
      "Epoch: 355,Discriminator Loss: -0.111598625779, Generator Loss: 0.749617815018\n",
      "Epoch: 356,Discriminator Loss: 0.195564717054, Generator Loss: 0.475522518158\n",
      "Epoch: 357,Discriminator Loss: -0.521103262901, Generator Loss: 0.907257258892\n",
      "Epoch: 358,Discriminator Loss: -0.0842220708728, Generator Loss: 4.26786470413\n",
      "Epoch: 359,Discriminator Loss: 0.332658857107, Generator Loss: 0.00241025304422\n",
      "Epoch: 360,Discriminator Loss: 0.483715325594, Generator Loss: 0.0\n",
      "Epoch: 361,Discriminator Loss: -0.421294480562, Generator Loss: 5.03318834305\n",
      "Epoch: 362,Discriminator Loss: 1.49846720695, Generator Loss: 0.683867394924\n",
      "Epoch: 363,Discriminator Loss: 1.83306396008, Generator Loss: 0.182967379689\n",
      "Epoch: 364,Discriminator Loss: 2.49966621399, Generator Loss: 0.881796479225\n",
      "Epoch: 365,Discriminator Loss: 1.2703063488, Generator Loss: 0.871248483658\n",
      "Epoch: 366,Discriminator Loss: 0.779092788696, Generator Loss: 0.910720288754\n",
      "Epoch: 367,Discriminator Loss: 0.363339275122, Generator Loss: 0.0840944200754\n",
      "Epoch: 368,Discriminator Loss: 0.320828974247, Generator Loss: 0.17566563189\n",
      "Epoch: 369,Discriminator Loss: 0.392841696739, Generator Loss: 0.331445515156\n",
      "Epoch: 370,Discriminator Loss: -0.198118150234, Generator Loss: 0.634167790413\n",
      "Epoch: 371,Discriminator Loss: 1.20272195339, Generator Loss: 1.32922434807\n",
      "Epoch: 372,Discriminator Loss: 0.286596357822, Generator Loss: 0.0836229622364\n",
      "Epoch: 373,Discriminator Loss: -0.481784194708, Generator Loss: 0.713879525661\n",
      "Epoch: 374,Discriminator Loss: 0.00601171143353, Generator Loss: 2.50501132011\n",
      "Epoch: 375,Discriminator Loss: -0.735770463943, Generator Loss: 8.00611019135\n",
      "Epoch: 376,Discriminator Loss: 1.99125003815, Generator Loss: 0.000111549117719\n",
      "Epoch: 377,Discriminator Loss: 0.427648305893, Generator Loss: 0.0218150541186\n",
      "Epoch: 378,Discriminator Loss: 2.05485200882, Generator Loss: 0.000726044760086\n",
      "Epoch: 379,Discriminator Loss: 0.0214301198721, Generator Loss: 1.51572871208\n",
      "Epoch: 380,Discriminator Loss: 0.503643631935, Generator Loss: 3.22870969772\n",
      "Epoch: 381,Discriminator Loss: 1.19533622265, Generator Loss: 0.0256084576249\n",
      "Epoch: 382,Discriminator Loss: -0.631106257439, Generator Loss: 11.512925148\n",
      "Epoch: 383,Discriminator Loss: 0.194770842791, Generator Loss: 7.83526992798\n",
      "Epoch: 384,Discriminator Loss: -0.534186899662, Generator Loss: 2.31656646729\n",
      "Epoch: 385,Discriminator Loss: -0.345187872648, Generator Loss: 0.571021974087\n",
      "Epoch: 386,Discriminator Loss: 0.0761252045631, Generator Loss: 0.324844896793\n",
      "Epoch: 387,Discriminator Loss: 0.315888285637, Generator Loss: 0.0126160634682\n",
      "Epoch: 388,Discriminator Loss: 1.41635835171, Generator Loss: 6.10949030033e-07\n",
      "Epoch: 389,Discriminator Loss: -0.506887674332, Generator Loss: 6.22223377228\n",
      "Epoch: 390,Discriminator Loss: -0.125733792782, Generator Loss: 0.305364280939\n",
      "Epoch: 391,Discriminator Loss: 0.397578507662, Generator Loss: 0.0273462198675\n",
      "Epoch: 392,Discriminator Loss: 1.39560866356, Generator Loss: 0.00471599120647\n",
      "Epoch: 393,Discriminator Loss: -0.860158741474, Generator Loss: 10.1595821381\n",
      "Epoch: 394,Discriminator Loss: -0.317697614431, Generator Loss: 3.25327086449\n",
      "Epoch: 395,Discriminator Loss: -0.367341727018, Generator Loss: 5.02235126495\n",
      "Epoch: 396,Discriminator Loss: 0.228824362159, Generator Loss: 0.224083051085\n",
      "Epoch: 397,Discriminator Loss: -0.267872452736, Generator Loss: 1.66395401955\n",
      "Epoch: 398,Discriminator Loss: 0.37861546874, Generator Loss: 3.65763473511\n",
      "Epoch: 399,Discriminator Loss: 1.34368896484, Generator Loss: 0.348816215992\n",
      "Epoch: 400,Discriminator Loss: 0.161557167768, Generator Loss: 0.0866968780756\n",
      "Epoch: 401,Discriminator Loss: -0.164800316095, Generator Loss: 2.44829559326\n",
      "Epoch: 402,Discriminator Loss: 0.532330751419, Generator Loss: 0.256708830595\n",
      "Epoch: 403,Discriminator Loss: 1.53222632408, Generator Loss: 0.281317323446\n",
      "Epoch: 404,Discriminator Loss: 0.205013021827, Generator Loss: 0.0331778377295\n",
      "Epoch: 405,Discriminator Loss: -0.167349845171, Generator Loss: 9.47092723846\n",
      "Epoch: 406,Discriminator Loss: 0.316158682108, Generator Loss: 0.000121449542348\n",
      "Epoch: 407,Discriminator Loss: 0.364743947983, Generator Loss: 0.292146205902\n",
      "Epoch: 408,Discriminator Loss: 5.36982345581, Generator Loss: 0.0296347364783\n",
      "Epoch: 409,Discriminator Loss: 0.174409806728, Generator Loss: 0.00834525376558\n",
      "Epoch: 410,Discriminator Loss: 0.63575565815, Generator Loss: 0.0460761748254\n",
      "Epoch: 411,Discriminator Loss: -0.339481443167, Generator Loss: 8.64848136902\n",
      "Epoch: 412,Discriminator Loss: 0.699667453766, Generator Loss: 0.325052082539\n",
      "Epoch: 413,Discriminator Loss: 0.0851828753948, Generator Loss: 0.0373925976455\n",
      "Epoch: 414,Discriminator Loss: 0.208462357521, Generator Loss: 5.75808238983\n",
      "Epoch: 415,Discriminator Loss: -0.0756811723113, Generator Loss: 0.691439628601\n",
      "Epoch: 416,Discriminator Loss: 0.0636620521545, Generator Loss: 0.573353171349\n",
      "Epoch: 417,Discriminator Loss: 0.365603327751, Generator Loss: 2.01329567062e-05\n",
      "Epoch: 418,Discriminator Loss: -0.98039740324, Generator Loss: 10.512845993\n",
      "Epoch: 419,Discriminator Loss: 3.04506659508, Generator Loss: 5.90040111542\n",
      "Epoch: 420,Discriminator Loss: 1.08441197872, Generator Loss: 0.0029245459009\n",
      "Epoch: 421,Discriminator Loss: -0.170892909169, Generator Loss: 0.74542170763\n",
      "Epoch: 422,Discriminator Loss: 0.152548074722, Generator Loss: 0.101616464555\n",
      "Epoch: 423,Discriminator Loss: 0.0589161291718, Generator Loss: 0.232872754335\n",
      "Epoch: 424,Discriminator Loss: 0.954741537571, Generator Loss: 0.0434987954795\n",
      "Epoch: 425,Discriminator Loss: -0.754681885242, Generator Loss: 2.85138273239\n",
      "Epoch: 426,Discriminator Loss: -0.294339120388, Generator Loss: 0.624375343323\n",
      "Epoch: 427,Discriminator Loss: 5.08218669891, Generator Loss: 0.000785738171544\n",
      "Epoch: 428,Discriminator Loss: 0.853611648083, Generator Loss: 0.249724432826\n",
      "Epoch: 429,Discriminator Loss: 0.977458834648, Generator Loss: 0.000284741428914\n",
      "Epoch: 430,Discriminator Loss: 0.0312399175018, Generator Loss: 0.0301200542599\n",
      "Epoch: 431,Discriminator Loss: -0.0870393067598, Generator Loss: 0.104743905365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 432,Discriminator Loss: -0.174652054906, Generator Loss: 4.43835449219\n",
      "Epoch: 433,Discriminator Loss: -0.183990716934, Generator Loss: 0.370343655348\n",
      "Epoch: 434,Discriminator Loss: 0.741985321045, Generator Loss: 0.271081805229\n",
      "Epoch: 435,Discriminator Loss: 0.0830157995224, Generator Loss: 0.00364928273484\n",
      "Epoch: 436,Discriminator Loss: 0.407642543316, Generator Loss: 0.00777700403705\n",
      "Epoch: 437,Discriminator Loss: 0.472333103418, Generator Loss: 0.0928152352571\n",
      "Epoch: 438,Discriminator Loss: 0.0928432047367, Generator Loss: 3.57628380243e-07\n",
      "Epoch: 439,Discriminator Loss: -0.643009006977, Generator Loss: 9.42436981201\n",
      "Epoch: 440,Discriminator Loss: -0.136717841029, Generator Loss: 0.616515278816\n",
      "Epoch: 441,Discriminator Loss: -0.602838993073, Generator Loss: 11.512925148\n",
      "Epoch: 442,Discriminator Loss: -0.234539836645, Generator Loss: 0.553027391434\n",
      "Epoch: 443,Discriminator Loss: 1.04933977127, Generator Loss: 1.49011611938e-08\n",
      "Epoch: 444,Discriminator Loss: 0.343920707703, Generator Loss: 0.11890335381\n",
      "Epoch: 445,Discriminator Loss: 0.131281539798, Generator Loss: 1.53789260366e-05\n",
      "Epoch: 446,Discriminator Loss: -0.405890107155, Generator Loss: 1.47812211514\n",
      "Epoch: 447,Discriminator Loss: -0.0653362423182, Generator Loss: 0.239450007677\n",
      "Epoch: 448,Discriminator Loss: -0.378959804773, Generator Loss: 5.92039299011\n",
      "Epoch: 449,Discriminator Loss: -0.182134926319, Generator Loss: 5.60966587067\n",
      "Epoch: 450,Discriminator Loss: 0.805529713631, Generator Loss: 0.125238090754\n",
      "Epoch: 451,Discriminator Loss: 0.246470138431, Generator Loss: 0.00278527103364\n",
      "Epoch: 452,Discriminator Loss: -0.093059875071, Generator Loss: 0.430791407824\n",
      "Epoch: 453,Discriminator Loss: -0.361379861832, Generator Loss: 5.93382263184\n",
      "Epoch: 454,Discriminator Loss: 0.351391434669, Generator Loss: 11.512925148\n",
      "Epoch: 455,Discriminator Loss: 0.164151668549, Generator Loss: 0.225368559361\n",
      "Epoch: 456,Discriminator Loss: 0.683099150658, Generator Loss: 0.0094593083486\n",
      "Epoch: 457,Discriminator Loss: 0.068186737597, Generator Loss: 0.00875893048942\n",
      "Epoch: 458,Discriminator Loss: 1.68006086349, Generator Loss: 0.425079375505\n",
      "Epoch: 459,Discriminator Loss: 0.356807857752, Generator Loss: 0.230483695865\n",
      "Epoch: 460,Discriminator Loss: 0.0869388878345, Generator Loss: 0.414109289646\n",
      "Epoch: 461,Discriminator Loss: 0.35859015584, Generator Loss: 0.128730639815\n",
      "Epoch: 462,Discriminator Loss: 0.244651570916, Generator Loss: 1.85378958122e-05\n",
      "Epoch: 463,Discriminator Loss: -0.513077437878, Generator Loss: 5.71897029877\n",
      "Epoch: 464,Discriminator Loss: -0.318350195885, Generator Loss: 4.35700845718\n",
      "Epoch: 465,Discriminator Loss: 0.37782305479, Generator Loss: 4.72179599456e-05\n",
      "Epoch: 466,Discriminator Loss: 0.267742156982, Generator Loss: 0.00336277042516\n",
      "Epoch: 467,Discriminator Loss: 0.579273462296, Generator Loss: 0.000780860893428\n",
      "Epoch: 468,Discriminator Loss: 3.0042860508, Generator Loss: 0.0664179623127\n",
      "Epoch: 469,Discriminator Loss: 0.708026051521, Generator Loss: 0.0358723253012\n",
      "Epoch: 470,Discriminator Loss: 0.0798226445913, Generator Loss: 0.361515045166\n",
      "Epoch: 471,Discriminator Loss: -0.291405916214, Generator Loss: 3.28961467743\n",
      "Epoch: 472,Discriminator Loss: 0.375104665756, Generator Loss: 3.54538941383\n",
      "Epoch: 473,Discriminator Loss: -0.121945030987, Generator Loss: 0.37635114789\n",
      "Epoch: 474,Discriminator Loss: 0.147771447897, Generator Loss: 0.0413230136037\n",
      "Epoch: 475,Discriminator Loss: -0.541154980659, Generator Loss: 11.512925148\n",
      "Epoch: 476,Discriminator Loss: 0.308617174625, Generator Loss: 4.40039634705\n",
      "Epoch: 477,Discriminator Loss: 0.729300498962, Generator Loss: 0.0902231708169\n",
      "Epoch: 478,Discriminator Loss: -0.361022233963, Generator Loss: 2.8053855896\n",
      "Epoch: 479,Discriminator Loss: 0.382599592209, Generator Loss: 0.0259045474231\n",
      "Epoch: 480,Discriminator Loss: -0.0472604073584, Generator Loss: 0.190317779779\n",
      "Epoch: 481,Discriminator Loss: 0.490207403898, Generator Loss: 0.0594267584383\n",
      "Epoch: 482,Discriminator Loss: 0.197464466095, Generator Loss: 0.0811003148556\n",
      "Epoch: 483,Discriminator Loss: 0.521534323692, Generator Loss: 0.0225629471242\n",
      "Epoch: 484,Discriminator Loss: 0.144338846207, Generator Loss: 0.332522749901\n",
      "Epoch: 485,Discriminator Loss: 0.393662422895, Generator Loss: 0.0\n",
      "Epoch: 486,Discriminator Loss: 0.0160317495465, Generator Loss: 0.721010565758\n",
      "Epoch: 487,Discriminator Loss: 0.14350861311, Generator Loss: 5.01977491379\n",
      "Epoch: 488,Discriminator Loss: 0.829343318939, Generator Loss: 0.0\n",
      "Epoch: 489,Discriminator Loss: 0.716228842735, Generator Loss: 1.96696646526e-06\n",
      "Epoch: 490,Discriminator Loss: -0.217995256186, Generator Loss: 10.6630887985\n",
      "Epoch: 491,Discriminator Loss: 0.87014311552, Generator Loss: 0.225019067526\n",
      "Epoch: 492,Discriminator Loss: 0.249893456697, Generator Loss: 0.0840888395905\n",
      "Epoch: 493,Discriminator Loss: 0.342741250992, Generator Loss: 0.118559151888\n",
      "Epoch: 494,Discriminator Loss: 1.25326812267, Generator Loss: 11.512925148\n",
      "Epoch: 495,Discriminator Loss: 0.160132542253, Generator Loss: 0.00890949834138\n",
      "Epoch: 496,Discriminator Loss: 0.618055939674, Generator Loss: 0.156148046255\n",
      "Epoch: 497,Discriminator Loss: 0.234524175525, Generator Loss: 0.0168462581933\n",
      "Epoch: 498,Discriminator Loss: -0.0391943380237, Generator Loss: 6.5429558754\n",
      "Epoch: 499,Discriminator Loss: 0.0949872806668, Generator Loss: 0.00764600560069\n",
      "Epoch: 500,Discriminator Loss: 0.0436147376895, Generator Loss: 2.98290634155\n",
      "Epoch: 501,Discriminator Loss: -0.23889914155, Generator Loss: 0.514900624752\n",
      "Epoch: 502,Discriminator Loss: 0.185092300177, Generator Loss: 0.0689496845007\n",
      "Epoch: 503,Discriminator Loss: 0.191089168191, Generator Loss: 0.0407502278686\n",
      "Epoch: 504,Discriminator Loss: 0.488891065121, Generator Loss: 0.122319057584\n",
      "Epoch: 505,Discriminator Loss: 0.453375607729, Generator Loss: 2.38418806475e-07\n",
      "Epoch: 506,Discriminator Loss: -0.0169141944498, Generator Loss: 0.209097459912\n",
      "Epoch: 507,Discriminator Loss: 0.213068693876, Generator Loss: 0.0452237203717\n",
      "Epoch: 508,Discriminator Loss: 0.440865188837, Generator Loss: 0.0199774708599\n",
      "Epoch: 509,Discriminator Loss: -0.612755298615, Generator Loss: 8.05474472046\n",
      "Epoch: 510,Discriminator Loss: -0.477218210697, Generator Loss: 6.28904628754\n",
      "Epoch: 511,Discriminator Loss: 0.705673515797, Generator Loss: 0.0329263210297\n",
      "Epoch: 512,Discriminator Loss: 1.11466789246, Generator Loss: 5.77025651932\n",
      "Epoch: 513,Discriminator Loss: -0.111236900091, Generator Loss: 0.225996047258\n",
      "Epoch: 514,Discriminator Loss: 1.17927026749, Generator Loss: 3.54969406128\n",
      "Epoch: 515,Discriminator Loss: 0.329988032579, Generator Loss: 0.156216606498\n",
      "Epoch: 516,Discriminator Loss: 0.105887115002, Generator Loss: 0.163788482547\n",
      "Epoch: 517,Discriminator Loss: 0.172291725874, Generator Loss: 1.13589286804\n",
      "Epoch: 518,Discriminator Loss: 1.23804616928, Generator Loss: 0.0670511722565\n",
      "Epoch: 519,Discriminator Loss: -0.0701063722372, Generator Loss: 0.242506712675\n",
      "Epoch: 520,Discriminator Loss: 0.487879514694, Generator Loss: 0.00307134236209\n",
      "Epoch: 521,Discriminator Loss: -0.0125667490065, Generator Loss: 0.437416702509\n",
      "Epoch: 522,Discriminator Loss: -0.0866771191359, Generator Loss: 0.291828691959\n",
      "Epoch: 523,Discriminator Loss: 0.212960064411, Generator Loss: 0.00140251859557\n",
      "Epoch: 524,Discriminator Loss: 0.243895038962, Generator Loss: 0.0648303255439\n",
      "Epoch: 525,Discriminator Loss: 0.273673474789, Generator Loss: 8.42030276544e-05\n",
      "Epoch: 526,Discriminator Loss: 0.126991480589, Generator Loss: 0.0587964989245\n",
      "Epoch: 527,Discriminator Loss: 0.130276709795, Generator Loss: 0.00616318872198\n",
      "Epoch: 528,Discriminator Loss: 0.324957966805, Generator Loss: 0.000881327025127\n",
      "Epoch: 529,Discriminator Loss: 0.69257491827, Generator Loss: 0.136303365231\n",
      "Epoch: 530,Discriminator Loss: 0.921619653702, Generator Loss: 0.00364344520494\n",
      "Epoch: 531,Discriminator Loss: 0.654092609882, Generator Loss: 3.01005820802e-06\n",
      "Epoch: 532,Discriminator Loss: 0.00224549882114, Generator Loss: 0.42682492733\n",
      "Epoch: 533,Discriminator Loss: 0.534969866276, Generator Loss: 0.151474133134\n",
      "Epoch: 534,Discriminator Loss: -0.633959770203, Generator Loss: 7.76950120926\n",
      "Epoch: 535,Discriminator Loss: 0.227290958166, Generator Loss: 0.0147038549185\n",
      "Epoch: 536,Discriminator Loss: 0.708556354046, Generator Loss: 0.000977059360594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 537,Discriminator Loss: -0.387900829315, Generator Loss: 8.15682506561\n",
      "Epoch: 538,Discriminator Loss: 0.177709117532, Generator Loss: 0.130128622055\n",
      "Epoch: 539,Discriminator Loss: 0.352073192596, Generator Loss: 0.0563066937029\n",
      "Epoch: 540,Discriminator Loss: -0.41950315237, Generator Loss: 9.17831420898\n",
      "Epoch: 541,Discriminator Loss: 1.83743333817, Generator Loss: 0.159379929304\n",
      "Epoch: 542,Discriminator Loss: 1.42624902725, Generator Loss: 0.260356158018\n",
      "Epoch: 543,Discriminator Loss: 0.196172043681, Generator Loss: 0.000590452109464\n",
      "Epoch: 544,Discriminator Loss: -0.331209242344, Generator Loss: 5.62537908554\n",
      "Epoch: 545,Discriminator Loss: -0.014595001936, Generator Loss: 0.053760021925\n",
      "Epoch: 546,Discriminator Loss: 0.050797984004, Generator Loss: 0.0152999637648\n",
      "Epoch: 547,Discriminator Loss: 0.0205229241401, Generator Loss: 9.17944453249e-06\n",
      "Epoch: 548,Discriminator Loss: 0.317145913839, Generator Loss: 4.77872467041\n",
      "Epoch: 549,Discriminator Loss: 0.850216984749, Generator Loss: 0.139388173819\n",
      "Epoch: 550,Discriminator Loss: 0.80473780632, Generator Loss: 0.0616953261197\n",
      "Epoch: 551,Discriminator Loss: 1.53040313721, Generator Loss: 4.45323181152\n",
      "Epoch: 552,Discriminator Loss: 2.49370837212, Generator Loss: 0.0128429373726\n",
      "Epoch: 553,Discriminator Loss: 5.45347499847, Generator Loss: 6.99860247551e-05\n",
      "Epoch: 554,Discriminator Loss: 1.4290368557, Generator Loss: 0.00571787822992\n",
      "Epoch: 555,Discriminator Loss: -0.136360704899, Generator Loss: 0.171913892031\n",
      "Epoch: 556,Discriminator Loss: 0.109832316637, Generator Loss: 10.1636009216\n",
      "Epoch: 557,Discriminator Loss: 0.530532240868, Generator Loss: 0.00219288258813\n",
      "Epoch: 558,Discriminator Loss: 0.14522716403, Generator Loss: 0.401545226574\n",
      "Epoch: 559,Discriminator Loss: 0.465415775776, Generator Loss: 0.552854895592\n",
      "Epoch: 560,Discriminator Loss: 0.49846804142, Generator Loss: 0.00226570363156\n",
      "Epoch: 561,Discriminator Loss: 0.33661210537, Generator Loss: 0.0203252993524\n",
      "Epoch: 562,Discriminator Loss: 1.95176720619, Generator Loss: 3.09754614136e-05\n",
      "Epoch: 563,Discriminator Loss: 0.365204334259, Generator Loss: 0.528379380703\n",
      "Epoch: 564,Discriminator Loss: -0.605650305748, Generator Loss: 10.0678787231\n",
      "Epoch: 565,Discriminator Loss: 0.220492988825, Generator Loss: 0.000503585266415\n",
      "Epoch: 566,Discriminator Loss: -0.643970251083, Generator Loss: 4.36912584305\n",
      "Epoch: 567,Discriminator Loss: 0.11956910044, Generator Loss: 0.0148998470977\n",
      "Epoch: 568,Discriminator Loss: 0.592734098434, Generator Loss: 3.57671451569\n",
      "Epoch: 569,Discriminator Loss: -0.172030940652, Generator Loss: 11.512925148\n",
      "Epoch: 570,Discriminator Loss: -0.423929989338, Generator Loss: 1.26695632935\n",
      "Epoch: 571,Discriminator Loss: -0.352844059467, Generator Loss: 0.68294698\n",
      "Epoch: 572,Discriminator Loss: -0.847512483597, Generator Loss: 11.512925148\n",
      "Epoch: 573,Discriminator Loss: 0.0545994564891, Generator Loss: 0.0114791896194\n",
      "Epoch: 574,Discriminator Loss: -0.796556949615, Generator Loss: 5.67834568024\n",
      "Epoch: 575,Discriminator Loss: 3.22520494461, Generator Loss: 0.00521106272936\n",
      "Epoch: 576,Discriminator Loss: 0.521023988724, Generator Loss: 0.161712676287\n",
      "Epoch: 577,Discriminator Loss: 0.283308804035, Generator Loss: 0.00216905446723\n",
      "Epoch: 578,Discriminator Loss: 0.00289096683264, Generator Loss: 5.31007671356\n",
      "Epoch: 579,Discriminator Loss: 0.374723017216, Generator Loss: 1.19209346394e-07\n",
      "Epoch: 580,Discriminator Loss: -0.107866153121, Generator Loss: 0.305633664131\n",
      "Epoch: 581,Discriminator Loss: -0.317167192698, Generator Loss: 4.56698656082\n",
      "Epoch: 582,Discriminator Loss: -0.513888120651, Generator Loss: 1.44460463524\n",
      "Epoch: 583,Discriminator Loss: 3.44989490509, Generator Loss: 4.16729736328\n",
      "Epoch: 584,Discriminator Loss: -0.237366780639, Generator Loss: 4.12696027756\n",
      "Epoch: 585,Discriminator Loss: 0.910091638565, Generator Loss: 0.453614592552\n",
      "Epoch: 586,Discriminator Loss: 3.14232325554, Generator Loss: 6.03692770004\n",
      "Epoch: 587,Discriminator Loss: -0.312649309635, Generator Loss: 0.683339357376\n",
      "Epoch: 588,Discriminator Loss: 3.45724987984, Generator Loss: 0.000147519647726\n",
      "Epoch: 589,Discriminator Loss: -0.145165652037, Generator Loss: 0.718119084835\n",
      "Epoch: 590,Discriminator Loss: -0.607728660107, Generator Loss: 3.06571769714\n",
      "Epoch: 591,Discriminator Loss: 0.402375251055, Generator Loss: 0.0729968175292\n",
      "Epoch: 592,Discriminator Loss: 0.508640408516, Generator Loss: 11.512925148\n",
      "Epoch: 593,Discriminator Loss: -0.40412440896, Generator Loss: 4.63931894302\n",
      "Epoch: 594,Discriminator Loss: 0.335024237633, Generator Loss: 0.108960025012\n",
      "Epoch: 595,Discriminator Loss: 0.660515606403, Generator Loss: 0.272591650486\n",
      "Epoch: 596,Discriminator Loss: 2.78821897507, Generator Loss: 0.86151611805\n",
      "Epoch: 597,Discriminator Loss: 0.15051369369, Generator Loss: 8.94069742685e-08\n",
      "Epoch: 598,Discriminator Loss: 0.506018102169, Generator Loss: 0.680977165699\n",
      "Epoch: 599,Discriminator Loss: 0.564834952354, Generator Loss: 0.0653046965599\n",
      "Epoch: 600,Discriminator Loss: 2.29323172569, Generator Loss: 0.686817228794\n",
      "Epoch: 601,Discriminator Loss: 0.131887286901, Generator Loss: 0.869817197323\n",
      "Epoch: 602,Discriminator Loss: 0.314447700977, Generator Loss: 0.0633424967527\n",
      "Epoch: 603,Discriminator Loss: -0.968786358833, Generator Loss: 10.1525201797\n",
      "Epoch: 604,Discriminator Loss: -0.137848645449, Generator Loss: 4.435338974\n",
      "Epoch: 605,Discriminator Loss: 1.01274037361, Generator Loss: 0.0\n",
      "Epoch: 606,Discriminator Loss: 1.24904632568, Generator Loss: 0.00174330442678\n",
      "Epoch: 607,Discriminator Loss: 0.904747486115, Generator Loss: 5.95180702209\n",
      "Epoch: 608,Discriminator Loss: 0.786374568939, Generator Loss: 0.00361014250666\n",
      "Epoch: 609,Discriminator Loss: 0.166798859835, Generator Loss: 4.3885602951\n",
      "Epoch: 610,Discriminator Loss: -0.491228699684, Generator Loss: 4.94731903076\n",
      "Epoch: 611,Discriminator Loss: 0.144507229328, Generator Loss: 0.121086880565\n",
      "Epoch: 612,Discriminator Loss: 0.38180077076, Generator Loss: 11.512925148\n",
      "Epoch: 613,Discriminator Loss: 0.213967621326, Generator Loss: 0.00154564448167\n",
      "Epoch: 614,Discriminator Loss: -0.0626292675734, Generator Loss: 0.223242253065\n",
      "Epoch: 615,Discriminator Loss: 1.08261907101, Generator Loss: 1.49011611938e-08\n",
      "Epoch: 616,Discriminator Loss: 2.36836338043, Generator Loss: 0.0199783649296\n",
      "Epoch: 617,Discriminator Loss: 2.28214907646, Generator Loss: 0.124796643853\n",
      "Epoch: 618,Discriminator Loss: 1.93364202976, Generator Loss: 0.2186563164\n",
      "Epoch: 619,Discriminator Loss: 0.656887471676, Generator Loss: 0.00974473822862\n",
      "Epoch: 620,Discriminator Loss: 0.828536987305, Generator Loss: 0.232730686665\n",
      "Epoch: 621,Discriminator Loss: -0.470547795296, Generator Loss: 11.512925148\n",
      "Epoch: 622,Discriminator Loss: 0.508161485195, Generator Loss: 0.0717898756266\n",
      "Epoch: 623,Discriminator Loss: 0.439321398735, Generator Loss: 2.53319967669e-07\n",
      "Epoch: 624,Discriminator Loss: -0.0800319612026, Generator Loss: 4.94740247726\n",
      "Epoch: 625,Discriminator Loss: 0.00742327421904, Generator Loss: 0.146105468273\n",
      "Epoch: 626,Discriminator Loss: 1.56640219688, Generator Loss: 0.203174650669\n",
      "Epoch: 627,Discriminator Loss: 0.778532147408, Generator Loss: 0.306142747402\n",
      "Epoch: 628,Discriminator Loss: -0.02863362059, Generator Loss: 0.120500668883\n",
      "Epoch: 629,Discriminator Loss: 0.142015308142, Generator Loss: 0.00127724220511\n",
      "Epoch: 630,Discriminator Loss: -0.0344171710312, Generator Loss: 0.0499949455261\n",
      "Epoch: 631,Discriminator Loss: 4.74546718597, Generator Loss: 0.0158101674169\n",
      "Epoch: 632,Discriminator Loss: 0.308579385281, Generator Loss: 0.0317481830716\n",
      "Epoch: 633,Discriminator Loss: -0.764055252075, Generator Loss: 3.23089742661\n",
      "Epoch: 634,Discriminator Loss: -0.924872875214, Generator Loss: 9.94515609741\n",
      "Epoch: 635,Discriminator Loss: -0.282488644123, Generator Loss: 1.31659197807\n",
      "Epoch: 636,Discriminator Loss: 0.357127964497, Generator Loss: 0.188834369183\n",
      "Epoch: 637,Discriminator Loss: 0.447998940945, Generator Loss: 0.000171690815478\n",
      "Epoch: 638,Discriminator Loss: 1.38755118847, Generator Loss: 6.05031490326\n",
      "Epoch: 639,Discriminator Loss: 2.55577945709, Generator Loss: 0.00810545682907\n",
      "Epoch: 640,Discriminator Loss: 0.193876758218, Generator Loss: 0.242828160524\n",
      "Epoch: 641,Discriminator Loss: 0.04491552338, Generator Loss: 0.551723718643\n",
      "Epoch: 642,Discriminator Loss: 0.171249300241, Generator Loss: 0.0128759359941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 643,Discriminator Loss: 0.645623683929, Generator Loss: 0.000706044316757\n",
      "Epoch: 644,Discriminator Loss: -0.634537816048, Generator Loss: 10.6429843903\n",
      "Epoch: 645,Discriminator Loss: 0.222692489624, Generator Loss: 4.49920749664\n",
      "Epoch: 646,Discriminator Loss: -0.0309068076313, Generator Loss: 0.115512177348\n",
      "Epoch: 647,Discriminator Loss: -0.571150898933, Generator Loss: 9.01086997986\n",
      "Epoch: 648,Discriminator Loss: 2.14055109024, Generator Loss: 0.154600173235\n",
      "Epoch: 649,Discriminator Loss: 1.01870250702, Generator Loss: 0.0298261940479\n",
      "Epoch: 650,Discriminator Loss: 0.257453471422, Generator Loss: 0.273761689663\n",
      "Epoch: 651,Discriminator Loss: 0.0912015289068, Generator Loss: 0.206358522177\n",
      "Epoch: 652,Discriminator Loss: 3.5222029686, Generator Loss: 0.101987197995\n",
      "Epoch: 653,Discriminator Loss: 0.0125540606678, Generator Loss: 0.0869450867176\n",
      "Epoch: 654,Discriminator Loss: -0.374042868614, Generator Loss: 4.41628313065\n",
      "Epoch: 655,Discriminator Loss: 0.411211103201, Generator Loss: 0.0545750036836\n",
      "Epoch: 656,Discriminator Loss: 0.497192978859, Generator Loss: 0.000322346721077\n",
      "Epoch: 657,Discriminator Loss: -0.371587455273, Generator Loss: 0.686838984489\n",
      "Epoch: 658,Discriminator Loss: 2.08304023743, Generator Loss: 9.85244941711\n",
      "Epoch: 659,Discriminator Loss: -0.0741733461618, Generator Loss: 0.200263619423\n",
      "Epoch: 660,Discriminator Loss: 2.21365666389, Generator Loss: 0.0273513421416\n",
      "Epoch: 661,Discriminator Loss: 0.427782446146, Generator Loss: 0.0103738354519\n",
      "Epoch: 662,Discriminator Loss: 0.0284413658082, Generator Loss: 0.0888428837061\n",
      "Epoch: 663,Discriminator Loss: 0.673503637314, Generator Loss: 0.0110745895654\n",
      "Epoch: 664,Discriminator Loss: 1.7398352623, Generator Loss: 4.57911205292\n",
      "Epoch: 665,Discriminator Loss: 2.06676077843, Generator Loss: 0.295089513063\n",
      "Epoch: 666,Discriminator Loss: 3.04224491119, Generator Loss: 0.363119125366\n",
      "Epoch: 667,Discriminator Loss: -0.715901494026, Generator Loss: 4.32055044174\n",
      "Epoch: 668,Discriminator Loss: 4.08866500854, Generator Loss: 0.000199150905246\n",
      "Epoch: 669,Discriminator Loss: -0.111052751541, Generator Loss: 4.4956278801\n",
      "Epoch: 670,Discriminator Loss: 0.607417106628, Generator Loss: 0.223369941115\n",
      "Epoch: 671,Discriminator Loss: -0.0191270764917, Generator Loss: 0.338304251432\n",
      "Epoch: 672,Discriminator Loss: 0.850315690041, Generator Loss: 0.0279350355268\n",
      "Epoch: 673,Discriminator Loss: 0.497074902058, Generator Loss: 0.196193128824\n",
      "Epoch: 674,Discriminator Loss: 0.0396733358502, Generator Loss: 0.0410533547401\n",
      "Epoch: 675,Discriminator Loss: 0.0304896831512, Generator Loss: 0.0335211269557\n",
      "Epoch: 676,Discriminator Loss: 0.449938684702, Generator Loss: 0.282744437456\n",
      "Epoch: 677,Discriminator Loss: 0.225146234035, Generator Loss: 0.0839353427291\n",
      "Epoch: 678,Discriminator Loss: 0.40626180172, Generator Loss: 4.68616199493\n",
      "Epoch: 679,Discriminator Loss: 1.49286353588, Generator Loss: 0.143483668566\n",
      "Epoch: 680,Discriminator Loss: 2.2313978672, Generator Loss: 0.152456969023\n",
      "Epoch: 681,Discriminator Loss: 0.285409927368, Generator Loss: 0.000214459112613\n",
      "Epoch: 682,Discriminator Loss: -0.304592251778, Generator Loss: 0.67005854845\n",
      "Epoch: 683,Discriminator Loss: 0.189564347267, Generator Loss: 0.087421387434\n",
      "Epoch: 684,Discriminator Loss: -0.498541146517, Generator Loss: 0.868586242199\n",
      "Epoch: 685,Discriminator Loss: 0.0463350079954, Generator Loss: 0.363856554031\n",
      "Epoch: 686,Discriminator Loss: 0.5159984231, Generator Loss: 5.75736188889\n",
      "Epoch: 687,Discriminator Loss: 0.28855162859, Generator Loss: 0.195423573256\n",
      "Epoch: 688,Discriminator Loss: -0.401562154293, Generator Loss: 10.7683811188\n",
      "Epoch: 689,Discriminator Loss: 0.370132267475, Generator Loss: 0.0339302495122\n",
      "Epoch: 690,Discriminator Loss: -0.0217425711453, Generator Loss: 0.279910027981\n",
      "Epoch: 691,Discriminator Loss: 0.46377325058, Generator Loss: 0.0167101044208\n",
      "Epoch: 692,Discriminator Loss: 1.3801510334, Generator Loss: 0.00942893698812\n",
      "Epoch: 693,Discriminator Loss: 4.67494487762, Generator Loss: 0.0541662499309\n",
      "Epoch: 694,Discriminator Loss: 0.387353718281, Generator Loss: 0.0178205184639\n",
      "Epoch: 695,Discriminator Loss: 0.340711593628, Generator Loss: 0.0418270900846\n",
      "Epoch: 696,Discriminator Loss: -0.414035916328, Generator Loss: 4.81022405624\n",
      "Epoch: 697,Discriminator Loss: 1.12018847466, Generator Loss: 0.23703455925\n",
      "Epoch: 698,Discriminator Loss: 1.20023703575, Generator Loss: 0.0640986412764\n",
      "Epoch: 699,Discriminator Loss: 0.230045974255, Generator Loss: 1.88662943401e-05\n",
      "Epoch: 700,Discriminator Loss: 0.176911234856, Generator Loss: 0.0624210499227\n",
      "Epoch: 701,Discriminator Loss: 0.87089908123, Generator Loss: 0.0285769794136\n",
      "Epoch: 702,Discriminator Loss: 0.425090193748, Generator Loss: 0.680862009525\n",
      "Epoch: 703,Discriminator Loss: 0.72638553381, Generator Loss: 3.56899472536e-05\n",
      "Epoch: 704,Discriminator Loss: 1.40807080269, Generator Loss: 0.300026237965\n",
      "Epoch: 705,Discriminator Loss: -0.135448768735, Generator Loss: 4.19521903992\n",
      "Epoch: 706,Discriminator Loss: 0.388953208923, Generator Loss: 0.101528972387\n",
      "Epoch: 707,Discriminator Loss: 0.33302089572, Generator Loss: 0.0229268502444\n",
      "Epoch: 708,Discriminator Loss: 0.599481463432, Generator Loss: 0.427971720695\n",
      "Epoch: 709,Discriminator Loss: 0.705704689026, Generator Loss: 0.00820185150951\n",
      "Epoch: 710,Discriminator Loss: 0.794785261154, Generator Loss: 0.00183821818791\n",
      "Epoch: 711,Discriminator Loss: 0.400364816189, Generator Loss: 10.3483228683\n",
      "Epoch: 712,Discriminator Loss: 0.148161590099, Generator Loss: 0.0155360884964\n",
      "Epoch: 713,Discriminator Loss: 3.62283277512, Generator Loss: 0.0996491834521\n",
      "Epoch: 714,Discriminator Loss: -0.873548984528, Generator Loss: 11.512925148\n",
      "Epoch: 715,Discriminator Loss: 0.559880852699, Generator Loss: 0.114583924413\n",
      "Epoch: 716,Discriminator Loss: -0.216424867511, Generator Loss: 0.686838984489\n",
      "Epoch: 717,Discriminator Loss: 0.537155210972, Generator Loss: 0.0089489556849\n",
      "Epoch: 718,Discriminator Loss: 0.00700005888939, Generator Loss: 0.11522398144\n",
      "Epoch: 719,Discriminator Loss: 0.583488702774, Generator Loss: 0.0400516837835\n",
      "Epoch: 720,Discriminator Loss: -0.526361227036, Generator Loss: 4.6958527565\n",
      "Epoch: 721,Discriminator Loss: -0.180726155639, Generator Loss: 0.33438077569\n",
      "Epoch: 722,Discriminator Loss: -0.586867570877, Generator Loss: 11.512925148\n",
      "Epoch: 723,Discriminator Loss: 0.975070357323, Generator Loss: 0.116594597697\n",
      "Epoch: 724,Discriminator Loss: -0.27495315671, Generator Loss: 3.24103140831\n",
      "Epoch: 725,Discriminator Loss: 0.287652432919, Generator Loss: 0.116522267461\n",
      "Epoch: 726,Discriminator Loss: -0.189620614052, Generator Loss: 4.74567270279\n",
      "Epoch: 727,Discriminator Loss: 1.51165699959, Generator Loss: 0.000193153391592\n",
      "Epoch: 728,Discriminator Loss: -0.202508270741, Generator Loss: 0.320290148258\n",
      "Epoch: 729,Discriminator Loss: 3.33523035049, Generator Loss: 0.0601751767099\n",
      "Epoch: 730,Discriminator Loss: -0.083374120295, Generator Loss: 6.33721160889\n",
      "Epoch: 731,Discriminator Loss: 0.358427941799, Generator Loss: 0.0339227691293\n",
      "Epoch: 732,Discriminator Loss: 0.263504803181, Generator Loss: 0.198768436909\n",
      "Epoch: 733,Discriminator Loss: -0.00553165376186, Generator Loss: 4.76610088348\n",
      "Epoch: 734,Discriminator Loss: 0.391248136759, Generator Loss: 0.0306270308793\n",
      "Epoch: 735,Discriminator Loss: 0.483806341887, Generator Loss: 7.49702072144\n",
      "Epoch: 736,Discriminator Loss: -0.384321659803, Generator Loss: 0.646550655365\n",
      "Epoch: 737,Discriminator Loss: -0.756347954273, Generator Loss: 2.53947257996\n",
      "Epoch: 738,Discriminator Loss: 0.650744080544, Generator Loss: 0.00209482712671\n",
      "Epoch: 739,Discriminator Loss: 0.0267730113119, Generator Loss: 0.00328355305828\n",
      "Epoch: 740,Discriminator Loss: -0.893447101116, Generator Loss: 11.512925148\n",
      "Epoch: 741,Discriminator Loss: 0.104091882706, Generator Loss: 0.00291367643513\n",
      "Epoch: 742,Discriminator Loss: -0.189834207296, Generator Loss: 0.647711157799\n",
      "Epoch: 743,Discriminator Loss: 0.499636292458, Generator Loss: 0.0805775672197\n",
      "Epoch: 744,Discriminator Loss: 0.498226881027, Generator Loss: 0.0259341243654\n",
      "Epoch: 745,Discriminator Loss: -0.961212515831, Generator Loss: 11.512925148\n",
      "Epoch: 746,Discriminator Loss: 0.105349175632, Generator Loss: 1.21458864212\n",
      "Epoch: 747,Discriminator Loss: 2.18024992943, Generator Loss: 0.00773151172325\n",
      "Epoch: 748,Discriminator Loss: 0.188581138849, Generator Loss: 0.207297116518\n",
      "Epoch: 749,Discriminator Loss: -0.495638102293, Generator Loss: 10.1652297974\n",
      "Epoch: 750,Discriminator Loss: -0.0775412470102, Generator Loss: 0.213345244527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 751,Discriminator Loss: -0.668432414532, Generator Loss: 5.20353794098\n",
      "Epoch: 752,Discriminator Loss: 0.062703281641, Generator Loss: 0.00872201658785\n",
      "Epoch: 753,Discriminator Loss: 1.37400341034, Generator Loss: 0.430761426687\n",
      "Epoch: 754,Discriminator Loss: 0.309286266565, Generator Loss: 0.0263230316341\n",
      "Epoch: 755,Discriminator Loss: 0.735411524773, Generator Loss: 0.000458029971924\n",
      "Epoch: 756,Discriminator Loss: 0.328130453825, Generator Loss: 5.31982232133e-06\n",
      "Epoch: 757,Discriminator Loss: -0.371413946152, Generator Loss: 4.27179145813\n",
      "Epoch: 758,Discriminator Loss: 0.378003746271, Generator Loss: 0.000500327441841\n",
      "Epoch: 759,Discriminator Loss: 0.089689552784, Generator Loss: 0.0417612791061\n",
      "Epoch: 760,Discriminator Loss: 0.299541205168, Generator Loss: 0.0789649561048\n",
      "Epoch: 761,Discriminator Loss: 1.04476070404, Generator Loss: 0.316963851452\n",
      "Epoch: 762,Discriminator Loss: 0.650246441364, Generator Loss: 0.0210849512368\n",
      "Epoch: 763,Discriminator Loss: 0.815696299076, Generator Loss: 0.181628361344\n",
      "Epoch: 764,Discriminator Loss: -0.349771916866, Generator Loss: 9.33493804932\n",
      "Epoch: 765,Discriminator Loss: -0.25783675909, Generator Loss: 0.821886897087\n",
      "Epoch: 766,Discriminator Loss: 0.186799734831, Generator Loss: 0.00396109325811\n",
      "Epoch: 767,Discriminator Loss: 3.82500362396, Generator Loss: 0.000243015005253\n",
      "Epoch: 768,Discriminator Loss: 0.482605338097, Generator Loss: 0.0136694703251\n",
      "Epoch: 769,Discriminator Loss: -0.701830029488, Generator Loss: 6.16415309906\n",
      "Epoch: 770,Discriminator Loss: -0.799206256866, Generator Loss: 11.512925148\n",
      "Epoch: 771,Discriminator Loss: 0.728779911995, Generator Loss: 2.68319363386e-05\n",
      "Epoch: 772,Discriminator Loss: 0.284990102053, Generator Loss: 0.00378298363648\n",
      "Epoch: 773,Discriminator Loss: 2.38499593735, Generator Loss: 6.35585165583e-05\n",
      "Epoch: 774,Discriminator Loss: -0.218176200986, Generator Loss: 0.478554457426\n",
      "Epoch: 775,Discriminator Loss: 0.449731111526, Generator Loss: 0.0734420120716\n",
      "Epoch: 776,Discriminator Loss: 0.152900099754, Generator Loss: 0.0839100256562\n",
      "Epoch: 777,Discriminator Loss: 2.03959751129, Generator Loss: 0.00135906937066\n",
      "Epoch: 778,Discriminator Loss: -0.517034590244, Generator Loss: 6.16711521149\n",
      "Epoch: 779,Discriminator Loss: 0.160322770476, Generator Loss: 0.0785753577948\n",
      "Epoch: 780,Discriminator Loss: 0.273962646723, Generator Loss: 0.674885988235\n",
      "Epoch: 781,Discriminator Loss: 0.452444583178, Generator Loss: 0.00451044319198\n",
      "Epoch: 782,Discriminator Loss: 0.919371545315, Generator Loss: 0.0352206341922\n",
      "Epoch: 783,Discriminator Loss: 0.571064829826, Generator Loss: 0.00986986421049\n",
      "Epoch: 784,Discriminator Loss: 0.331021010876, Generator Loss: 0.290788888931\n",
      "Epoch: 785,Discriminator Loss: 1.02055597305, Generator Loss: 0.0669931620359\n",
      "Epoch: 786,Discriminator Loss: 0.689241111279, Generator Loss: 0.543391168118\n",
      "Epoch: 787,Discriminator Loss: 0.208365157247, Generator Loss: 0.201113253832\n",
      "Epoch: 788,Discriminator Loss: 0.778370380402, Generator Loss: 0.237579584122\n",
      "Epoch: 789,Discriminator Loss: 0.440578013659, Generator Loss: 0.00140887056477\n",
      "Epoch: 790,Discriminator Loss: 0.743120670319, Generator Loss: 0.159341841936\n",
      "Epoch: 791,Discriminator Loss: 1.70757472515, Generator Loss: 7.95602609287e-05\n",
      "Epoch: 792,Discriminator Loss: 0.103523090482, Generator Loss: 0.0187960863113\n",
      "Epoch: 793,Discriminator Loss: 0.0718648135662, Generator Loss: 0.12014336884\n",
      "Epoch: 794,Discriminator Loss: 0.287319719791, Generator Loss: 0.180330336094\n",
      "Epoch: 795,Discriminator Loss: -0.110880896449, Generator Loss: 0.616514921188\n",
      "Epoch: 796,Discriminator Loss: 0.360711425543, Generator Loss: 0.0562227889895\n",
      "Epoch: 797,Discriminator Loss: 0.186272621155, Generator Loss: 0.0961909592152\n",
      "Epoch: 798,Discriminator Loss: -0.00469056563452, Generator Loss: 0.01449141372\n",
      "Epoch: 799,Discriminator Loss: -0.26632630825, Generator Loss: 10.7841300964\n",
      "Epoch: 800,Discriminator Loss: 0.364373385906, Generator Loss: 0.0788221657276\n",
      "Epoch: 801,Discriminator Loss: -0.0601514428854, Generator Loss: 0.16950379312\n",
      "Epoch: 802,Discriminator Loss: 4.20283794403, Generator Loss: 0.15245193243\n",
      "Epoch: 803,Discriminator Loss: 0.236311241984, Generator Loss: 0.0654862672091\n",
      "Epoch: 804,Discriminator Loss: -0.232106626034, Generator Loss: 6.69321250916\n",
      "Epoch: 805,Discriminator Loss: 1.1297249794, Generator Loss: 0.00409289589152\n",
      "Epoch: 806,Discriminator Loss: 6.65325832367, Generator Loss: 0.00016946606047\n",
      "Epoch: 807,Discriminator Loss: 0.225239992142, Generator Loss: 0.043252825737\n",
      "Epoch: 808,Discriminator Loss: 0.0547239072621, Generator Loss: 0.00145409035031\n",
      "Epoch: 809,Discriminator Loss: -0.166200727224, Generator Loss: 0.327836215496\n",
      "Epoch: 810,Discriminator Loss: 0.316574037075, Generator Loss: 0.152786612511\n",
      "Epoch: 811,Discriminator Loss: 0.383902490139, Generator Loss: 0.238257721066\n",
      "Epoch: 812,Discriminator Loss: 0.245773553848, Generator Loss: 0.0314251706004\n",
      "Epoch: 813,Discriminator Loss: 0.254508405924, Generator Loss: 0.00290750944987\n",
      "Epoch: 814,Discriminator Loss: 1.07535171509, Generator Loss: 0.0366849415004\n",
      "Epoch: 815,Discriminator Loss: -0.827004373074, Generator Loss: 11.512925148\n",
      "Epoch: 816,Discriminator Loss: 0.602378845215, Generator Loss: 0.0576191209257\n",
      "Epoch: 817,Discriminator Loss: 0.244491800666, Generator Loss: 0.0638328567147\n",
      "Epoch: 818,Discriminator Loss: -0.13324084878, Generator Loss: 7.80980873108\n",
      "Epoch: 819,Discriminator Loss: -0.816504836082, Generator Loss: 9.08269405365\n",
      "Epoch: 820,Discriminator Loss: 1.41552257538, Generator Loss: 0.0257847979665\n",
      "Epoch: 821,Discriminator Loss: -0.0642514899373, Generator Loss: 0.299509942532\n",
      "Epoch: 822,Discriminator Loss: 3.69608473778, Generator Loss: 0.280108749866\n",
      "Epoch: 823,Discriminator Loss: 0.193334802985, Generator Loss: 0.502996683121\n",
      "Epoch: 824,Discriminator Loss: -0.190094172955, Generator Loss: 8.47563552856\n",
      "Epoch: 825,Discriminator Loss: 3.73578023911, Generator Loss: 0.105966337025\n",
      "Epoch: 826,Discriminator Loss: -0.858908295631, Generator Loss: 10.2203655243\n",
      "Epoch: 827,Discriminator Loss: -0.394848197699, Generator Loss: 0.664851903915\n",
      "Epoch: 828,Discriminator Loss: 2.63496041298, Generator Loss: 0.0773877501488\n",
      "Epoch: 829,Discriminator Loss: 3.39137148857, Generator Loss: 0.0142994727939\n",
      "Epoch: 830,Discriminator Loss: -0.646250486374, Generator Loss: 5.34673881531\n",
      "Epoch: 831,Discriminator Loss: -0.37264841795, Generator Loss: 0.776936590672\n",
      "Epoch: 832,Discriminator Loss: 0.264560163021, Generator Loss: 11.512925148\n",
      "Epoch: 833,Discriminator Loss: 0.71719622612, Generator Loss: 0.012436799705\n",
      "Epoch: 834,Discriminator Loss: -0.186787560582, Generator Loss: 5.44052600861\n",
      "Epoch: 835,Discriminator Loss: -0.0593358129263, Generator Loss: 10.6049499512\n",
      "Epoch: 836,Discriminator Loss: 0.657207250595, Generator Loss: 11.512925148\n",
      "Epoch: 837,Discriminator Loss: 0.370997309685, Generator Loss: 0.026681592688\n",
      "Epoch: 838,Discriminator Loss: 0.249490588903, Generator Loss: 8.64378929138\n",
      "Epoch: 839,Discriminator Loss: -0.158904120326, Generator Loss: 0.552086293697\n",
      "Epoch: 840,Discriminator Loss: 0.383687585592, Generator Loss: 0.0243474841118\n",
      "Epoch: 841,Discriminator Loss: -0.471366167068, Generator Loss: 3.64007782936\n",
      "Epoch: 842,Discriminator Loss: -0.025725223124, Generator Loss: 3.48893618584\n",
      "Epoch: 843,Discriminator Loss: 0.301911979914, Generator Loss: 0.175163060427\n",
      "Epoch: 844,Discriminator Loss: 0.419514745474, Generator Loss: 0.0547799095511\n",
      "Epoch: 845,Discriminator Loss: -0.0839928239584, Generator Loss: 0.557836949825\n",
      "Epoch: 846,Discriminator Loss: -0.563179135323, Generator Loss: 11.512925148\n",
      "Epoch: 847,Discriminator Loss: 0.270948559046, Generator Loss: 0.252023130655\n",
      "Epoch: 848,Discriminator Loss: -0.826707243919, Generator Loss: 9.11440849304\n",
      "Epoch: 849,Discriminator Loss: -0.0417944863439, Generator Loss: 3.6239528656\n",
      "Epoch: 850,Discriminator Loss: -0.841809272766, Generator Loss: 11.512925148\n",
      "Epoch: 851,Discriminator Loss: 0.465490221977, Generator Loss: 0.000289556570351\n",
      "Epoch: 852,Discriminator Loss: 0.262509435415, Generator Loss: 0.137063607574\n",
      "Epoch: 853,Discriminator Loss: 0.765620052814, Generator Loss: 0.144823670387\n",
      "Epoch: 854,Discriminator Loss: 0.370178818703, Generator Loss: 0.686838984489\n",
      "Epoch: 855,Discriminator Loss: -0.421273857355, Generator Loss: 6.30776405334\n",
      "Epoch: 856,Discriminator Loss: -0.517951905727, Generator Loss: 2.33749675751\n",
      "Epoch: 857,Discriminator Loss: 0.131077706814, Generator Loss: 0.0443899929523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 858,Discriminator Loss: 0.0800305232406, Generator Loss: 0.163774251938\n",
      "Epoch: 859,Discriminator Loss: 0.649021744728, Generator Loss: 0.573048233986\n",
      "Epoch: 860,Discriminator Loss: 0.108807049692, Generator Loss: 0.221668332815\n",
      "Epoch: 861,Discriminator Loss: -0.530497014523, Generator Loss: 6.21257305145\n",
      "Epoch: 862,Discriminator Loss: -0.810575485229, Generator Loss: 6.66986465454\n",
      "Epoch: 863,Discriminator Loss: -0.828205704689, Generator Loss: 7.69912719727\n",
      "Epoch: 864,Discriminator Loss: 0.147654294968, Generator Loss: 0.343994110823\n",
      "Epoch: 865,Discriminator Loss: 0.324064135551, Generator Loss: 0.00038850918645\n",
      "Epoch: 866,Discriminator Loss: -0.382114708424, Generator Loss: 1.13246428967\n",
      "Epoch: 867,Discriminator Loss: -0.443725407124, Generator Loss: 5.37438678741\n",
      "Epoch: 868,Discriminator Loss: 0.414129853249, Generator Loss: 0.0213371980935\n",
      "Epoch: 869,Discriminator Loss: 0.923392772675, Generator Loss: 0.474047899246\n",
      "Epoch: 870,Discriminator Loss: 0.505004525185, Generator Loss: 1.68798160553\n",
      "Epoch: 871,Discriminator Loss: 0.124226808548, Generator Loss: 0.173086047173\n",
      "Epoch: 872,Discriminator Loss: 0.0433118008077, Generator Loss: 0.467017918825\n",
      "Epoch: 873,Discriminator Loss: 0.0233148671687, Generator Loss: 0.179729223251\n",
      "Epoch: 874,Discriminator Loss: -0.374131202698, Generator Loss: 2.05724072456\n",
      "Epoch: 875,Discriminator Loss: -0.590622544289, Generator Loss: 11.512925148\n",
      "Epoch: 876,Discriminator Loss: -0.715841531754, Generator Loss: 10.5836849213\n",
      "Epoch: 877,Discriminator Loss: 0.00193357467651, Generator Loss: 5.16579627991\n",
      "Epoch: 878,Discriminator Loss: 0.195207834244, Generator Loss: 0.0421803183854\n",
      "Epoch: 879,Discriminator Loss: 0.397900044918, Generator Loss: 0.0498080775142\n",
      "Epoch: 880,Discriminator Loss: -0.119111269712, Generator Loss: 5.76389408112\n",
      "Epoch: 881,Discriminator Loss: 0.556183457375, Generator Loss: 0.335824668407\n",
      "Epoch: 882,Discriminator Loss: -0.336425632238, Generator Loss: 5.98136711121\n",
      "Epoch: 883,Discriminator Loss: 0.111064091325, Generator Loss: 6.05929136276\n",
      "Epoch: 884,Discriminator Loss: 0.365684270859, Generator Loss: 0.573257267475\n",
      "Epoch: 885,Discriminator Loss: 0.405185997486, Generator Loss: 0.0826804414392\n",
      "Epoch: 886,Discriminator Loss: 0.196368083358, Generator Loss: 0.648285448551\n",
      "Epoch: 887,Discriminator Loss: 0.603230953217, Generator Loss: 0.00256500206888\n",
      "Epoch: 888,Discriminator Loss: 0.159461438656, Generator Loss: 0.0192214287817\n",
      "Epoch: 889,Discriminator Loss: 0.539501368999, Generator Loss: 0.000166576559423\n",
      "Epoch: 890,Discriminator Loss: -0.627441644669, Generator Loss: 6.43329143524\n",
      "Epoch: 891,Discriminator Loss: 0.147134974599, Generator Loss: 9.80919212452e-05\n",
      "Epoch: 892,Discriminator Loss: 0.0763756781816, Generator Loss: 0.152023613453\n",
      "Epoch: 893,Discriminator Loss: 0.0980391576886, Generator Loss: 0.389456421137\n",
      "Epoch: 894,Discriminator Loss: 0.0669673383236, Generator Loss: 0.00285451184027\n",
      "Epoch: 895,Discriminator Loss: 0.880627274513, Generator Loss: 0.0434607416391\n",
      "Epoch: 896,Discriminator Loss: 0.406797170639, Generator Loss: 0.11072434485\n",
      "Epoch: 897,Discriminator Loss: 0.602762401104, Generator Loss: 0.0316871777177\n",
      "Epoch: 898,Discriminator Loss: 0.190999776125, Generator Loss: 0.32849919796\n",
      "Epoch: 899,Discriminator Loss: 0.456615418196, Generator Loss: 0.289652377367\n",
      "Epoch: 900,Discriminator Loss: 0.197254657745, Generator Loss: 0.00105916755274\n",
      "Epoch: 901,Discriminator Loss: 0.56283557415, Generator Loss: 0.0697890520096\n",
      "Epoch: 902,Discriminator Loss: -0.236478954554, Generator Loss: 0.782806396484\n",
      "Epoch: 903,Discriminator Loss: 0.393192946911, Generator Loss: 0.0954595655203\n",
      "Epoch: 904,Discriminator Loss: 0.188746243715, Generator Loss: 0.0342869050801\n",
      "Epoch: 905,Discriminator Loss: 0.628005743027, Generator Loss: 8.27001349535e-05\n",
      "Epoch: 906,Discriminator Loss: 0.367920547724, Generator Loss: 0.0795230939984\n",
      "Epoch: 907,Discriminator Loss: 0.122215732932, Generator Loss: 0.0721017643809\n",
      "Epoch: 908,Discriminator Loss: 0.759692430496, Generator Loss: 0.0850753337145\n",
      "Epoch: 909,Discriminator Loss: 0.842898547649, Generator Loss: 0.18928770721\n",
      "Epoch: 910,Discriminator Loss: 1.31427824497, Generator Loss: 0.11782053858\n",
      "Epoch: 911,Discriminator Loss: -0.224485382438, Generator Loss: 8.96507644653\n",
      "Epoch: 912,Discriminator Loss: 0.307803928852, Generator Loss: 0.00661792280152\n",
      "Epoch: 913,Discriminator Loss: 0.392305016518, Generator Loss: 0.0206317380071\n",
      "Epoch: 914,Discriminator Loss: 0.244653224945, Generator Loss: 1.91935614566e-05\n",
      "Epoch: 915,Discriminator Loss: 0.452091932297, Generator Loss: 0.0153888454661\n",
      "Epoch: 916,Discriminator Loss: -0.0870171040297, Generator Loss: 1.1462007761\n",
      "Epoch: 917,Discriminator Loss: 0.223084568977, Generator Loss: 0.0081031518057\n",
      "Epoch: 918,Discriminator Loss: 0.233191415668, Generator Loss: 0.0941268652678\n",
      "Epoch: 919,Discriminator Loss: -0.0846765711904, Generator Loss: 0.188170164824\n",
      "Epoch: 920,Discriminator Loss: 0.0267320424318, Generator Loss: 6.71451377869\n",
      "Epoch: 921,Discriminator Loss: 0.21312455833, Generator Loss: 0.287294715643\n",
      "Epoch: 922,Discriminator Loss: -0.159257873893, Generator Loss: 6.08098173141\n",
      "Epoch: 923,Discriminator Loss: 1.32655620575, Generator Loss: 0.00916307140142\n",
      "Epoch: 924,Discriminator Loss: 0.0302475076169, Generator Loss: 0.0421808101237\n",
      "Epoch: 925,Discriminator Loss: 1.03626489639, Generator Loss: 0.229940503836\n",
      "Epoch: 926,Discriminator Loss: -0.104816332459, Generator Loss: 6.00875663757\n",
      "Epoch: 927,Discriminator Loss: -0.119061402977, Generator Loss: 10.8348340988\n",
      "Epoch: 928,Discriminator Loss: 0.173208892345, Generator Loss: 1.34111166972e-06\n",
      "Epoch: 929,Discriminator Loss: -0.488494873047, Generator Loss: 5.76330375671\n",
      "Epoch: 930,Discriminator Loss: -0.345484167337, Generator Loss: 0.686838984489\n",
      "Epoch: 931,Discriminator Loss: 1.52486729622, Generator Loss: 0.0248380247504\n",
      "Epoch: 932,Discriminator Loss: -0.0406531244516, Generator Loss: 5.27639722824\n",
      "Epoch: 933,Discriminator Loss: 1.00101327896, Generator Loss: 5.05155821884e-06\n",
      "Epoch: 934,Discriminator Loss: -0.0863287448883, Generator Loss: 1.82836806774\n",
      "Epoch: 935,Discriminator Loss: 1.61860871315, Generator Loss: 9.94202613831\n",
      "Epoch: 936,Discriminator Loss: 0.580920159817, Generator Loss: 0.0659015774727\n",
      "Epoch: 937,Discriminator Loss: 0.438737213612, Generator Loss: 0.315637797117\n",
      "Epoch: 938,Discriminator Loss: 0.190035551786, Generator Loss: 0.157537400723\n",
      "Epoch: 939,Discriminator Loss: 0.617400944233, Generator Loss: 6.02100515366\n",
      "Epoch: 940,Discriminator Loss: 1.35669183731, Generator Loss: 0.490747749805\n",
      "Epoch: 941,Discriminator Loss: 0.164153039455, Generator Loss: 7.0334672273e-06\n",
      "Epoch: 942,Discriminator Loss: 0.177350565791, Generator Loss: 0.00505200074986\n",
      "Epoch: 943,Discriminator Loss: -0.434038937092, Generator Loss: 0.630459189415\n",
      "Epoch: 944,Discriminator Loss: 2.62879943848, Generator Loss: 11.512925148\n",
      "Epoch: 945,Discriminator Loss: 0.0216651260853, Generator Loss: 6.32598114014\n",
      "Epoch: 946,Discriminator Loss: 1.54915058613, Generator Loss: 0.705591082573\n",
      "Epoch: 947,Discriminator Loss: -0.171387672424, Generator Loss: 5.04551029205\n",
      "Epoch: 948,Discriminator Loss: 6.36944675446, Generator Loss: 1.68839907646\n",
      "Epoch: 949,Discriminator Loss: 0.565353751183, Generator Loss: 0.0775178894401\n",
      "Epoch: 950,Discriminator Loss: 0.37050807476, Generator Loss: 0.00934461317956\n",
      "Epoch: 951,Discriminator Loss: 0.347031414509, Generator Loss: 3.50347763742e-05\n",
      "Epoch: 952,Discriminator Loss: 0.18897254765, Generator Loss: 0.00373362679966\n",
      "Epoch: 953,Discriminator Loss: 0.183252871037, Generator Loss: 0.00266420422122\n",
      "Epoch: 954,Discriminator Loss: 1.16612195969, Generator Loss: 6.92849111557\n",
      "Epoch: 955,Discriminator Loss: 1.11764538288, Generator Loss: 0.0279144197702\n",
      "Epoch: 956,Discriminator Loss: 0.848670363426, Generator Loss: 3.57628380243e-07\n",
      "Epoch: 957,Discriminator Loss: -0.28181412816, Generator Loss: 0.966911911964\n",
      "Epoch: 958,Discriminator Loss: 0.58012008667, Generator Loss: 0.0135879712179\n",
      "Epoch: 959,Discriminator Loss: 0.139221832156, Generator Loss: 0.1309928298\n",
      "Epoch: 960,Discriminator Loss: 0.753193974495, Generator Loss: 0.0916647613049\n",
      "Epoch: 961,Discriminator Loss: 1.60329341888, Generator Loss: 9.28459739685\n",
      "Epoch: 962,Discriminator Loss: 0.431713759899, Generator Loss: 4.75134897232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 963,Discriminator Loss: -0.240363270044, Generator Loss: 0.686682641506\n",
      "Epoch: 964,Discriminator Loss: 3.83853507042, Generator Loss: 1.00894629955\n",
      "Epoch: 965,Discriminator Loss: -0.760938644409, Generator Loss: 7.43253040314\n",
      "Epoch: 966,Discriminator Loss: 0.235027879477, Generator Loss: 0.0\n",
      "Epoch: 967,Discriminator Loss: -0.271387934685, Generator Loss: 2.91525506973\n",
      "Epoch: 968,Discriminator Loss: 0.0567469187081, Generator Loss: 0.00849473662674\n",
      "Epoch: 969,Discriminator Loss: -0.913118243217, Generator Loss: 6.49866962433\n",
      "Epoch: 970,Discriminator Loss: -0.297259271145, Generator Loss: 2.56818890572\n",
      "Epoch: 971,Discriminator Loss: 0.352289110422, Generator Loss: 5.29925727844\n",
      "Epoch: 972,Discriminator Loss: -0.495901286602, Generator Loss: 0.832511007786\n",
      "Epoch: 973,Discriminator Loss: 2.13132953644, Generator Loss: 0.00499351834878\n",
      "Epoch: 974,Discriminator Loss: 0.675129413605, Generator Loss: 0.100551962852\n",
      "Epoch: 975,Discriminator Loss: -0.90173047781, Generator Loss: 8.57470321655\n",
      "Epoch: 976,Discriminator Loss: 0.0282318089157, Generator Loss: 0.0\n",
      "Epoch: 977,Discriminator Loss: 0.400458365679, Generator Loss: 0.0881901830435\n",
      "Epoch: 978,Discriminator Loss: -0.855842471123, Generator Loss: 11.512925148\n",
      "Epoch: 979,Discriminator Loss: 0.0795018970966, Generator Loss: 0.188958793879\n",
      "Epoch: 980,Discriminator Loss: 0.119000785053, Generator Loss: 0.0\n",
      "Epoch: 981,Discriminator Loss: 0.537053525448, Generator Loss: 0.0144504979253\n",
      "Epoch: 982,Discriminator Loss: -0.362316608429, Generator Loss: 2.10884690285\n",
      "Epoch: 983,Discriminator Loss: -0.490512549877, Generator Loss: 11.512925148\n",
      "Epoch: 984,Discriminator Loss: 0.0500854328275, Generator Loss: 0.758097231388\n",
      "Epoch: 985,Discriminator Loss: -0.138668850064, Generator Loss: 0.826910197735\n",
      "Epoch: 986,Discriminator Loss: -0.732630908489, Generator Loss: 10.2698640823\n",
      "Epoch: 987,Discriminator Loss: -0.235094204545, Generator Loss: 0.671402037144\n",
      "Epoch: 988,Discriminator Loss: 0.283121585846, Generator Loss: 0.00270742224529\n",
      "Epoch: 989,Discriminator Loss: -0.380680978298, Generator Loss: 5.70899868011\n",
      "Epoch: 990,Discriminator Loss: 0.550008714199, Generator Loss: 1.9596047423e-05\n",
      "Epoch: 991,Discriminator Loss: 0.389697104692, Generator Loss: 0.0489892736077\n",
      "Epoch: 992,Discriminator Loss: 1.65169978142, Generator Loss: 0.119784906507\n",
      "Epoch: 993,Discriminator Loss: -0.367805421352, Generator Loss: 0.613496899605\n",
      "Epoch: 994,Discriminator Loss: 0.0353000313044, Generator Loss: 3.83489727974\n",
      "Epoch: 995,Discriminator Loss: 0.0473011694849, Generator Loss: 0.107438877225\n",
      "Epoch: 996,Discriminator Loss: -0.164807349443, Generator Loss: 5.82863235474\n",
      "Epoch: 997,Discriminator Loss: -0.439758747816, Generator Loss: 9.33191490173\n",
      "Epoch: 998,Discriminator Loss: 0.136866509914, Generator Loss: 0.424317598343\n",
      "Epoch: 999,Discriminator Loss: 3.95931959152, Generator Loss: 2.08617143471e-06\n"
     ]
    }
   ],
   "source": [
    "optimize(epoch,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result():\n",
    "    real_data = pd.Series(gen_data_sample(1000).ravel())\n",
    "    generated_data = pd.Series( session.run(g_output,{x_g: gen_noise_sample(1000)}).ravel())\n",
    "    real_data.plot(kind = \"density\", label = \"real data\")\n",
    "    generated_data.plot(kind = \"density\", label = \"generated data\")\n",
    "    noise = pd.Series(gen_noise_sample(1000).ravel())\n",
    "    noise.plot(kind = \"density\", label = \"input noise\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6d4d650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

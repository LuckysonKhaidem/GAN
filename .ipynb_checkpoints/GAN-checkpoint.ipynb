{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "#Distribution of the training data\n",
    "class DataDistribution:\n",
    "    def __init__(self,mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "    def samples(self, N):\n",
    "        return np.random.normal(self.mu, self.sigma,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data_distribution():\n",
    "    distribution = DataDistribution(4,0.5)\n",
    "    samples = distribution.samples(1000)\n",
    "    samples = pd.Series(samples)\n",
    "    samples.plot(kind=\"density\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMaaHJQVjjDE9LCkYY4zpYUnBGGNMj/8P5BRmNYtMYnIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b688150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots the density curve of the training data that the generator tries to estimate\n",
    "plot_data_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Noisy signal which serves as an input to the generator\n",
    "class GeneratorNoiseDistribution:\n",
    "    def __init__(self,limit):\n",
    "        self.limit = limit\n",
    "    def sample_noise(self,N):\n",
    "        return np.linspace(-self.limit, self.limit,N) + np.random.random() * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_noise_distribution():\n",
    "    distribution = GeneratorNoiseDistribution(8)\n",
    "    samples = distribution.sample_noise(1000)\n",
    "    samples = pd.Series(samples)\n",
    "    samples.plot(kind = \"density\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVDBERCQhKhgiIpIQFQwREUnI/wd/UbVkUgWPagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1200320d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_noise_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def new_weights(self, shape, name):\n",
    "        return tf.Variable(tf.truncated_normal(shape, stddev = 1.0), name = name)\n",
    "    def new_biases(self, length, name):\n",
    "        return tf.Variable(tf.constant(0.0, shape = [length]), name = name)\n",
    "    def linear(self, data_input,weights, biases):\n",
    "        return tf.matmul(data_input, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self,num_input_neurons,num_hidden_neurons,num_output_neurons):\n",
    "        self.num_input_neurons = num_input_neurons\n",
    "        self.num_hidden_neurons = num_hidden_neurons\n",
    "        self.num_output_neurons = num_output_neurons\n",
    "    def get_output(self,x):\n",
    "        w1 = self.new_weights([self.num_input_neurons,self.num_hidden_neurons],\"w1\")\n",
    "        b1 = self.new_biases(self.num_hidden_neurons,\"b1\")\n",
    "        w2 = self.new_weights([self.num_hidden_neurons, self.num_output_neurons],\"w2\")\n",
    "        b2 = self.new_biases(self.num_output_neurons,\"b2\")   \n",
    "        layer_1 = tf.nn.softplus(self.linear(x, w1, b1))\n",
    "        layer_2 = self.linear(layer_1,w2,b2)\n",
    "        return layer_2              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self,num_input_neurons,num_hidden_neurons,num_output_neurons):\n",
    "        self.num_input_neurons = num_input_neurons\n",
    "        self.num_hidden_neurons = num_hidden_neurons\n",
    "        self.num_output_neurons = num_output_neurons\n",
    "    def get_output(self,x):\n",
    "        w1 = self.new_weights([self.num_input_neurons,self.num_hidden_neurons],\"w1\")\n",
    "        b1 = self.new_biases(self.num_hidden_neurons,\"b1\")\n",
    "        w2 = self.new_weights([self.num_hidden_neurons, self.num_hidden_neurons],\"w2\")\n",
    "        b2 = self.new_biases(self.num_hidden_neurons,\"b2\")\n",
    "        w3 = self.new_weights([self.num_hidden_neurons, self.num_hidden_neurons],\"w3\")\n",
    "        b3 = self.new_biases(self.num_hidden_neurons,\"b3\")\n",
    "        w4 = self.new_weights([self.num_hidden_neurons, self.num_output_neurons],\"w4\")\n",
    "        b4 = self.new_biases(self.num_output_neurons,\"b4\")\n",
    "        layer_1 = tf.nn.relu(self.linear(x, w1, b1))\n",
    "        layer_2 = tf.nn.relu(self.linear(layer_1,w2,b2))\n",
    "        layer_3 = tf.nn.relu(self.linear(layer_2,w3,b3))\n",
    "        layer_4 = tf.sigmoid(self.linear(layer_3,w4,b4))\n",
    "        return layer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return tf.log(tf.maximum(x,1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = Generator(1,8,1)\n",
    "D = Discriminator(1,8,1)\n",
    "x_d = tf.placeholder(tf.float32, [None,1])\n",
    "x_g = tf.placeholder(tf.float32, [None,1])\n",
    "g_output = G.get_output(x_g)\n",
    "d1 = D.get_output(x_d)\n",
    "d2 = D.get_output(g_output)\n",
    "loss_d = tf.reduce_mean(-log(d1) - (1 - d2))\n",
    "loss_g = tf.reduce_mean(-log(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.05\n",
    "decay = 0.95\n",
    "num_decay_steps = 1000\n",
    "global_step = tf.Variable(0, trainable = True)\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate,global_step,num_decay_steps, decay, staircase = True)\n",
    "train_d = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_d)\n",
    "train_g = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data_sample(batch_size):\n",
    "    return DataDistribution(0,1).samples(batch_size).reshape((-1,1))\n",
    "def gen_noise_sample(batch_size):\n",
    "    return GeneratorNoiseDistribution(8).sample_noise(batch_size).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "batch_size = 8\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-521fab3ab0dc>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-521fab3ab0dc>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    if i % 100 = 0:\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def optimize(epoch, batch_size):\n",
    "    for i in xrange(epoch):\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        d_input = gen_data_sample(batch_size)\n",
    "        z_noise = gen_noise_sample(batch_size)\n",
    "       \n",
    "        session.run(train_d, { x_d: d_input,\n",
    "                                   x_g: z_noise})\n",
    "        z_noise = gen_noise_sample(batch_size)\n",
    "        session.run(train_g, {x_g: z_noise})\n",
    "        loss_discriminator, loss_generator = session.run([loss_d, loss_g], {\n",
    "                                                x_d: d_input,\n",
    "                                                x_g: z_noise})\n",
    "        if i % 100 == 0:\n",
    "            print \"Step: {},Discriminator Loss: {}, Generator Loss: {}\".format(i, loss_discriminator, loss_generator)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,Discriminator Loss: -0.103443942964, Generator Loss: 0.47323474288\n",
      "Epoch: 1,Discriminator Loss: 0.826062619686, Generator Loss: 0.00231499806978\n",
      "Epoch: 2,Discriminator Loss: 8.68288516998, Generator Loss: 0.318146795034\n",
      "Epoch: 3,Discriminator Loss: 0.160373985767, Generator Loss: 1.49011668782e-07\n",
      "Epoch: 4,Discriminator Loss: 0.100334972143, Generator Loss: 0.0581748597324\n",
      "Epoch: 5,Discriminator Loss: 0.0410004928708, Generator Loss: 0.0161449573934\n",
      "Epoch: 6,Discriminator Loss: 0.430436432362, Generator Loss: 0.0853071957827\n",
      "Epoch: 7,Discriminator Loss: 1.32215774059, Generator Loss: 1.39480680446e-05\n",
      "Epoch: 8,Discriminator Loss: 0.418759167194, Generator Loss: 0.23075646162\n",
      "Epoch: 9,Discriminator Loss: 0.634169280529, Generator Loss: 3.20539808273\n",
      "Epoch: 10,Discriminator Loss: 0.136435344815, Generator Loss: 0.266071349382\n",
      "Epoch: 11,Discriminator Loss: -0.302047163248, Generator Loss: 0.545399069786\n",
      "Epoch: 12,Discriminator Loss: -0.582368373871, Generator Loss: 1.89215731621\n",
      "Epoch: 13,Discriminator Loss: 0.493572741747, Generator Loss: 0.00629770802334\n",
      "Epoch: 14,Discriminator Loss: 0.92381131649, Generator Loss: 0.000132348242914\n",
      "Epoch: 15,Discriminator Loss: 0.415827155113, Generator Loss: 0.0502451583743\n",
      "Epoch: 16,Discriminator Loss: 2.60401415825, Generator Loss: 0.00295469234698\n",
      "Epoch: 17,Discriminator Loss: 1.13258492947, Generator Loss: 0.689029991627\n",
      "Epoch: 18,Discriminator Loss: -0.303862273693, Generator Loss: 4.0253367424\n",
      "Epoch: 19,Discriminator Loss: 1.80209636688, Generator Loss: 10.2850236893\n",
      "Epoch: 20,Discriminator Loss: 0.633334338665, Generator Loss: 0.343121707439\n",
      "Epoch: 21,Discriminator Loss: 0.47248929739, Generator Loss: 0.0954402387142\n",
      "Epoch: 22,Discriminator Loss: 0.473799020052, Generator Loss: 1.62423691563e-06\n",
      "Epoch: 23,Discriminator Loss: -0.464480578899, Generator Loss: 6.130900383\n",
      "Epoch: 24,Discriminator Loss: 0.163274437189, Generator Loss: 5.32347548869e-05\n",
      "Epoch: 25,Discriminator Loss: 0.197089001536, Generator Loss: 0.163148134947\n",
      "Epoch: 26,Discriminator Loss: 0.469634473324, Generator Loss: 0.000386492203688\n",
      "Epoch: 27,Discriminator Loss: 0.465473562479, Generator Loss: 0.133452787995\n",
      "Epoch: 28,Discriminator Loss: -0.19020485878, Generator Loss: 0.909085273743\n",
      "Epoch: 29,Discriminator Loss: 0.755296230316, Generator Loss: 1.61849880219\n",
      "Epoch: 30,Discriminator Loss: 0.134851157665, Generator Loss: 11.1962490082\n",
      "Epoch: 31,Discriminator Loss: 1.77214968204, Generator Loss: 0.152272939682\n",
      "Epoch: 32,Discriminator Loss: -0.00522899068892, Generator Loss: 0.287677228451\n",
      "Epoch: 33,Discriminator Loss: -0.310603886843, Generator Loss: 6.46741199493\n",
      "Epoch: 34,Discriminator Loss: -0.104111306369, Generator Loss: 0.686838984489\n",
      "Epoch: 35,Discriminator Loss: 0.0158351361752, Generator Loss: 0.689165830612\n",
      "Epoch: 36,Discriminator Loss: 1.37102675438, Generator Loss: 0.00247655482963\n",
      "Epoch: 37,Discriminator Loss: -0.473607182503, Generator Loss: 1.97237098217\n",
      "Epoch: 38,Discriminator Loss: -0.176759213209, Generator Loss: 11.512925148\n",
      "Epoch: 39,Discriminator Loss: 0.495939165354, Generator Loss: 3.85795354843\n",
      "Epoch: 40,Discriminator Loss: 0.088789537549, Generator Loss: 0.451576173306\n",
      "Epoch: 41,Discriminator Loss: -0.387851029634, Generator Loss: 2.69804334641\n",
      "Epoch: 42,Discriminator Loss: 0.411322057247, Generator Loss: 0.635696530342\n",
      "Epoch: 43,Discriminator Loss: 2.30080938339, Generator Loss: 5.87852287292\n",
      "Epoch: 44,Discriminator Loss: 0.371051967144, Generator Loss: 0.0315416529775\n",
      "Epoch: 45,Discriminator Loss: -0.783580064774, Generator Loss: 10.1801156998\n",
      "Epoch: 46,Discriminator Loss: 0.167572557926, Generator Loss: 2.11937046051\n",
      "Epoch: 47,Discriminator Loss: 0.382182568312, Generator Loss: 0.0447302535176\n",
      "Epoch: 48,Discriminator Loss: -0.258433640003, Generator Loss: 0.605732858181\n",
      "Epoch: 49,Discriminator Loss: 1.45656251907, Generator Loss: 6.48697948456\n",
      "Epoch: 50,Discriminator Loss: 0.0755461156368, Generator Loss: 0.630216479301\n",
      "Epoch: 51,Discriminator Loss: 1.29706048965, Generator Loss: 0.105388656259\n",
      "Epoch: 52,Discriminator Loss: -0.456023663282, Generator Loss: 11.512925148\n",
      "Epoch: 53,Discriminator Loss: 0.300169974566, Generator Loss: 0.0444239526987\n",
      "Epoch: 54,Discriminator Loss: 1.00259041786, Generator Loss: 0.025339173153\n",
      "Epoch: 55,Discriminator Loss: 0.833538353443, Generator Loss: 0.336887866259\n",
      "Epoch: 56,Discriminator Loss: 1.83809804916, Generator Loss: 0.0665758103132\n",
      "Epoch: 57,Discriminator Loss: 0.243966192007, Generator Loss: 0.0176661610603\n",
      "Epoch: 58,Discriminator Loss: -0.544885516167, Generator Loss: 8.16072273254\n",
      "Epoch: 59,Discriminator Loss: 1.1143296957, Generator Loss: 0.242198973894\n",
      "Epoch: 60,Discriminator Loss: 0.635274410248, Generator Loss: 0.0376100763679\n",
      "Epoch: 61,Discriminator Loss: 0.649603664875, Generator Loss: 0.0506381653249\n",
      "Epoch: 62,Discriminator Loss: -0.351108491421, Generator Loss: 5.14212036133\n",
      "Epoch: 63,Discriminator Loss: 0.090332955122, Generator Loss: 0.00100933201611\n",
      "Epoch: 64,Discriminator Loss: 0.184187144041, Generator Loss: 0.0112630967051\n",
      "Epoch: 65,Discriminator Loss: 0.303034126759, Generator Loss: 0.000184182601515\n",
      "Epoch: 66,Discriminator Loss: 0.577565491199, Generator Loss: 0.0620776340365\n",
      "Epoch: 67,Discriminator Loss: 0.438142359257, Generator Loss: 0.000525860290509\n",
      "Epoch: 68,Discriminator Loss: 0.160905063152, Generator Loss: 0.00302668800578\n",
      "Epoch: 69,Discriminator Loss: 0.576233386993, Generator Loss: 0.0578500181437\n",
      "Epoch: 70,Discriminator Loss: 0.160503670573, Generator Loss: 0.000423770630732\n",
      "Epoch: 71,Discriminator Loss: 1.14657998085, Generator Loss: 0.706279993057\n",
      "Epoch: 72,Discriminator Loss: 0.0627489760518, Generator Loss: 0.457342803478\n",
      "Epoch: 73,Discriminator Loss: 0.521800518036, Generator Loss: 0.0186653770506\n",
      "Epoch: 74,Discriminator Loss: 0.175706267357, Generator Loss: 0.101698592305\n",
      "Epoch: 75,Discriminator Loss: -0.494902014732, Generator Loss: 5.13930273056\n",
      "Epoch: 76,Discriminator Loss: -0.8367882967, Generator Loss: 5.0025100708\n",
      "Epoch: 77,Discriminator Loss: 0.878018260002, Generator Loss: 0.0076905679889\n",
      "Epoch: 78,Discriminator Loss: 3.31615900993, Generator Loss: 0.102969959378\n",
      "Epoch: 79,Discriminator Loss: -0.0972403734922, Generator Loss: 0.605590939522\n",
      "Epoch: 80,Discriminator Loss: 0.207474738359, Generator Loss: 1.66946136951\n",
      "Epoch: 81,Discriminator Loss: -0.920021653175, Generator Loss: 8.94862651825\n",
      "Epoch: 82,Discriminator Loss: 0.115858830512, Generator Loss: 4.53822231293\n",
      "Epoch: 83,Discriminator Loss: 0.0624538511038, Generator Loss: 0.0350303798914\n",
      "Epoch: 84,Discriminator Loss: 0.305084466934, Generator Loss: 10.7795848846\n",
      "Epoch: 85,Discriminator Loss: -0.757232189178, Generator Loss: 5.44511842728\n",
      "Epoch: 86,Discriminator Loss: 1.37220263481, Generator Loss: 10.6337814331\n",
      "Epoch: 87,Discriminator Loss: 0.987229526043, Generator Loss: 0.0105618285015\n",
      "Epoch: 88,Discriminator Loss: 0.553887844086, Generator Loss: 0.0\n",
      "Epoch: 89,Discriminator Loss: -0.396883606911, Generator Loss: 1.26364576817\n",
      "Epoch: 90,Discriminator Loss: 0.900874972343, Generator Loss: 0.0354668349028\n",
      "Epoch: 91,Discriminator Loss: -0.727840065956, Generator Loss: 11.512925148\n",
      "Epoch: 92,Discriminator Loss: 0.456612735987, Generator Loss: 8.41046524048\n",
      "Epoch: 93,Discriminator Loss: 0.493969559669, Generator Loss: 0.00087822356727\n",
      "Epoch: 94,Discriminator Loss: -0.311322808266, Generator Loss: 4.24189805984\n",
      "Epoch: 95,Discriminator Loss: -0.230056375265, Generator Loss: 11.4525527954\n",
      "Epoch: 96,Discriminator Loss: 0.21578656137, Generator Loss: 0.223602429032\n",
      "Epoch: 97,Discriminator Loss: 0.514514565468, Generator Loss: 0.0722378492355\n",
      "Epoch: 98,Discriminator Loss: 0.229635179043, Generator Loss: 0.00424036337063\n",
      "Epoch: 99,Discriminator Loss: 0.371941536665, Generator Loss: 0.923771381378\n",
      "Epoch: 100,Discriminator Loss: 0.209404557943, Generator Loss: 0.00109645840712\n",
      "Epoch: 101,Discriminator Loss: 1.02657222748, Generator Loss: 0.00113137648441\n",
      "Epoch: 102,Discriminator Loss: 0.18025188148, Generator Loss: 0.160349279642\n",
      "Epoch: 103,Discriminator Loss: -0.744058609009, Generator Loss: 5.68299674988\n",
      "Epoch: 104,Discriminator Loss: 1.52868688107, Generator Loss: 0.290785163641\n",
      "Epoch: 105,Discriminator Loss: 0.130572155118, Generator Loss: 0.0151139637455\n",
      "Epoch: 106,Discriminator Loss: 0.315351963043, Generator Loss: 0.0160168819129\n",
      "Epoch: 107,Discriminator Loss: -0.161563813686, Generator Loss: 0.683884859085\n",
      "Epoch: 108,Discriminator Loss: 0.598602414131, Generator Loss: 0.00532566709444\n",
      "Epoch: 109,Discriminator Loss: 0.746093988419, Generator Loss: 0.0107246888801\n",
      "Epoch: 110,Discriminator Loss: -0.0428053811193, Generator Loss: 0.319925040007\n",
      "Epoch: 111,Discriminator Loss: 0.364428699017, Generator Loss: 0.040341027081\n",
      "Epoch: 112,Discriminator Loss: 0.0662605911493, Generator Loss: 0.0287735573947\n",
      "Epoch: 113,Discriminator Loss: -0.877304792404, Generator Loss: 11.512925148\n",
      "Epoch: 114,Discriminator Loss: 0.30825394392, Generator Loss: 0.318253546953\n",
      "Epoch: 115,Discriminator Loss: 1.39834880829, Generator Loss: 0.0838051363826\n",
      "Epoch: 116,Discriminator Loss: 0.898004710674, Generator Loss: 0.162837937474\n",
      "Epoch: 117,Discriminator Loss: 0.4044893682, Generator Loss: 0.296481609344\n",
      "Epoch: 118,Discriminator Loss: 0.298133194447, Generator Loss: 0.0\n",
      "Epoch: 119,Discriminator Loss: -0.0331244021654, Generator Loss: 0.112875364721\n",
      "Epoch: 120,Discriminator Loss: 0.339890986681, Generator Loss: 0.00255993171595\n",
      "Epoch: 121,Discriminator Loss: 0.168569266796, Generator Loss: 0.00348078063689\n",
      "Epoch: 122,Discriminator Loss: -0.424475193024, Generator Loss: 2.78365588188\n",
      "Epoch: 123,Discriminator Loss: 2.63683319092, Generator Loss: 0.345053911209\n",
      "Epoch: 124,Discriminator Loss: -0.0510830804706, Generator Loss: 1.00650238991\n",
      "Epoch: 125,Discriminator Loss: 0.000865902751684, Generator Loss: 1.60762214661\n",
      "Epoch: 126,Discriminator Loss: 3.8089838028, Generator Loss: 6.6209230423\n",
      "Epoch: 127,Discriminator Loss: 0.395469367504, Generator Loss: 4.47034871343e-08\n",
      "Epoch: 128,Discriminator Loss: -0.198904126883, Generator Loss: 6.11298561096\n",
      "Epoch: 129,Discriminator Loss: 0.59907579422, Generator Loss: 0.00466000055894\n",
      "Epoch: 130,Discriminator Loss: -0.930955767632, Generator Loss: 8.98545265198\n",
      "Epoch: 131,Discriminator Loss: -0.732308506966, Generator Loss: 6.5917801857\n",
      "Epoch: 132,Discriminator Loss: 0.323622107506, Generator Loss: 11.512925148\n",
      "Epoch: 133,Discriminator Loss: 0.236087590456, Generator Loss: 1.34415704451e-05\n",
      "Epoch: 134,Discriminator Loss: 0.846393704414, Generator Loss: 0.0527079738677\n",
      "Epoch: 135,Discriminator Loss: 0.214584425092, Generator Loss: 0.00505437701941\n",
      "Epoch: 136,Discriminator Loss: 0.121689721942, Generator Loss: 0.150912061334\n",
      "Epoch: 137,Discriminator Loss: 0.252887368202, Generator Loss: 0.357315450907\n",
      "Epoch: 138,Discriminator Loss: 0.34057289362, Generator Loss: 0.441811650991\n",
      "Epoch: 139,Discriminator Loss: -0.431883603334, Generator Loss: 9.03711128235\n",
      "Epoch: 140,Discriminator Loss: 0.016898419708, Generator Loss: 0.334624052048\n",
      "Epoch: 141,Discriminator Loss: 0.254983663559, Generator Loss: 4.47042839369e-06\n",
      "Epoch: 142,Discriminator Loss: 2.39036512375, Generator Loss: 3.60901165009\n",
      "Epoch: 143,Discriminator Loss: 0.92170882225, Generator Loss: 0.0170769840479\n",
      "Epoch: 144,Discriminator Loss: 0.798294663429, Generator Loss: 0.0782401561737\n",
      "Epoch: 145,Discriminator Loss: -0.0651260465384, Generator Loss: 0.162548705935\n",
      "Epoch: 146,Discriminator Loss: -0.0145671516657, Generator Loss: 6.71462917328\n",
      "Epoch: 147,Discriminator Loss: 0.02712854743, Generator Loss: 0.79686653614\n",
      "Epoch: 148,Discriminator Loss: 0.260948866606, Generator Loss: 0.000628514040727\n",
      "Epoch: 149,Discriminator Loss: 0.182639747858, Generator Loss: 0.0076875705272\n",
      "Epoch: 150,Discriminator Loss: 0.276813566685, Generator Loss: 0.00168674951419\n",
      "Epoch: 151,Discriminator Loss: 0.799696326256, Generator Loss: 0.0051758447662\n",
      "Epoch: 152,Discriminator Loss: 0.483463436365, Generator Loss: 0.0248630829155\n",
      "Epoch: 153,Discriminator Loss: 0.379617422819, Generator Loss: 8.22439906187e-05\n",
      "Epoch: 154,Discriminator Loss: 0.0604263395071, Generator Loss: 1.1696614027\n",
      "Epoch: 155,Discriminator Loss: 0.771523952484, Generator Loss: 0.014113958925\n",
      "Epoch: 156,Discriminator Loss: -0.0152712417766, Generator Loss: 0.0553653538227\n",
      "Epoch: 157,Discriminator Loss: 1.1883752346, Generator Loss: 0.0331968963146\n",
      "Epoch: 158,Discriminator Loss: 0.146263092756, Generator Loss: 0.357129752636\n",
      "Epoch: 159,Discriminator Loss: 0.292230129242, Generator Loss: 3.60613307748e-06\n",
      "Epoch: 160,Discriminator Loss: 0.318688899279, Generator Loss: 0.0575296133757\n",
      "Epoch: 161,Discriminator Loss: -0.479067325592, Generator Loss: 10.1922292709\n",
      "Epoch: 162,Discriminator Loss: 0.335068792105, Generator Loss: 0.560000360012\n",
      "Epoch: 163,Discriminator Loss: 0.0599827952683, Generator Loss: 0.091808103025\n",
      "Epoch: 164,Discriminator Loss: 2.57166838646, Generator Loss: 0.105871915817\n",
      "Epoch: 165,Discriminator Loss: 0.872001230717, Generator Loss: 0.0237894821912\n",
      "Epoch: 166,Discriminator Loss: 0.16829662025, Generator Loss: 0.140007585287\n",
      "Epoch: 167,Discriminator Loss: 0.466792285442, Generator Loss: 0.107258543372\n",
      "Epoch: 168,Discriminator Loss: -0.050058029592, Generator Loss: 10.3157510757\n",
      "Epoch: 169,Discriminator Loss: 0.430737674236, Generator Loss: 0.0185263007879\n",
      "Epoch: 170,Discriminator Loss: 0.265910148621, Generator Loss: 0.00625740224496\n",
      "Epoch: 171,Discriminator Loss: 0.491030424833, Generator Loss: 0.112790048122\n",
      "Epoch: 172,Discriminator Loss: 0.219607114792, Generator Loss: 0.686838984489\n",
      "Epoch: 173,Discriminator Loss: 0.0932313725352, Generator Loss: 3.57628380243e-07\n",
      "Epoch: 174,Discriminator Loss: -0.648728013039, Generator Loss: 5.76031303406\n",
      "Epoch: 175,Discriminator Loss: -0.0299888625741, Generator Loss: 0.0948927849531\n",
      "Epoch: 176,Discriminator Loss: -0.597384512424, Generator Loss: 8.91646099091\n",
      "Epoch: 177,Discriminator Loss: -0.249916955829, Generator Loss: 1.54810357094\n",
      "Epoch: 178,Discriminator Loss: -0.510087966919, Generator Loss: 2.02158999443\n",
      "Epoch: 179,Discriminator Loss: 1.68061470985, Generator Loss: 0.0365223586559\n",
      "Epoch: 180,Discriminator Loss: 0.327078998089, Generator Loss: 0.0829616785049\n",
      "Epoch: 181,Discriminator Loss: 1.2893447876, Generator Loss: 0.00121225102339\n",
      "Epoch: 182,Discriminator Loss: 0.324694037437, Generator Loss: 0.0491524487734\n",
      "Epoch: 183,Discriminator Loss: -0.537546634674, Generator Loss: 5.61668395996\n",
      "Epoch: 184,Discriminator Loss: 0.587270379066, Generator Loss: 0.00385359115899\n",
      "Epoch: 185,Discriminator Loss: 0.30882704258, Generator Loss: 0.000219283989281\n",
      "Epoch: 186,Discriminator Loss: 1.35919761658, Generator Loss: 0.176873475313\n",
      "Epoch: 187,Discriminator Loss: 0.101590253413, Generator Loss: 0.166157126427\n",
      "Epoch: 188,Discriminator Loss: -0.251749277115, Generator Loss: 0.607769668102\n",
      "Epoch: 189,Discriminator Loss: -0.41716709733, Generator Loss: 10.2343816757\n",
      "Epoch: 190,Discriminator Loss: 0.24586379528, Generator Loss: 0.532559454441\n",
      "Epoch: 191,Discriminator Loss: -0.500507712364, Generator Loss: 2.4247481823\n",
      "Epoch: 192,Discriminator Loss: 0.338227927685, Generator Loss: 0.0915142148733\n",
      "Epoch: 193,Discriminator Loss: 0.294326007366, Generator Loss: 0.0261033736169\n",
      "Epoch: 194,Discriminator Loss: 0.404602438211, Generator Loss: 0.388532519341\n",
      "Epoch: 195,Discriminator Loss: 0.611174345016, Generator Loss: 0.000219239213038\n",
      "Epoch: 196,Discriminator Loss: 0.0197114907205, Generator Loss: 0.0880617424846\n",
      "Epoch: 197,Discriminator Loss: 0.184548854828, Generator Loss: 0.0193985961378\n",
      "Epoch: 198,Discriminator Loss: 0.0278854630888, Generator Loss: 0.000102051162685\n",
      "Epoch: 199,Discriminator Loss: -0.156278863549, Generator Loss: 0.537414669991\n",
      "Epoch: 200,Discriminator Loss: 2.19780921936, Generator Loss: 0.0689159408212\n",
      "Epoch: 201,Discriminator Loss: -0.583371162415, Generator Loss: 6.79820966721\n",
      "Epoch: 202,Discriminator Loss: -0.289826363325, Generator Loss: 7.86995363235\n",
      "Epoch: 203,Discriminator Loss: 0.374515205622, Generator Loss: 0.408966362476\n",
      "Epoch: 204,Discriminator Loss: 0.216621756554, Generator Loss: 0.164654746652\n",
      "Epoch: 205,Discriminator Loss: -0.370697379112, Generator Loss: 4.6358795166\n",
      "Epoch: 206,Discriminator Loss: 0.132575392723, Generator Loss: 0.0\n",
      "Epoch: 207,Discriminator Loss: 0.164847075939, Generator Loss: 5.9984085965e-05\n",
      "Epoch: 208,Discriminator Loss: 0.671396017075, Generator Loss: 0.0299677979201\n",
      "Epoch: 209,Discriminator Loss: 0.33740362525, Generator Loss: 0.235315173864\n",
      "Epoch: 210,Discriminator Loss: 0.253471374512, Generator Loss: 0.0881750285625\n",
      "Epoch: 211,Discriminator Loss: -0.00064099393785, Generator Loss: 0.250388503075\n",
      "Epoch: 212,Discriminator Loss: 0.59267359972, Generator Loss: 0.340314149857\n",
      "Epoch: 213,Discriminator Loss: -0.0186644867063, Generator Loss: 4.95831298828\n",
      "Epoch: 214,Discriminator Loss: -0.79961335659, Generator Loss: 6.55152082443\n",
      "Epoch: 215,Discriminator Loss: -0.578611731529, Generator Loss: 1.11447238922\n",
      "Epoch: 216,Discriminator Loss: -0.0857653096318, Generator Loss: 0.623041749001\n",
      "Epoch: 217,Discriminator Loss: 0.919669747353, Generator Loss: 0.0712386369705\n",
      "Epoch: 218,Discriminator Loss: 0.927424132824, Generator Loss: 0.0436122529209\n",
      "Epoch: 219,Discriminator Loss: 0.525106191635, Generator Loss: 0.000787662691437\n",
      "Epoch: 220,Discriminator Loss: 0.346666634083, Generator Loss: 0.0634604990482\n",
      "Epoch: 221,Discriminator Loss: 0.328684538603, Generator Loss: 0.109960898757\n",
      "Epoch: 222,Discriminator Loss: 2.22062468529, Generator Loss: 0.281028389931\n",
      "Epoch: 223,Discriminator Loss: 0.207620427012, Generator Loss: 0.0258869212121\n",
      "Epoch: 224,Discriminator Loss: 0.13297329843, Generator Loss: 0.000822722795419\n",
      "Epoch: 225,Discriminator Loss: -0.728822231293, Generator Loss: 5.47651386261\n",
      "Epoch: 226,Discriminator Loss: 0.401591718197, Generator Loss: 0.0133243240416\n",
      "Epoch: 227,Discriminator Loss: 1.90202641487, Generator Loss: 0.247815489769\n",
      "Epoch: 228,Discriminator Loss: -0.151395201683, Generator Loss: 5.84392261505\n",
      "Epoch: 229,Discriminator Loss: 2.86368989944, Generator Loss: 0.0680879279971\n",
      "Epoch: 230,Discriminator Loss: 1.2981607914, Generator Loss: 0.0238837487996\n",
      "Epoch: 231,Discriminator Loss: 0.0123840682209, Generator Loss: 0.24494086206\n",
      "Epoch: 232,Discriminator Loss: -0.0425877571106, Generator Loss: 2.16065597534\n",
      "Epoch: 233,Discriminator Loss: 0.225983083248, Generator Loss: 0.00253993016668\n",
      "Epoch: 234,Discriminator Loss: 0.292618691921, Generator Loss: 0.00396336521953\n",
      "Epoch: 235,Discriminator Loss: 0.169835150242, Generator Loss: 0.0709382519126\n",
      "Epoch: 236,Discriminator Loss: 0.58149266243, Generator Loss: 0.0587361454964\n",
      "Epoch: 237,Discriminator Loss: 0.303737401962, Generator Loss: 0.0389927588403\n",
      "Epoch: 238,Discriminator Loss: 0.0277387872338, Generator Loss: 0.340799659491\n",
      "Epoch: 239,Discriminator Loss: -0.0202864427119, Generator Loss: 0.053903978318\n",
      "Epoch: 240,Discriminator Loss: 0.171547949314, Generator Loss: 8.30029678345\n",
      "Epoch: 241,Discriminator Loss: 0.90466272831, Generator Loss: 4.91192245483\n",
      "Epoch: 242,Discriminator Loss: -0.35397619009, Generator Loss: 1.58120036125\n",
      "Epoch: 243,Discriminator Loss: 0.406352907419, Generator Loss: 0.359904408455\n",
      "Epoch: 244,Discriminator Loss: 0.934069991112, Generator Loss: 7.3378329277\n",
      "Epoch: 245,Discriminator Loss: 1.85499274731, Generator Loss: 0.00104225066025\n",
      "Epoch: 246,Discriminator Loss: 0.179872870445, Generator Loss: 1.46032232351e-06\n",
      "Epoch: 247,Discriminator Loss: 1.36729216576, Generator Loss: 0.0271075814962\n",
      "Epoch: 248,Discriminator Loss: 0.312601804733, Generator Loss: 0.00306762102991\n",
      "Epoch: 249,Discriminator Loss: 1.15970540047, Generator Loss: 0.063018091023\n",
      "Epoch: 250,Discriminator Loss: -0.60043233633, Generator Loss: 6.72398376465\n",
      "Epoch: 251,Discriminator Loss: 0.799590229988, Generator Loss: 0.00370959471911\n",
      "Epoch: 252,Discriminator Loss: 0.129812657833, Generator Loss: 0.244405806065\n",
      "Epoch: 253,Discriminator Loss: -0.0652727484703, Generator Loss: 0.185004904866\n",
      "Epoch: 254,Discriminator Loss: 0.0451721996069, Generator Loss: 0.281037926674\n",
      "Epoch: 255,Discriminator Loss: 0.34955444932, Generator Loss: 0.00847906433046\n",
      "Epoch: 256,Discriminator Loss: -0.300949573517, Generator Loss: 6.29294300079\n",
      "Epoch: 257,Discriminator Loss: 0.39014351368, Generator Loss: 8.61842490849e-05\n",
      "Epoch: 258,Discriminator Loss: 0.412623137236, Generator Loss: 0.016174197197\n",
      "Epoch: 259,Discriminator Loss: 0.0198087021708, Generator Loss: 0.138077348471\n",
      "Epoch: 260,Discriminator Loss: 0.271631121635, Generator Loss: 0.0480008460581\n",
      "Epoch: 261,Discriminator Loss: -0.481140077114, Generator Loss: 11.512925148\n",
      "Epoch: 262,Discriminator Loss: -0.0455756634474, Generator Loss: 0.235283970833\n",
      "Epoch: 263,Discriminator Loss: -0.778620839119, Generator Loss: 6.89692258835\n",
      "Epoch: 264,Discriminator Loss: 7.01980733871, Generator Loss: 0.710117816925\n",
      "Epoch: 265,Discriminator Loss: 0.443050503731, Generator Loss: 0.372992068529\n",
      "Epoch: 266,Discriminator Loss: 0.241203069687, Generator Loss: 0.946756660938\n",
      "Epoch: 267,Discriminator Loss: -0.306568801403, Generator Loss: 4.47132110596\n",
      "Epoch: 268,Discriminator Loss: 0.690951943398, Generator Loss: 0.0376669839025\n",
      "Epoch: 269,Discriminator Loss: 0.287271857262, Generator Loss: 3.21235747833e-05\n",
      "Epoch: 270,Discriminator Loss: 0.181822478771, Generator Loss: 0.0303209349513\n",
      "Epoch: 271,Discriminator Loss: -0.243548050523, Generator Loss: 3.19758248329\n",
      "Epoch: 272,Discriminator Loss: 0.209542542696, Generator Loss: 0.686599731445\n",
      "Epoch: 273,Discriminator Loss: 0.843634724617, Generator Loss: 0.0235290937126\n",
      "Epoch: 274,Discriminator Loss: 0.419273883104, Generator Loss: 2.55756592751\n",
      "Epoch: 275,Discriminator Loss: 0.376046746969, Generator Loss: 0.00299999676645\n",
      "Epoch: 276,Discriminator Loss: -0.173731833696, Generator Loss: 8.80254936218\n",
      "Epoch: 277,Discriminator Loss: 0.146332219243, Generator Loss: 0.384562075138\n",
      "Epoch: 278,Discriminator Loss: -0.0422558709979, Generator Loss: 0.155184715986\n",
      "Epoch: 279,Discriminator Loss: 0.26163187623, Generator Loss: 0.072049498558\n",
      "Epoch: 280,Discriminator Loss: 0.238516509533, Generator Loss: 0.585359096527\n",
      "Epoch: 281,Discriminator Loss: 0.0621831640601, Generator Loss: 0.0456262975931\n",
      "Epoch: 282,Discriminator Loss: 0.227568313479, Generator Loss: 0.295158326626\n",
      "Epoch: 283,Discriminator Loss: 0.458088517189, Generator Loss: 6.67715215683\n",
      "Epoch: 284,Discriminator Loss: 0.509299695492, Generator Loss: 0.001244291896\n",
      "Epoch: 285,Discriminator Loss: 0.327842593193, Generator Loss: 0.00120620755479\n",
      "Epoch: 286,Discriminator Loss: -0.156463772058, Generator Loss: 0.364860594273\n",
      "Epoch: 287,Discriminator Loss: 0.0354687869549, Generator Loss: 0.290800571442\n",
      "Epoch: 288,Discriminator Loss: -0.954859256744, Generator Loss: 10.5591125488\n",
      "Epoch: 289,Discriminator Loss: 0.559819936752, Generator Loss: 0.00418165558949\n",
      "Epoch: 290,Discriminator Loss: 0.0335188955069, Generator Loss: 2.46243000031\n",
      "Epoch: 291,Discriminator Loss: -0.489328086376, Generator Loss: 6.7006983757\n",
      "Epoch: 292,Discriminator Loss: -0.158137366176, Generator Loss: 0.686838984489\n",
      "Epoch: 293,Discriminator Loss: 2.16471982002, Generator Loss: 0.86380636692\n",
      "Epoch: 294,Discriminator Loss: 0.254599750042, Generator Loss: 0.0297236554325\n",
      "Epoch: 295,Discriminator Loss: 0.30528819561, Generator Loss: 0.0159181989729\n",
      "Epoch: 296,Discriminator Loss: 0.0366995446384, Generator Loss: 0.00349675118923\n",
      "Epoch: 297,Discriminator Loss: 0.311704516411, Generator Loss: 0.0805848687887\n",
      "Epoch: 298,Discriminator Loss: 4.77640533447, Generator Loss: 0.0253402851522\n",
      "Epoch: 299,Discriminator Loss: 0.412416398525, Generator Loss: 0.0904908031225\n",
      "Epoch: 300,Discriminator Loss: 0.469748228788, Generator Loss: 2.53319967669e-07\n",
      "Epoch: 301,Discriminator Loss: -0.0102779641747, Generator Loss: 0.232969149947\n",
      "Epoch: 302,Discriminator Loss: 0.150490239263, Generator Loss: 0.0064852302894\n",
      "Epoch: 303,Discriminator Loss: 0.165595084429, Generator Loss: 0.00435558380559\n",
      "Epoch: 304,Discriminator Loss: 0.240553051233, Generator Loss: 0.000919345882721\n",
      "Epoch: 305,Discriminator Loss: 0.632183790207, Generator Loss: 0.0154027407989\n",
      "Epoch: 306,Discriminator Loss: 0.0774914175272, Generator Loss: 0.841746330261\n",
      "Epoch: 307,Discriminator Loss: -0.0875450745225, Generator Loss: 0.226992294192\n",
      "Epoch: 308,Discriminator Loss: 0.897428750992, Generator Loss: 0.0311820618808\n",
      "Epoch: 309,Discriminator Loss: 0.515192687511, Generator Loss: 0.0381054393947\n",
      "Epoch: 310,Discriminator Loss: 1.49094700813, Generator Loss: 2.43862438202\n",
      "Epoch: 311,Discriminator Loss: 0.615954339504, Generator Loss: 0.000396401475882\n",
      "Epoch: 312,Discriminator Loss: -0.018967313692, Generator Loss: 0.108900889754\n",
      "Epoch: 313,Discriminator Loss: 0.510732769966, Generator Loss: 5.23490142822\n",
      "Epoch: 314,Discriminator Loss: 0.0300896894187, Generator Loss: 0.000294535711873\n",
      "Epoch: 315,Discriminator Loss: -0.166406780481, Generator Loss: 0.311814367771\n",
      "Epoch: 316,Discriminator Loss: -0.75684261322, Generator Loss: 10.6085796356\n",
      "Epoch: 317,Discriminator Loss: -0.153424799442, Generator Loss: 0.570530414581\n",
      "Epoch: 318,Discriminator Loss: 0.725737929344, Generator Loss: 0.53187841177\n",
      "Epoch: 319,Discriminator Loss: 1.82635116577, Generator Loss: 0.345003813505\n",
      "Epoch: 320,Discriminator Loss: 1.39488625526, Generator Loss: 0.0108756870031\n",
      "Epoch: 321,Discriminator Loss: 1.13693392277, Generator Loss: 0.00117507227696\n",
      "Epoch: 322,Discriminator Loss: 0.443621218204, Generator Loss: 0.0771215930581\n",
      "Epoch: 323,Discriminator Loss: 0.250833570957, Generator Loss: 2.06190371513\n",
      "Epoch: 324,Discriminator Loss: 0.560721099377, Generator Loss: 5.7606252085e-05\n",
      "Epoch: 325,Discriminator Loss: 1.42181384563, Generator Loss: 0.339241981506\n",
      "Epoch: 326,Discriminator Loss: 1.03692090511, Generator Loss: 0.233589529991\n",
      "Epoch: 327,Discriminator Loss: 0.108449503779, Generator Loss: 0.0546689033508\n",
      "Epoch: 328,Discriminator Loss: 1.0044580698, Generator Loss: 0.310255646706\n",
      "Epoch: 329,Discriminator Loss: 0.734769105911, Generator Loss: 0.0735514685512\n",
      "Epoch: 330,Discriminator Loss: 2.67952895164, Generator Loss: 0.226162865758\n",
      "Epoch: 331,Discriminator Loss: -0.858565449715, Generator Loss: 7.11862754822\n",
      "Epoch: 332,Discriminator Loss: 0.142666459084, Generator Loss: 6.72059968565e-06\n",
      "Epoch: 333,Discriminator Loss: 0.581153094769, Generator Loss: 0.022936180234\n",
      "Epoch: 334,Discriminator Loss: -0.0648639202118, Generator Loss: 0.287599682808\n",
      "Epoch: 335,Discriminator Loss: -0.682207405567, Generator Loss: 1.98038101196\n",
      "Epoch: 336,Discriminator Loss: -0.689247369766, Generator Loss: 5.44479179382\n",
      "Epoch: 337,Discriminator Loss: 0.852597415447, Generator Loss: 0.0100520066917\n",
      "Epoch: 338,Discriminator Loss: 1.27925610542, Generator Loss: 0.354826509953\n",
      "Epoch: 339,Discriminator Loss: 2.35044312477, Generator Loss: 0.214569672942\n",
      "Epoch: 340,Discriminator Loss: 0.632574677467, Generator Loss: 0.0143979229033\n",
      "Epoch: 341,Discriminator Loss: 0.0539823174477, Generator Loss: 0.272439628839\n",
      "Epoch: 342,Discriminator Loss: 0.457055091858, Generator Loss: 0.00048719055485\n",
      "Epoch: 343,Discriminator Loss: 0.500499427319, Generator Loss: 0.89750957489\n",
      "Epoch: 344,Discriminator Loss: -0.462450146675, Generator Loss: 6.00051307678\n",
      "Epoch: 345,Discriminator Loss: 2.04372811317, Generator Loss: 0.00118454988115\n",
      "Epoch: 346,Discriminator Loss: 0.559524178505, Generator Loss: 5.20144462585\n",
      "Epoch: 347,Discriminator Loss: 0.168890267611, Generator Loss: 0.157799199224\n",
      "Epoch: 348,Discriminator Loss: -0.129635512829, Generator Loss: 0.487506896257\n",
      "Epoch: 349,Discriminator Loss: -0.585352540016, Generator Loss: 11.512925148\n",
      "Epoch: 350,Discriminator Loss: -0.258314490318, Generator Loss: 0.769082665443\n",
      "Epoch: 351,Discriminator Loss: 0.832089602947, Generator Loss: 0.211156606674\n",
      "Epoch: 352,Discriminator Loss: 0.992151498795, Generator Loss: 0.696421682835\n",
      "Epoch: 353,Discriminator Loss: 0.276212930679, Generator Loss: 0.0\n",
      "Epoch: 354,Discriminator Loss: 0.151858150959, Generator Loss: 1.78586745262\n",
      "Epoch: 355,Discriminator Loss: -0.111598625779, Generator Loss: 0.749617815018\n",
      "Epoch: 356,Discriminator Loss: 0.195564717054, Generator Loss: 0.475522518158\n",
      "Epoch: 357,Discriminator Loss: -0.521103262901, Generator Loss: 0.907257258892\n",
      "Epoch: 358,Discriminator Loss: -0.0842220708728, Generator Loss: 4.26786470413\n",
      "Epoch: 359,Discriminator Loss: 0.332658857107, Generator Loss: 0.00241025304422\n",
      "Epoch: 360,Discriminator Loss: 0.483715325594, Generator Loss: 0.0\n",
      "Epoch: 361,Discriminator Loss: -0.421294480562, Generator Loss: 5.03318834305\n",
      "Epoch: 362,Discriminator Loss: 1.49846720695, Generator Loss: 0.683867394924\n",
      "Epoch: 363,Discriminator Loss: 1.83306396008, Generator Loss: 0.182967379689\n",
      "Epoch: 364,Discriminator Loss: 2.49966621399, Generator Loss: 0.881796479225\n",
      "Epoch: 365,Discriminator Loss: 1.2703063488, Generator Loss: 0.871248483658\n",
      "Epoch: 366,Discriminator Loss: 0.779092788696, Generator Loss: 0.910720288754\n",
      "Epoch: 367,Discriminator Loss: 0.363339275122, Generator Loss: 0.0840944200754\n",
      "Epoch: 368,Discriminator Loss: 0.320828974247, Generator Loss: 0.17566563189\n",
      "Epoch: 369,Discriminator Loss: 0.392841696739, Generator Loss: 0.331445515156\n",
      "Epoch: 370,Discriminator Loss: -0.198118150234, Generator Loss: 0.634167790413\n",
      "Epoch: 371,Discriminator Loss: 1.20272195339, Generator Loss: 1.32922434807\n",
      "Epoch: 372,Discriminator Loss: 0.286596357822, Generator Loss: 0.0836229622364\n",
      "Epoch: 373,Discriminator Loss: -0.481784194708, Generator Loss: 0.713879525661\n",
      "Epoch: 374,Discriminator Loss: 0.00601171143353, Generator Loss: 2.50501132011\n",
      "Epoch: 375,Discriminator Loss: -0.735770463943, Generator Loss: 8.00611019135\n",
      "Epoch: 376,Discriminator Loss: 1.99125003815, Generator Loss: 0.000111549117719\n",
      "Epoch: 377,Discriminator Loss: 0.427648305893, Generator Loss: 0.0218150541186\n",
      "Epoch: 378,Discriminator Loss: 2.05485200882, Generator Loss: 0.000726044760086\n",
      "Epoch: 379,Discriminator Loss: 0.0214301198721, Generator Loss: 1.51572871208\n",
      "Epoch: 380,Discriminator Loss: 0.503643631935, Generator Loss: 3.22870969772\n",
      "Epoch: 381,Discriminator Loss: 1.19533622265, Generator Loss: 0.0256084576249\n",
      "Epoch: 382,Discriminator Loss: -0.631106257439, Generator Loss: 11.512925148\n",
      "Epoch: 383,Discriminator Loss: 0.194770842791, Generator Loss: 7.83526992798\n",
      "Epoch: 384,Discriminator Loss: -0.534186899662, Generator Loss: 2.31656646729\n",
      "Epoch: 385,Discriminator Loss: -0.345187872648, Generator Loss: 0.571021974087\n",
      "Epoch: 386,Discriminator Loss: 0.0761252045631, Generator Loss: 0.324844896793\n",
      "Epoch: 387,Discriminator Loss: 0.315888285637, Generator Loss: 0.0126160634682\n",
      "Epoch: 388,Discriminator Loss: 1.41635835171, Generator Loss: 6.10949030033e-07\n",
      "Epoch: 389,Discriminator Loss: -0.506887674332, Generator Loss: 6.22223377228\n",
      "Epoch: 390,Discriminator Loss: -0.125733792782, Generator Loss: 0.305364280939\n",
      "Epoch: 391,Discriminator Loss: 0.397578507662, Generator Loss: 0.0273462198675\n",
      "Epoch: 392,Discriminator Loss: 1.39560866356, Generator Loss: 0.00471599120647\n",
      "Epoch: 393,Discriminator Loss: -0.860158741474, Generator Loss: 10.1595821381\n",
      "Epoch: 394,Discriminator Loss: -0.317697614431, Generator Loss: 3.25327086449\n",
      "Epoch: 395,Discriminator Loss: -0.367341727018, Generator Loss: 5.02235126495\n",
      "Epoch: 396,Discriminator Loss: 0.228824362159, Generator Loss: 0.224083051085\n",
      "Epoch: 397,Discriminator Loss: -0.267872452736, Generator Loss: 1.66395401955\n",
      "Epoch: 398,Discriminator Loss: 0.37861546874, Generator Loss: 3.65763473511\n",
      "Epoch: 399,Discriminator Loss: 1.34368896484, Generator Loss: 0.348816215992\n",
      "Epoch: 400,Discriminator Loss: 0.161557167768, Generator Loss: 0.0866968780756\n",
      "Epoch: 401,Discriminator Loss: -0.164800316095, Generator Loss: 2.44829559326\n",
      "Epoch: 402,Discriminator Loss: 0.532330751419, Generator Loss: 0.256708830595\n",
      "Epoch: 403,Discriminator Loss: 1.53222632408, Generator Loss: 0.281317323446\n",
      "Epoch: 404,Discriminator Loss: 0.205013021827, Generator Loss: 0.0331778377295\n",
      "Epoch: 405,Discriminator Loss: -0.167349845171, Generator Loss: 9.47092723846\n",
      "Epoch: 406,Discriminator Loss: 0.316158682108, Generator Loss: 0.000121449542348\n",
      "Epoch: 407,Discriminator Loss: 0.364743947983, Generator Loss: 0.292146205902\n",
      "Epoch: 408,Discriminator Loss: 5.36982345581, Generator Loss: 0.0296347364783\n",
      "Epoch: 409,Discriminator Loss: 0.174409806728, Generator Loss: 0.00834525376558\n",
      "Epoch: 410,Discriminator Loss: 0.63575565815, Generator Loss: 0.0460761748254\n",
      "Epoch: 411,Discriminator Loss: -0.339481443167, Generator Loss: 8.64848136902\n",
      "Epoch: 412,Discriminator Loss: 0.699667453766, Generator Loss: 0.325052082539\n",
      "Epoch: 413,Discriminator Loss: 0.0851828753948, Generator Loss: 0.0373925976455\n",
      "Epoch: 414,Discriminator Loss: 0.208462357521, Generator Loss: 5.75808238983\n",
      "Epoch: 415,Discriminator Loss: -0.0756811723113, Generator Loss: 0.691439628601\n",
      "Epoch: 416,Discriminator Loss: 0.0636620521545, Generator Loss: 0.573353171349\n",
      "Epoch: 417,Discriminator Loss: 0.365603327751, Generator Loss: 2.01329567062e-05\n",
      "Epoch: 418,Discriminator Loss: -0.98039740324, Generator Loss: 10.512845993\n",
      "Epoch: 419,Discriminator Loss: 3.04506659508, Generator Loss: 5.90040111542\n",
      "Epoch: 420,Discriminator Loss: 1.08441197872, Generator Loss: 0.0029245459009\n",
      "Epoch: 421,Discriminator Loss: -0.170892909169, Generator Loss: 0.74542170763\n",
      "Epoch: 422,Discriminator Loss: 0.152548074722, Generator Loss: 0.101616464555\n",
      "Epoch: 423,Discriminator Loss: 0.0589161291718, Generator Loss: 0.232872754335\n",
      "Epoch: 424,Discriminator Loss: 0.954741537571, Generator Loss: 0.0434987954795\n",
      "Epoch: 425,Discriminator Loss: -0.754681885242, Generator Loss: 2.85138273239\n",
      "Epoch: 426,Discriminator Loss: -0.294339120388, Generator Loss: 0.624375343323\n",
      "Epoch: 427,Discriminator Loss: 5.08218669891, Generator Loss: 0.000785738171544\n",
      "Epoch: 428,Discriminator Loss: 0.853611648083, Generator Loss: 0.249724432826\n",
      "Epoch: 429,Discriminator Loss: 0.977458834648, Generator Loss: 0.000284741428914\n",
      "Epoch: 430,Discriminator Loss: 0.0312399175018, Generator Loss: 0.0301200542599\n",
      "Epoch: 431,Discriminator Loss: -0.0870393067598, Generator Loss: 0.104743905365\n",
      "Epoch: 432,Discriminator Loss: -0.174652054906, Generator Loss: 4.43835449219\n",
      "Epoch: 433,Discriminator Loss: -0.183990716934, Generator Loss: 0.370343655348\n",
      "Epoch: 434,Discriminator Loss: 0.741985321045, Generator Loss: 0.271081805229\n",
      "Epoch: 435,Discriminator Loss: 0.0830157995224, Generator Loss: 0.00364928273484\n",
      "Epoch: 436,Discriminator Loss: 0.407642543316, Generator Loss: 0.00777700403705\n",
      "Epoch: 437,Discriminator Loss: 0.472333103418, Generator Loss: 0.0928152352571\n",
      "Epoch: 438,Discriminator Loss: 0.0928432047367, Generator Loss: 3.57628380243e-07\n",
      "Epoch: 439,Discriminator Loss: -0.643009006977, Generator Loss: 9.42436981201\n",
      "Epoch: 440,Discriminator Loss: -0.136717841029, Generator Loss: 0.616515278816\n",
      "Epoch: 441,Discriminator Loss: -0.602838993073, Generator Loss: 11.512925148\n",
      "Epoch: 442,Discriminator Loss: -0.234539836645, Generator Loss: 0.553027391434\n",
      "Epoch: 443,Discriminator Loss: 1.04933977127, Generator Loss: 1.49011611938e-08\n",
      "Epoch: 444,Discriminator Loss: 0.343920707703, Generator Loss: 0.11890335381\n",
      "Epoch: 445,Discriminator Loss: 0.131281539798, Generator Loss: 1.53789260366e-05\n",
      "Epoch: 446,Discriminator Loss: -0.405890107155, Generator Loss: 1.47812211514\n",
      "Epoch: 447,Discriminator Loss: -0.0653362423182, Generator Loss: 0.239450007677\n",
      "Epoch: 448,Discriminator Loss: -0.378959804773, Generator Loss: 5.92039299011\n",
      "Epoch: 449,Discriminator Loss: -0.182134926319, Generator Loss: 5.60966587067\n",
      "Epoch: 450,Discriminator Loss: 0.805529713631, Generator Loss: 0.125238090754\n",
      "Epoch: 451,Discriminator Loss: 0.246470138431, Generator Loss: 0.00278527103364\n",
      "Epoch: 452,Discriminator Loss: -0.093059875071, Generator Loss: 0.430791407824\n",
      "Epoch: 453,Discriminator Loss: -0.361379861832, Generator Loss: 5.93382263184\n",
      "Epoch: 454,Discriminator Loss: 0.351391434669, Generator Loss: 11.512925148\n",
      "Epoch: 455,Discriminator Loss: 0.164151668549, Generator Loss: 0.225368559361\n",
      "Epoch: 456,Discriminator Loss: 0.683099150658, Generator Loss: 0.0094593083486\n",
      "Epoch: 457,Discriminator Loss: 0.068186737597, Generator Loss: 0.00875893048942\n",
      "Epoch: 458,Discriminator Loss: 1.68006086349, Generator Loss: 0.425079375505\n",
      "Epoch: 459,Discriminator Loss: 0.356807857752, Generator Loss: 0.230483695865\n",
      "Epoch: 460,Discriminator Loss: 0.0869388878345, Generator Loss: 0.414109289646\n",
      "Epoch: 461,Discriminator Loss: 0.35859015584, Generator Loss: 0.128730639815\n",
      "Epoch: 462,Discriminator Loss: 0.244651570916, Generator Loss: 1.85378958122e-05\n",
      "Epoch: 463,Discriminator Loss: -0.513077437878, Generator Loss: 5.71897029877\n",
      "Epoch: 464,Discriminator Loss: -0.318350195885, Generator Loss: 4.35700845718\n",
      "Epoch: 465,Discriminator Loss: 0.37782305479, Generator Loss: 4.72179599456e-05\n",
      "Epoch: 466,Discriminator Loss: 0.267742156982, Generator Loss: 0.00336277042516\n",
      "Epoch: 467,Discriminator Loss: 0.579273462296, Generator Loss: 0.000780860893428\n",
      "Epoch: 468,Discriminator Loss: 3.0042860508, Generator Loss: 0.0664179623127\n",
      "Epoch: 469,Discriminator Loss: 0.708026051521, Generator Loss: 0.0358723253012\n",
      "Epoch: 470,Discriminator Loss: 0.0798226445913, Generator Loss: 0.361515045166\n",
      "Epoch: 471,Discriminator Loss: -0.291405916214, Generator Loss: 3.28961467743\n",
      "Epoch: 472,Discriminator Loss: 0.375104665756, Generator Loss: 3.54538941383\n",
      "Epoch: 473,Discriminator Loss: -0.121945030987, Generator Loss: 0.37635114789\n",
      "Epoch: 474,Discriminator Loss: 0.147771447897, Generator Loss: 0.0413230136037\n",
      "Epoch: 475,Discriminator Loss: -0.541154980659, Generator Loss: 11.512925148\n",
      "Epoch: 476,Discriminator Loss: 0.308617174625, Generator Loss: 4.40039634705\n",
      "Epoch: 477,Discriminator Loss: 0.729300498962, Generator Loss: 0.0902231708169\n",
      "Epoch: 478,Discriminator Loss: -0.361022233963, Generator Loss: 2.8053855896\n",
      "Epoch: 479,Discriminator Loss: 0.382599592209, Generator Loss: 0.0259045474231\n",
      "Epoch: 480,Discriminator Loss: -0.0472604073584, Generator Loss: 0.190317779779\n",
      "Epoch: 481,Discriminator Loss: 0.490207403898, Generator Loss: 0.0594267584383\n",
      "Epoch: 482,Discriminator Loss: 0.197464466095, Generator Loss: 0.0811003148556\n",
      "Epoch: 483,Discriminator Loss: 0.521534323692, Generator Loss: 0.0225629471242\n",
      "Epoch: 484,Discriminator Loss: 0.144338846207, Generator Loss: 0.332522749901\n",
      "Epoch: 485,Discriminator Loss: 0.393662422895, Generator Loss: 0.0\n",
      "Epoch: 486,Discriminator Loss: 0.0160317495465, Generator Loss: 0.721010565758\n",
      "Epoch: 487,Discriminator Loss: 0.14350861311, Generator Loss: 5.01977491379\n",
      "Epoch: 488,Discriminator Loss: 0.829343318939, Generator Loss: 0.0\n",
      "Epoch: 489,Discriminator Loss: 0.716228842735, Generator Loss: 1.96696646526e-06\n",
      "Epoch: 490,Discriminator Loss: -0.217995256186, Generator Loss: 10.6630887985\n",
      "Epoch: 491,Discriminator Loss: 0.87014311552, Generator Loss: 0.225019067526\n",
      "Epoch: 492,Discriminator Loss: 0.249893456697, Generator Loss: 0.0840888395905\n",
      "Epoch: 493,Discriminator Loss: 0.342741250992, Generator Loss: 0.118559151888\n",
      "Epoch: 494,Discriminator Loss: 1.25326812267, Generator Loss: 11.512925148\n",
      "Epoch: 495,Discriminator Loss: 0.160132542253, Generator Loss: 0.00890949834138\n",
      "Epoch: 496,Discriminator Loss: 0.618055939674, Generator Loss: 0.156148046255\n",
      "Epoch: 497,Discriminator Loss: 0.234524175525, Generator Loss: 0.0168462581933\n",
      "Epoch: 498,Discriminator Loss: -0.0391943380237, Generator Loss: 6.5429558754\n",
      "Epoch: 499,Discriminator Loss: 0.0949872806668, Generator Loss: 0.00764600560069\n",
      "Epoch: 500,Discriminator Loss: 0.0436147376895, Generator Loss: 2.98290634155\n",
      "Epoch: 501,Discriminator Loss: -0.23889914155, Generator Loss: 0.514900624752\n",
      "Epoch: 502,Discriminator Loss: 0.185092300177, Generator Loss: 0.0689496845007\n",
      "Epoch: 503,Discriminator Loss: 0.191089168191, Generator Loss: 0.0407502278686\n",
      "Epoch: 504,Discriminator Loss: 0.488891065121, Generator Loss: 0.122319057584\n",
      "Epoch: 505,Discriminator Loss: 0.453375607729, Generator Loss: 2.38418806475e-07\n",
      "Epoch: 506,Discriminator Loss: -0.0169141944498, Generator Loss: 0.209097459912\n",
      "Epoch: 507,Discriminator Loss: 0.213068693876, Generator Loss: 0.0452237203717\n",
      "Epoch: 508,Discriminator Loss: 0.440865188837, Generator Loss: 0.0199774708599\n",
      "Epoch: 509,Discriminator Loss: -0.612755298615, Generator Loss: 8.05474472046\n",
      "Epoch: 510,Discriminator Loss: -0.477218210697, Generator Loss: 6.28904628754\n",
      "Epoch: 511,Discriminator Loss: 0.705673515797, Generator Loss: 0.0329263210297\n",
      "Epoch: 512,Discriminator Loss: 1.11466789246, Generator Loss: 5.77025651932\n",
      "Epoch: 513,Discriminator Loss: -0.111236900091, Generator Loss: 0.225996047258\n",
      "Epoch: 514,Discriminator Loss: 1.17927026749, Generator Loss: 3.54969406128\n",
      "Epoch: 515,Discriminator Loss: 0.329988032579, Generator Loss: 0.156216606498\n",
      "Epoch: 516,Discriminator Loss: 0.105887115002, Generator Loss: 0.163788482547\n",
      "Epoch: 517,Discriminator Loss: 0.172291725874, Generator Loss: 1.13589286804\n",
      "Epoch: 518,Discriminator Loss: 1.23804616928, Generator Loss: 0.0670511722565\n",
      "Epoch: 519,Discriminator Loss: -0.0701063722372, Generator Loss: 0.242506712675\n",
      "Epoch: 520,Discriminator Loss: 0.487879514694, Generator Loss: 0.00307134236209\n",
      "Epoch: 521,Discriminator Loss: -0.0125667490065, Generator Loss: 0.437416702509\n",
      "Epoch: 522,Discriminator Loss: -0.0866771191359, Generator Loss: 0.291828691959\n",
      "Epoch: 523,Discriminator Loss: 0.212960064411, Generator Loss: 0.00140251859557\n",
      "Epoch: 524,Discriminator Loss: 0.243895038962, Generator Loss: 0.0648303255439\n",
      "Epoch: 525,Discriminator Loss: 0.273673474789, Generator Loss: 8.42030276544e-05\n",
      "Epoch: 526,Discriminator Loss: 0.126991480589, Generator Loss: 0.0587964989245\n",
      "Epoch: 527,Discriminator Loss: 0.130276709795, Generator Loss: 0.00616318872198\n",
      "Epoch: 528,Discriminator Loss: 0.324957966805, Generator Loss: 0.000881327025127\n",
      "Epoch: 529,Discriminator Loss: 0.69257491827, Generator Loss: 0.136303365231\n",
      "Epoch: 530,Discriminator Loss: 0.921619653702, Generator Loss: 0.00364344520494\n",
      "Epoch: 531,Discriminator Loss: 0.654092609882, Generator Loss: 3.01005820802e-06\n",
      "Epoch: 532,Discriminator Loss: 0.00224549882114, Generator Loss: 0.42682492733\n",
      "Epoch: 533,Discriminator Loss: 0.534969866276, Generator Loss: 0.151474133134\n",
      "Epoch: 534,Discriminator Loss: -0.633959770203, Generator Loss: 7.76950120926\n",
      "Epoch: 535,Discriminator Loss: 0.227290958166, Generator Loss: 0.0147038549185\n",
      "Epoch: 536,Discriminator Loss: 0.708556354046, Generator Loss: 0.000977059360594\n",
      "Epoch: 537,Discriminator Loss: -0.387900829315, Generator Loss: 8.15682506561\n",
      "Epoch: 538,Discriminator Loss: 0.177709117532, Generator Loss: 0.130128622055\n",
      "Epoch: 539,Discriminator Loss: 0.352073192596, Generator Loss: 0.0563066937029\n",
      "Epoch: 540,Discriminator Loss: -0.41950315237, Generator Loss: 9.17831420898\n",
      "Epoch: 541,Discriminator Loss: 1.83743333817, Generator Loss: 0.159379929304\n",
      "Epoch: 542,Discriminator Loss: 1.42624902725, Generator Loss: 0.260356158018\n",
      "Epoch: 543,Discriminator Loss: 0.196172043681, Generator Loss: 0.000590452109464\n",
      "Epoch: 544,Discriminator Loss: -0.331209242344, Generator Loss: 5.62537908554\n",
      "Epoch: 545,Discriminator Loss: -0.014595001936, Generator Loss: 0.053760021925\n",
      "Epoch: 546,Discriminator Loss: 0.050797984004, Generator Loss: 0.0152999637648\n",
      "Epoch: 547,Discriminator Loss: 0.0205229241401, Generator Loss: 9.17944453249e-06\n",
      "Epoch: 548,Discriminator Loss: 0.317145913839, Generator Loss: 4.77872467041\n",
      "Epoch: 549,Discriminator Loss: 0.850216984749, Generator Loss: 0.139388173819\n",
      "Epoch: 550,Discriminator Loss: 0.80473780632, Generator Loss: 0.0616953261197\n",
      "Epoch: 551,Discriminator Loss: 1.53040313721, Generator Loss: 4.45323181152\n",
      "Epoch: 552,Discriminator Loss: 2.49370837212, Generator Loss: 0.0128429373726\n",
      "Epoch: 553,Discriminator Loss: 5.45347499847, Generator Loss: 6.99860247551e-05\n",
      "Epoch: 554,Discriminator Loss: 1.4290368557, Generator Loss: 0.00571787822992\n",
      "Epoch: 555,Discriminator Loss: -0.136360704899, Generator Loss: 0.171913892031\n",
      "Epoch: 556,Discriminator Loss: 0.109832316637, Generator Loss: 10.1636009216\n",
      "Epoch: 557,Discriminator Loss: 0.530532240868, Generator Loss: 0.00219288258813\n",
      "Epoch: 558,Discriminator Loss: 0.14522716403, Generator Loss: 0.401545226574\n",
      "Epoch: 559,Discriminator Loss: 0.465415775776, Generator Loss: 0.552854895592\n",
      "Epoch: 560,Discriminator Loss: 0.49846804142, Generator Loss: 0.00226570363156\n",
      "Epoch: 561,Discriminator Loss: 0.33661210537, Generator Loss: 0.0203252993524\n",
      "Epoch: 562,Discriminator Loss: 1.95176720619, Generator Loss: 3.09754614136e-05\n",
      "Epoch: 563,Discriminator Loss: 0.365204334259, Generator Loss: 0.528379380703\n",
      "Epoch: 564,Discriminator Loss: -0.605650305748, Generator Loss: 10.0678787231\n",
      "Epoch: 565,Discriminator Loss: 0.220492988825, Generator Loss: 0.000503585266415\n",
      "Epoch: 566,Discriminator Loss: -0.643970251083, Generator Loss: 4.36912584305\n",
      "Epoch: 567,Discriminator Loss: 0.11956910044, Generator Loss: 0.0148998470977\n",
      "Epoch: 568,Discriminator Loss: 0.592734098434, Generator Loss: 3.57671451569\n",
      "Epoch: 569,Discriminator Loss: -0.172030940652, Generator Loss: 11.512925148\n",
      "Epoch: 570,Discriminator Loss: -0.423929989338, Generator Loss: 1.26695632935\n",
      "Epoch: 571,Discriminator Loss: -0.352844059467, Generator Loss: 0.68294698\n",
      "Epoch: 572,Discriminator Loss: -0.847512483597, Generator Loss: 11.512925148\n",
      "Epoch: 573,Discriminator Loss: 0.0545994564891, Generator Loss: 0.0114791896194\n",
      "Epoch: 574,Discriminator Loss: -0.796556949615, Generator Loss: 5.67834568024\n",
      "Epoch: 575,Discriminator Loss: 3.22520494461, Generator Loss: 0.00521106272936\n",
      "Epoch: 576,Discriminator Loss: 0.521023988724, Generator Loss: 0.161712676287\n",
      "Epoch: 577,Discriminator Loss: 0.283308804035, Generator Loss: 0.00216905446723\n",
      "Epoch: 578,Discriminator Loss: 0.00289096683264, Generator Loss: 5.31007671356\n",
      "Epoch: 579,Discriminator Loss: 0.374723017216, Generator Loss: 1.19209346394e-07\n",
      "Epoch: 580,Discriminator Loss: -0.107866153121, Generator Loss: 0.305633664131\n",
      "Epoch: 581,Discriminator Loss: -0.317167192698, Generator Loss: 4.56698656082\n",
      "Epoch: 582,Discriminator Loss: -0.513888120651, Generator Loss: 1.44460463524\n",
      "Epoch: 583,Discriminator Loss: 3.44989490509, Generator Loss: 4.16729736328\n",
      "Epoch: 584,Discriminator Loss: -0.237366780639, Generator Loss: 4.12696027756\n",
      "Epoch: 585,Discriminator Loss: 0.910091638565, Generator Loss: 0.453614592552\n",
      "Epoch: 586,Discriminator Loss: 3.14232325554, Generator Loss: 6.03692770004\n",
      "Epoch: 587,Discriminator Loss: -0.312649309635, Generator Loss: 0.683339357376\n",
      "Epoch: 588,Discriminator Loss: 3.45724987984, Generator Loss: 0.000147519647726\n",
      "Epoch: 589,Discriminator Loss: -0.145165652037, Generator Loss: 0.718119084835\n",
      "Epoch: 590,Discriminator Loss: -0.607728660107, Generator Loss: 3.06571769714\n",
      "Epoch: 591,Discriminator Loss: 0.402375251055, Generator Loss: 0.0729968175292\n",
      "Epoch: 592,Discriminator Loss: 0.508640408516, Generator Loss: 11.512925148\n",
      "Epoch: 593,Discriminator Loss: -0.40412440896, Generator Loss: 4.63931894302\n",
      "Epoch: 594,Discriminator Loss: 0.335024237633, Generator Loss: 0.108960025012\n",
      "Epoch: 595,Discriminator Loss: 0.660515606403, Generator Loss: 0.272591650486\n",
      "Epoch: 596,Discriminator Loss: 2.78821897507, Generator Loss: 0.86151611805\n",
      "Epoch: 597,Discriminator Loss: 0.15051369369, Generator Loss: 8.94069742685e-08\n",
      "Epoch: 598,Discriminator Loss: 0.506018102169, Generator Loss: 0.680977165699\n",
      "Epoch: 599,Discriminator Loss: 0.564834952354, Generator Loss: 0.0653046965599\n",
      "Epoch: 600,Discriminator Loss: 2.29323172569, Generator Loss: 0.686817228794\n",
      "Epoch: 601,Discriminator Loss: 0.131887286901, Generator Loss: 0.869817197323\n",
      "Epoch: 602,Discriminator Loss: 0.314447700977, Generator Loss: 0.0633424967527\n",
      "Epoch: 603,Discriminator Loss: -0.968786358833, Generator Loss: 10.1525201797\n",
      "Epoch: 604,Discriminator Loss: -0.137848645449, Generator Loss: 4.435338974\n",
      "Epoch: 605,Discriminator Loss: 1.01274037361, Generator Loss: 0.0\n",
      "Epoch: 606,Discriminator Loss: 1.24904632568, Generator Loss: 0.00174330442678\n",
      "Epoch: 607,Discriminator Loss: 0.904747486115, Generator Loss: 5.95180702209\n",
      "Epoch: 608,Discriminator Loss: 0.786374568939, Generator Loss: 0.00361014250666\n",
      "Epoch: 609,Discriminator Loss: 0.166798859835, Generator Loss: 4.3885602951\n",
      "Epoch: 610,Discriminator Loss: -0.491228699684, Generator Loss: 4.94731903076\n",
      "Epoch: 611,Discriminator Loss: 0.144507229328, Generator Loss: 0.121086880565\n",
      "Epoch: 612,Discriminator Loss: 0.38180077076, Generator Loss: 11.512925148\n",
      "Epoch: 613,Discriminator Loss: 0.213967621326, Generator Loss: 0.00154564448167\n",
      "Epoch: 614,Discriminator Loss: -0.0626292675734, Generator Loss: 0.223242253065\n",
      "Epoch: 615,Discriminator Loss: 1.08261907101, Generator Loss: 1.49011611938e-08\n",
      "Epoch: 616,Discriminator Loss: 2.36836338043, Generator Loss: 0.0199783649296\n",
      "Epoch: 617,Discriminator Loss: 2.28214907646, Generator Loss: 0.124796643853\n",
      "Epoch: 618,Discriminator Loss: 1.93364202976, Generator Loss: 0.2186563164\n",
      "Epoch: 619,Discriminator Loss: 0.656887471676, Generator Loss: 0.00974473822862\n",
      "Epoch: 620,Discriminator Loss: 0.828536987305, Generator Loss: 0.232730686665\n",
      "Epoch: 621,Discriminator Loss: -0.470547795296, Generator Loss: 11.512925148\n",
      "Epoch: 622,Discriminator Loss: 0.508161485195, Generator Loss: 0.0717898756266\n",
      "Epoch: 623,Discriminator Loss: 0.439321398735, Generator Loss: 2.53319967669e-07\n",
      "Epoch: 624,Discriminator Loss: -0.0800319612026, Generator Loss: 4.94740247726\n",
      "Epoch: 625,Discriminator Loss: 0.00742327421904, Generator Loss: 0.146105468273\n",
      "Epoch: 626,Discriminator Loss: 1.56640219688, Generator Loss: 0.203174650669\n",
      "Epoch: 627,Discriminator Loss: 0.778532147408, Generator Loss: 0.306142747402\n",
      "Epoch: 628,Discriminator Loss: -0.02863362059, Generator Loss: 0.120500668883\n",
      "Epoch: 629,Discriminator Loss: 0.142015308142, Generator Loss: 0.00127724220511\n",
      "Epoch: 630,Discriminator Loss: -0.0344171710312, Generator Loss: 0.0499949455261\n",
      "Epoch: 631,Discriminator Loss: 4.74546718597, Generator Loss: 0.0158101674169\n",
      "Epoch: 632,Discriminator Loss: 0.308579385281, Generator Loss: 0.0317481830716\n",
      "Epoch: 633,Discriminator Loss: -0.764055252075, Generator Loss: 3.23089742661\n",
      "Epoch: 634,Discriminator Loss: -0.924872875214, Generator Loss: 9.94515609741\n",
      "Epoch: 635,Discriminator Loss: -0.282488644123, Generator Loss: 1.31659197807\n",
      "Epoch: 636,Discriminator Loss: 0.357127964497, Generator Loss: 0.188834369183\n",
      "Epoch: 637,Discriminator Loss: 0.447998940945, Generator Loss: 0.000171690815478\n",
      "Epoch: 638,Discriminator Loss: 1.38755118847, Generator Loss: 6.05031490326\n",
      "Epoch: 639,Discriminator Loss: 2.55577945709, Generator Loss: 0.00810545682907\n",
      "Epoch: 640,Discriminator Loss: 0.193876758218, Generator Loss: 0.242828160524\n",
      "Epoch: 641,Discriminator Loss: 0.04491552338, Generator Loss: 0.551723718643\n",
      "Epoch: 642,Discriminator Loss: 0.171249300241, Generator Loss: 0.0128759359941\n",
      "Epoch: 643,Discriminator Loss: 0.645623683929, Generator Loss: 0.000706044316757\n",
      "Epoch: 644,Discriminator Loss: -0.634537816048, Generator Loss: 10.6429843903\n",
      "Epoch: 645,Discriminator Loss: 0.222692489624, Generator Loss: 4.49920749664\n",
      "Epoch: 646,Discriminator Loss: -0.0309068076313, Generator Loss: 0.115512177348\n",
      "Epoch: 647,Discriminator Loss: -0.571150898933, Generator Loss: 9.01086997986\n",
      "Epoch: 648,Discriminator Loss: 2.14055109024, Generator Loss: 0.154600173235\n",
      "Epoch: 649,Discriminator Loss: 1.01870250702, Generator Loss: 0.0298261940479\n",
      "Epoch: 650,Discriminator Loss: 0.257453471422, Generator Loss: 0.273761689663\n",
      "Epoch: 651,Discriminator Loss: 0.0912015289068, Generator Loss: 0.206358522177\n",
      "Epoch: 652,Discriminator Loss: 3.5222029686, Generator Loss: 0.101987197995\n",
      "Epoch: 653,Discriminator Loss: 0.0125540606678, Generator Loss: 0.0869450867176\n",
      "Epoch: 654,Discriminator Loss: -0.374042868614, Generator Loss: 4.41628313065\n",
      "Epoch: 655,Discriminator Loss: 0.411211103201, Generator Loss: 0.0545750036836\n",
      "Epoch: 656,Discriminator Loss: 0.497192978859, Generator Loss: 0.000322346721077\n",
      "Epoch: 657,Discriminator Loss: -0.371587455273, Generator Loss: 0.686838984489\n",
      "Epoch: 658,Discriminator Loss: 2.08304023743, Generator Loss: 9.85244941711\n",
      "Epoch: 659,Discriminator Loss: -0.0741733461618, Generator Loss: 0.200263619423\n",
      "Epoch: 660,Discriminator Loss: 2.21365666389, Generator Loss: 0.0273513421416\n",
      "Epoch: 661,Discriminator Loss: 0.427782446146, Generator Loss: 0.0103738354519\n",
      "Epoch: 662,Discriminator Loss: 0.0284413658082, Generator Loss: 0.0888428837061\n",
      "Epoch: 663,Discriminator Loss: 0.673503637314, Generator Loss: 0.0110745895654\n",
      "Epoch: 664,Discriminator Loss: 1.7398352623, Generator Loss: 4.57911205292\n",
      "Epoch: 665,Discriminator Loss: 2.06676077843, Generator Loss: 0.295089513063\n",
      "Epoch: 666,Discriminator Loss: 3.04224491119, Generator Loss: 0.363119125366\n",
      "Epoch: 667,Discriminator Loss: -0.715901494026, Generator Loss: 4.32055044174\n",
      "Epoch: 668,Discriminator Loss: 4.08866500854, Generator Loss: 0.000199150905246\n",
      "Epoch: 669,Discriminator Loss: -0.111052751541, Generator Loss: 4.4956278801\n",
      "Epoch: 670,Discriminator Loss: 0.607417106628, Generator Loss: 0.223369941115\n",
      "Epoch: 671,Discriminator Loss: -0.0191270764917, Generator Loss: 0.338304251432\n",
      "Epoch: 672,Discriminator Loss: 0.850315690041, Generator Loss: 0.0279350355268\n",
      "Epoch: 673,Discriminator Loss: 0.497074902058, Generator Loss: 0.196193128824\n",
      "Epoch: 674,Discriminator Loss: 0.0396733358502, Generator Loss: 0.0410533547401\n",
      "Epoch: 675,Discriminator Loss: 0.0304896831512, Generator Loss: 0.0335211269557\n",
      "Epoch: 676,Discriminator Loss: 0.449938684702, Generator Loss: 0.282744437456\n",
      "Epoch: 677,Discriminator Loss: 0.225146234035, Generator Loss: 0.0839353427291\n",
      "Epoch: 678,Discriminator Loss: 0.40626180172, Generator Loss: 4.68616199493\n",
      "Epoch: 679,Discriminator Loss: 1.49286353588, Generator Loss: 0.143483668566\n",
      "Epoch: 680,Discriminator Loss: 2.2313978672, Generator Loss: 0.152456969023\n",
      "Epoch: 681,Discriminator Loss: 0.285409927368, Generator Loss: 0.000214459112613\n",
      "Epoch: 682,Discriminator Loss: -0.304592251778, Generator Loss: 0.67005854845\n",
      "Epoch: 683,Discriminator Loss: 0.189564347267, Generator Loss: 0.087421387434\n",
      "Epoch: 684,Discriminator Loss: -0.498541146517, Generator Loss: 0.868586242199\n",
      "Epoch: 685,Discriminator Loss: 0.0463350079954, Generator Loss: 0.363856554031\n",
      "Epoch: 686,Discriminator Loss: 0.5159984231, Generator Loss: 5.75736188889\n",
      "Epoch: 687,Discriminator Loss: 0.28855162859, Generator Loss: 0.195423573256\n",
      "Epoch: 688,Discriminator Loss: -0.401562154293, Generator Loss: 10.7683811188\n",
      "Epoch: 689,Discriminator Loss: 0.370132267475, Generator Loss: 0.0339302495122\n",
      "Epoch: 690,Discriminator Loss: -0.0217425711453, Generator Loss: 0.279910027981\n",
      "Epoch: 691,Discriminator Loss: 0.46377325058, Generator Loss: 0.0167101044208\n",
      "Epoch: 692,Discriminator Loss: 1.3801510334, Generator Loss: 0.00942893698812\n",
      "Epoch: 693,Discriminator Loss: 4.67494487762, Generator Loss: 0.0541662499309\n",
      "Epoch: 694,Discriminator Loss: 0.387353718281, Generator Loss: 0.0178205184639\n",
      "Epoch: 695,Discriminator Loss: 0.340711593628, Generator Loss: 0.0418270900846\n",
      "Epoch: 696,Discriminator Loss: -0.414035916328, Generator Loss: 4.81022405624\n",
      "Epoch: 697,Discriminator Loss: 1.12018847466, Generator Loss: 0.23703455925\n",
      "Epoch: 698,Discriminator Loss: 1.20023703575, Generator Loss: 0.0640986412764\n",
      "Epoch: 699,Discriminator Loss: 0.230045974255, Generator Loss: 1.88662943401e-05\n",
      "Epoch: 700,Discriminator Loss: 0.176911234856, Generator Loss: 0.0624210499227\n",
      "Epoch: 701,Discriminator Loss: 0.87089908123, Generator Loss: 0.0285769794136\n",
      "Epoch: 702,Discriminator Loss: 0.425090193748, Generator Loss: 0.680862009525\n",
      "Epoch: 703,Discriminator Loss: 0.72638553381, Generator Loss: 3.56899472536e-05\n",
      "Epoch: 704,Discriminator Loss: 1.40807080269, Generator Loss: 0.300026237965\n",
      "Epoch: 705,Discriminator Loss: -0.135448768735, Generator Loss: 4.19521903992\n",
      "Epoch: 706,Discriminator Loss: 0.388953208923, Generator Loss: 0.101528972387\n",
      "Epoch: 707,Discriminator Loss: 0.33302089572, Generator Loss: 0.0229268502444\n",
      "Epoch: 708,Discriminator Loss: 0.599481463432, Generator Loss: 0.427971720695\n",
      "Epoch: 709,Discriminator Loss: 0.705704689026, Generator Loss: 0.00820185150951\n",
      "Epoch: 710,Discriminator Loss: 0.794785261154, Generator Loss: 0.00183821818791\n",
      "Epoch: 711,Discriminator Loss: 0.400364816189, Generator Loss: 10.3483228683\n",
      "Epoch: 712,Discriminator Loss: 0.148161590099, Generator Loss: 0.0155360884964\n",
      "Epoch: 713,Discriminator Loss: 3.62283277512, Generator Loss: 0.0996491834521\n",
      "Epoch: 714,Discriminator Loss: -0.873548984528, Generator Loss: 11.512925148\n",
      "Epoch: 715,Discriminator Loss: 0.559880852699, Generator Loss: 0.114583924413\n",
      "Epoch: 716,Discriminator Loss: -0.216424867511, Generator Loss: 0.686838984489\n",
      "Epoch: 717,Discriminator Loss: 0.537155210972, Generator Loss: 0.0089489556849\n",
      "Epoch: 718,Discriminator Loss: 0.00700005888939, Generator Loss: 0.11522398144\n",
      "Epoch: 719,Discriminator Loss: 0.583488702774, Generator Loss: 0.0400516837835\n",
      "Epoch: 720,Discriminator Loss: -0.526361227036, Generator Loss: 4.6958527565\n",
      "Epoch: 721,Discriminator Loss: -0.180726155639, Generator Loss: 0.33438077569\n",
      "Epoch: 722,Discriminator Loss: -0.586867570877, Generator Loss: 11.512925148\n",
      "Epoch: 723,Discriminator Loss: 0.975070357323, Generator Loss: 0.116594597697\n",
      "Epoch: 724,Discriminator Loss: -0.27495315671, Generator Loss: 3.24103140831\n",
      "Epoch: 725,Discriminator Loss: 0.287652432919, Generator Loss: 0.116522267461\n",
      "Epoch: 726,Discriminator Loss: -0.189620614052, Generator Loss: 4.74567270279\n",
      "Epoch: 727,Discriminator Loss: 1.51165699959, Generator Loss: 0.000193153391592\n",
      "Epoch: 728,Discriminator Loss: -0.202508270741, Generator Loss: 0.320290148258\n",
      "Epoch: 729,Discriminator Loss: 3.33523035049, Generator Loss: 0.0601751767099\n",
      "Epoch: 730,Discriminator Loss: -0.083374120295, Generator Loss: 6.33721160889\n",
      "Epoch: 731,Discriminator Loss: 0.358427941799, Generator Loss: 0.0339227691293\n",
      "Epoch: 732,Discriminator Loss: 0.263504803181, Generator Loss: 0.198768436909\n",
      "Epoch: 733,Discriminator Loss: -0.00553165376186, Generator Loss: 4.76610088348\n",
      "Epoch: 734,Discriminator Loss: 0.391248136759, Generator Loss: 0.0306270308793\n",
      "Epoch: 735,Discriminator Loss: 0.483806341887, Generator Loss: 7.49702072144\n",
      "Epoch: 736,Discriminator Loss: -0.384321659803, Generator Loss: 0.646550655365\n",
      "Epoch: 737,Discriminator Loss: -0.756347954273, Generator Loss: 2.53947257996\n",
      "Epoch: 738,Discriminator Loss: 0.650744080544, Generator Loss: 0.00209482712671\n",
      "Epoch: 739,Discriminator Loss: 0.0267730113119, Generator Loss: 0.00328355305828\n",
      "Epoch: 740,Discriminator Loss: -0.893447101116, Generator Loss: 11.512925148\n",
      "Epoch: 741,Discriminator Loss: 0.104091882706, Generator Loss: 0.00291367643513\n",
      "Epoch: 742,Discriminator Loss: -0.189834207296, Generator Loss: 0.647711157799\n",
      "Epoch: 743,Discriminator Loss: 0.499636292458, Generator Loss: 0.0805775672197\n",
      "Epoch: 744,Discriminator Loss: 0.498226881027, Generator Loss: 0.0259341243654\n",
      "Epoch: 745,Discriminator Loss: -0.961212515831, Generator Loss: 11.512925148\n",
      "Epoch: 746,Discriminator Loss: 0.105349175632, Generator Loss: 1.21458864212\n",
      "Epoch: 747,Discriminator Loss: 2.18024992943, Generator Loss: 0.00773151172325\n",
      "Epoch: 748,Discriminator Loss: 0.188581138849, Generator Loss: 0.207297116518\n",
      "Epoch: 749,Discriminator Loss: -0.495638102293, Generator Loss: 10.1652297974\n",
      "Epoch: 750,Discriminator Loss: -0.0775412470102, Generator Loss: 0.213345244527\n",
      "Epoch: 751,Discriminator Loss: -0.668432414532, Generator Loss: 5.20353794098\n",
      "Epoch: 752,Discriminator Loss: 0.062703281641, Generator Loss: 0.00872201658785\n",
      "Epoch: 753,Discriminator Loss: 1.37400341034, Generator Loss: 0.430761426687\n",
      "Epoch: 754,Discriminator Loss: 0.309286266565, Generator Loss: 0.0263230316341\n",
      "Epoch: 755,Discriminator Loss: 0.735411524773, Generator Loss: 0.000458029971924\n",
      "Epoch: 756,Discriminator Loss: 0.328130453825, Generator Loss: 5.31982232133e-06\n",
      "Epoch: 757,Discriminator Loss: -0.371413946152, Generator Loss: 4.27179145813\n",
      "Epoch: 758,Discriminator Loss: 0.378003746271, Generator Loss: 0.000500327441841\n",
      "Epoch: 759,Discriminator Loss: 0.089689552784, Generator Loss: 0.0417612791061\n",
      "Epoch: 760,Discriminator Loss: 0.299541205168, Generator Loss: 0.0789649561048\n",
      "Epoch: 761,Discriminator Loss: 1.04476070404, Generator Loss: 0.316963851452\n",
      "Epoch: 762,Discriminator Loss: 0.650246441364, Generator Loss: 0.0210849512368\n",
      "Epoch: 763,Discriminator Loss: 0.815696299076, Generator Loss: 0.181628361344\n",
      "Epoch: 764,Discriminator Loss: -0.349771916866, Generator Loss: 9.33493804932\n",
      "Epoch: 765,Discriminator Loss: -0.25783675909, Generator Loss: 0.821886897087\n",
      "Epoch: 766,Discriminator Loss: 0.186799734831, Generator Loss: 0.00396109325811\n",
      "Epoch: 767,Discriminator Loss: 3.82500362396, Generator Loss: 0.000243015005253\n",
      "Epoch: 768,Discriminator Loss: 0.482605338097, Generator Loss: 0.0136694703251\n",
      "Epoch: 769,Discriminator Loss: -0.701830029488, Generator Loss: 6.16415309906\n",
      "Epoch: 770,Discriminator Loss: -0.799206256866, Generator Loss: 11.512925148\n",
      "Epoch: 771,Discriminator Loss: 0.728779911995, Generator Loss: 2.68319363386e-05\n",
      "Epoch: 772,Discriminator Loss: 0.284990102053, Generator Loss: 0.00378298363648\n",
      "Epoch: 773,Discriminator Loss: 2.38499593735, Generator Loss: 6.35585165583e-05\n",
      "Epoch: 774,Discriminator Loss: -0.218176200986, Generator Loss: 0.478554457426\n",
      "Epoch: 775,Discriminator Loss: 0.449731111526, Generator Loss: 0.0734420120716\n",
      "Epoch: 776,Discriminator Loss: 0.152900099754, Generator Loss: 0.0839100256562\n",
      "Epoch: 777,Discriminator Loss: 2.03959751129, Generator Loss: 0.00135906937066\n",
      "Epoch: 778,Discriminator Loss: -0.517034590244, Generator Loss: 6.16711521149\n",
      "Epoch: 779,Discriminator Loss: 0.160322770476, Generator Loss: 0.0785753577948\n",
      "Epoch: 780,Discriminator Loss: 0.273962646723, Generator Loss: 0.674885988235\n",
      "Epoch: 781,Discriminator Loss: 0.452444583178, Generator Loss: 0.00451044319198\n",
      "Epoch: 782,Discriminator Loss: 0.919371545315, Generator Loss: 0.0352206341922\n",
      "Epoch: 783,Discriminator Loss: 0.571064829826, Generator Loss: 0.00986986421049\n",
      "Epoch: 784,Discriminator Loss: 0.331021010876, Generator Loss: 0.290788888931\n",
      "Epoch: 785,Discriminator Loss: 1.02055597305, Generator Loss: 0.0669931620359\n",
      "Epoch: 786,Discriminator Loss: 0.689241111279, Generator Loss: 0.543391168118\n",
      "Epoch: 787,Discriminator Loss: 0.208365157247, Generator Loss: 0.201113253832\n",
      "Epoch: 788,Discriminator Loss: 0.778370380402, Generator Loss: 0.237579584122\n",
      "Epoch: 789,Discriminator Loss: 0.440578013659, Generator Loss: 0.00140887056477\n",
      "Epoch: 790,Discriminator Loss: 0.743120670319, Generator Loss: 0.159341841936\n",
      "Epoch: 791,Discriminator Loss: 1.70757472515, Generator Loss: 7.95602609287e-05\n",
      "Epoch: 792,Discriminator Loss: 0.103523090482, Generator Loss: 0.0187960863113\n",
      "Epoch: 793,Discriminator Loss: 0.0718648135662, Generator Loss: 0.12014336884\n",
      "Epoch: 794,Discriminator Loss: 0.287319719791, Generator Loss: 0.180330336094\n",
      "Epoch: 795,Discriminator Loss: -0.110880896449, Generator Loss: 0.616514921188\n",
      "Epoch: 796,Discriminator Loss: 0.360711425543, Generator Loss: 0.0562227889895\n",
      "Epoch: 797,Discriminator Loss: 0.186272621155, Generator Loss: 0.0961909592152\n",
      "Epoch: 798,Discriminator Loss: -0.00469056563452, Generator Loss: 0.01449141372\n",
      "Epoch: 799,Discriminator Loss: -0.26632630825, Generator Loss: 10.7841300964\n",
      "Epoch: 800,Discriminator Loss: 0.364373385906, Generator Loss: 0.0788221657276\n",
      "Epoch: 801,Discriminator Loss: -0.0601514428854, Generator Loss: 0.16950379312\n",
      "Epoch: 802,Discriminator Loss: 4.20283794403, Generator Loss: 0.15245193243\n",
      "Epoch: 803,Discriminator Loss: 0.236311241984, Generator Loss: 0.0654862672091\n",
      "Epoch: 804,Discriminator Loss: -0.232106626034, Generator Loss: 6.69321250916\n",
      "Epoch: 805,Discriminator Loss: 1.1297249794, Generator Loss: 0.00409289589152\n",
      "Epoch: 806,Discriminator Loss: 6.65325832367, Generator Loss: 0.00016946606047\n",
      "Epoch: 807,Discriminator Loss: 0.225239992142, Generator Loss: 0.043252825737\n",
      "Epoch: 808,Discriminator Loss: 0.0547239072621, Generator Loss: 0.00145409035031\n",
      "Epoch: 809,Discriminator Loss: -0.166200727224, Generator Loss: 0.327836215496\n",
      "Epoch: 810,Discriminator Loss: 0.316574037075, Generator Loss: 0.152786612511\n",
      "Epoch: 811,Discriminator Loss: 0.383902490139, Generator Loss: 0.238257721066\n",
      "Epoch: 812,Discriminator Loss: 0.245773553848, Generator Loss: 0.0314251706004\n",
      "Epoch: 813,Discriminator Loss: 0.254508405924, Generator Loss: 0.00290750944987\n",
      "Epoch: 814,Discriminator Loss: 1.07535171509, Generator Loss: 0.0366849415004\n",
      "Epoch: 815,Discriminator Loss: -0.827004373074, Generator Loss: 11.512925148\n",
      "Epoch: 816,Discriminator Loss: 0.602378845215, Generator Loss: 0.0576191209257\n",
      "Epoch: 817,Discriminator Loss: 0.244491800666, Generator Loss: 0.0638328567147\n",
      "Epoch: 818,Discriminator Loss: -0.13324084878, Generator Loss: 7.80980873108\n",
      "Epoch: 819,Discriminator Loss: -0.816504836082, Generator Loss: 9.08269405365\n",
      "Epoch: 820,Discriminator Loss: 1.41552257538, Generator Loss: 0.0257847979665\n",
      "Epoch: 821,Discriminator Loss: -0.0642514899373, Generator Loss: 0.299509942532\n",
      "Epoch: 822,Discriminator Loss: 3.69608473778, Generator Loss: 0.280108749866\n",
      "Epoch: 823,Discriminator Loss: 0.193334802985, Generator Loss: 0.502996683121\n",
      "Epoch: 824,Discriminator Loss: -0.190094172955, Generator Loss: 8.47563552856\n",
      "Epoch: 825,Discriminator Loss: 3.73578023911, Generator Loss: 0.105966337025\n",
      "Epoch: 826,Discriminator Loss: -0.858908295631, Generator Loss: 10.2203655243\n",
      "Epoch: 827,Discriminator Loss: -0.394848197699, Generator Loss: 0.664851903915\n",
      "Epoch: 828,Discriminator Loss: 2.63496041298, Generator Loss: 0.0773877501488\n",
      "Epoch: 829,Discriminator Loss: 3.39137148857, Generator Loss: 0.0142994727939\n",
      "Epoch: 830,Discriminator Loss: -0.646250486374, Generator Loss: 5.34673881531\n",
      "Epoch: 831,Discriminator Loss: -0.37264841795, Generator Loss: 0.776936590672\n",
      "Epoch: 832,Discriminator Loss: 0.264560163021, Generator Loss: 11.512925148\n",
      "Epoch: 833,Discriminator Loss: 0.71719622612, Generator Loss: 0.012436799705\n",
      "Epoch: 834,Discriminator Loss: -0.186787560582, Generator Loss: 5.44052600861\n",
      "Epoch: 835,Discriminator Loss: -0.0593358129263, Generator Loss: 10.6049499512\n",
      "Epoch: 836,Discriminator Loss: 0.657207250595, Generator Loss: 11.512925148\n",
      "Epoch: 837,Discriminator Loss: 0.370997309685, Generator Loss: 0.026681592688\n",
      "Epoch: 838,Discriminator Loss: 0.249490588903, Generator Loss: 8.64378929138\n",
      "Epoch: 839,Discriminator Loss: -0.158904120326, Generator Loss: 0.552086293697\n",
      "Epoch: 840,Discriminator Loss: 0.383687585592, Generator Loss: 0.0243474841118\n",
      "Epoch: 841,Discriminator Loss: -0.471366167068, Generator Loss: 3.64007782936\n",
      "Epoch: 842,Discriminator Loss: -0.025725223124, Generator Loss: 3.48893618584\n",
      "Epoch: 843,Discriminator Loss: 0.301911979914, Generator Loss: 0.175163060427\n",
      "Epoch: 844,Discriminator Loss: 0.419514745474, Generator Loss: 0.0547799095511\n",
      "Epoch: 845,Discriminator Loss: -0.0839928239584, Generator Loss: 0.557836949825\n",
      "Epoch: 846,Discriminator Loss: -0.563179135323, Generator Loss: 11.512925148\n",
      "Epoch: 847,Discriminator Loss: 0.270948559046, Generator Loss: 0.252023130655\n",
      "Epoch: 848,Discriminator Loss: -0.826707243919, Generator Loss: 9.11440849304\n",
      "Epoch: 849,Discriminator Loss: -0.0417944863439, Generator Loss: 3.6239528656\n",
      "Epoch: 850,Discriminator Loss: -0.841809272766, Generator Loss: 11.512925148\n",
      "Epoch: 851,Discriminator Loss: 0.465490221977, Generator Loss: 0.000289556570351\n",
      "Epoch: 852,Discriminator Loss: 0.262509435415, Generator Loss: 0.137063607574\n",
      "Epoch: 853,Discriminator Loss: 0.765620052814, Generator Loss: 0.144823670387\n",
      "Epoch: 854,Discriminator Loss: 0.370178818703, Generator Loss: 0.686838984489\n",
      "Epoch: 855,Discriminator Loss: -0.421273857355, Generator Loss: 6.30776405334\n",
      "Epoch: 856,Discriminator Loss: -0.517951905727, Generator Loss: 2.33749675751\n",
      "Epoch: 857,Discriminator Loss: 0.131077706814, Generator Loss: 0.0443899929523\n",
      "Epoch: 858,Discriminator Loss: 0.0800305232406, Generator Loss: 0.163774251938\n",
      "Epoch: 859,Discriminator Loss: 0.649021744728, Generator Loss: 0.573048233986\n",
      "Epoch: 860,Discriminator Loss: 0.108807049692, Generator Loss: 0.221668332815\n",
      "Epoch: 861,Discriminator Loss: -0.530497014523, Generator Loss: 6.21257305145\n",
      "Epoch: 862,Discriminator Loss: -0.810575485229, Generator Loss: 6.66986465454\n",
      "Epoch: 863,Discriminator Loss: -0.828205704689, Generator Loss: 7.69912719727\n",
      "Epoch: 864,Discriminator Loss: 0.147654294968, Generator Loss: 0.343994110823\n",
      "Epoch: 865,Discriminator Loss: 0.324064135551, Generator Loss: 0.00038850918645\n",
      "Epoch: 866,Discriminator Loss: -0.382114708424, Generator Loss: 1.13246428967\n",
      "Epoch: 867,Discriminator Loss: -0.443725407124, Generator Loss: 5.37438678741\n",
      "Epoch: 868,Discriminator Loss: 0.414129853249, Generator Loss: 0.0213371980935\n",
      "Epoch: 869,Discriminator Loss: 0.923392772675, Generator Loss: 0.474047899246\n",
      "Epoch: 870,Discriminator Loss: 0.505004525185, Generator Loss: 1.68798160553\n",
      "Epoch: 871,Discriminator Loss: 0.124226808548, Generator Loss: 0.173086047173\n",
      "Epoch: 872,Discriminator Loss: 0.0433118008077, Generator Loss: 0.467017918825\n",
      "Epoch: 873,Discriminator Loss: 0.0233148671687, Generator Loss: 0.179729223251\n",
      "Epoch: 874,Discriminator Loss: -0.374131202698, Generator Loss: 2.05724072456\n",
      "Epoch: 875,Discriminator Loss: -0.590622544289, Generator Loss: 11.512925148\n",
      "Epoch: 876,Discriminator Loss: -0.715841531754, Generator Loss: 10.5836849213\n",
      "Epoch: 877,Discriminator Loss: 0.00193357467651, Generator Loss: 5.16579627991\n",
      "Epoch: 878,Discriminator Loss: 0.195207834244, Generator Loss: 0.0421803183854\n",
      "Epoch: 879,Discriminator Loss: 0.397900044918, Generator Loss: 0.0498080775142\n",
      "Epoch: 880,Discriminator Loss: -0.119111269712, Generator Loss: 5.76389408112\n",
      "Epoch: 881,Discriminator Loss: 0.556183457375, Generator Loss: 0.335824668407\n",
      "Epoch: 882,Discriminator Loss: -0.336425632238, Generator Loss: 5.98136711121\n",
      "Epoch: 883,Discriminator Loss: 0.111064091325, Generator Loss: 6.05929136276\n",
      "Epoch: 884,Discriminator Loss: 0.365684270859, Generator Loss: 0.573257267475\n",
      "Epoch: 885,Discriminator Loss: 0.405185997486, Generator Loss: 0.0826804414392\n",
      "Epoch: 886,Discriminator Loss: 0.196368083358, Generator Loss: 0.648285448551\n",
      "Epoch: 887,Discriminator Loss: 0.603230953217, Generator Loss: 0.00256500206888\n",
      "Epoch: 888,Discriminator Loss: 0.159461438656, Generator Loss: 0.0192214287817\n",
      "Epoch: 889,Discriminator Loss: 0.539501368999, Generator Loss: 0.000166576559423\n",
      "Epoch: 890,Discriminator Loss: -0.627441644669, Generator Loss: 6.43329143524\n",
      "Epoch: 891,Discriminator Loss: 0.147134974599, Generator Loss: 9.80919212452e-05\n",
      "Epoch: 892,Discriminator Loss: 0.0763756781816, Generator Loss: 0.152023613453\n",
      "Epoch: 893,Discriminator Loss: 0.0980391576886, Generator Loss: 0.389456421137\n",
      "Epoch: 894,Discriminator Loss: 0.0669673383236, Generator Loss: 0.00285451184027\n",
      "Epoch: 895,Discriminator Loss: 0.880627274513, Generator Loss: 0.0434607416391\n",
      "Epoch: 896,Discriminator Loss: 0.406797170639, Generator Loss: 0.11072434485\n",
      "Epoch: 897,Discriminator Loss: 0.602762401104, Generator Loss: 0.0316871777177\n",
      "Epoch: 898,Discriminator Loss: 0.190999776125, Generator Loss: 0.32849919796\n",
      "Epoch: 899,Discriminator Loss: 0.456615418196, Generator Loss: 0.289652377367\n",
      "Epoch: 900,Discriminator Loss: 0.197254657745, Generator Loss: 0.00105916755274\n",
      "Epoch: 901,Discriminator Loss: 0.56283557415, Generator Loss: 0.0697890520096\n",
      "Epoch: 902,Discriminator Loss: -0.236478954554, Generator Loss: 0.782806396484\n",
      "Epoch: 903,Discriminator Loss: 0.393192946911, Generator Loss: 0.0954595655203\n",
      "Epoch: 904,Discriminator Loss: 0.188746243715, Generator Loss: 0.0342869050801\n",
      "Epoch: 905,Discriminator Loss: 0.628005743027, Generator Loss: 8.27001349535e-05\n",
      "Epoch: 906,Discriminator Loss: 0.367920547724, Generator Loss: 0.0795230939984\n",
      "Epoch: 907,Discriminator Loss: 0.122215732932, Generator Loss: 0.0721017643809\n",
      "Epoch: 908,Discriminator Loss: 0.759692430496, Generator Loss: 0.0850753337145\n",
      "Epoch: 909,Discriminator Loss: 0.842898547649, Generator Loss: 0.18928770721\n",
      "Epoch: 910,Discriminator Loss: 1.31427824497, Generator Loss: 0.11782053858\n",
      "Epoch: 911,Discriminator Loss: -0.224485382438, Generator Loss: 8.96507644653\n",
      "Epoch: 912,Discriminator Loss: 0.307803928852, Generator Loss: 0.00661792280152\n",
      "Epoch: 913,Discriminator Loss: 0.392305016518, Generator Loss: 0.0206317380071\n",
      "Epoch: 914,Discriminator Loss: 0.244653224945, Generator Loss: 1.91935614566e-05\n",
      "Epoch: 915,Discriminator Loss: 0.452091932297, Generator Loss: 0.0153888454661\n",
      "Epoch: 916,Discriminator Loss: -0.0870171040297, Generator Loss: 1.1462007761\n",
      "Epoch: 917,Discriminator Loss: 0.223084568977, Generator Loss: 0.0081031518057\n",
      "Epoch: 918,Discriminator Loss: 0.233191415668, Generator Loss: 0.0941268652678\n",
      "Epoch: 919,Discriminator Loss: -0.0846765711904, Generator Loss: 0.188170164824\n",
      "Epoch: 920,Discriminator Loss: 0.0267320424318, Generator Loss: 6.71451377869\n",
      "Epoch: 921,Discriminator Loss: 0.21312455833, Generator Loss: 0.287294715643\n",
      "Epoch: 922,Discriminator Loss: -0.159257873893, Generator Loss: 6.08098173141\n",
      "Epoch: 923,Discriminator Loss: 1.32655620575, Generator Loss: 0.00916307140142\n",
      "Epoch: 924,Discriminator Loss: 0.0302475076169, Generator Loss: 0.0421808101237\n",
      "Epoch: 925,Discriminator Loss: 1.03626489639, Generator Loss: 0.229940503836\n",
      "Epoch: 926,Discriminator Loss: -0.104816332459, Generator Loss: 6.00875663757\n",
      "Epoch: 927,Discriminator Loss: -0.119061402977, Generator Loss: 10.8348340988\n",
      "Epoch: 928,Discriminator Loss: 0.173208892345, Generator Loss: 1.34111166972e-06\n",
      "Epoch: 929,Discriminator Loss: -0.488494873047, Generator Loss: 5.76330375671\n",
      "Epoch: 930,Discriminator Loss: -0.345484167337, Generator Loss: 0.686838984489\n",
      "Epoch: 931,Discriminator Loss: 1.52486729622, Generator Loss: 0.0248380247504\n",
      "Epoch: 932,Discriminator Loss: -0.0406531244516, Generator Loss: 5.27639722824\n",
      "Epoch: 933,Discriminator Loss: 1.00101327896, Generator Loss: 5.05155821884e-06\n",
      "Epoch: 934,Discriminator Loss: -0.0863287448883, Generator Loss: 1.82836806774\n",
      "Epoch: 935,Discriminator Loss: 1.61860871315, Generator Loss: 9.94202613831\n",
      "Epoch: 936,Discriminator Loss: 0.580920159817, Generator Loss: 0.0659015774727\n",
      "Epoch: 937,Discriminator Loss: 0.438737213612, Generator Loss: 0.315637797117\n",
      "Epoch: 938,Discriminator Loss: 0.190035551786, Generator Loss: 0.157537400723\n",
      "Epoch: 939,Discriminator Loss: 0.617400944233, Generator Loss: 6.02100515366\n",
      "Epoch: 940,Discriminator Loss: 1.35669183731, Generator Loss: 0.490747749805\n",
      "Epoch: 941,Discriminator Loss: 0.164153039455, Generator Loss: 7.0334672273e-06\n",
      "Epoch: 942,Discriminator Loss: 0.177350565791, Generator Loss: 0.00505200074986\n",
      "Epoch: 943,Discriminator Loss: -0.434038937092, Generator Loss: 0.630459189415\n",
      "Epoch: 944,Discriminator Loss: 2.62879943848, Generator Loss: 11.512925148\n",
      "Epoch: 945,Discriminator Loss: 0.0216651260853, Generator Loss: 6.32598114014\n",
      "Epoch: 946,Discriminator Loss: 1.54915058613, Generator Loss: 0.705591082573\n",
      "Epoch: 947,Discriminator Loss: -0.171387672424, Generator Loss: 5.04551029205\n",
      "Epoch: 948,Discriminator Loss: 6.36944675446, Generator Loss: 1.68839907646\n",
      "Epoch: 949,Discriminator Loss: 0.565353751183, Generator Loss: 0.0775178894401\n",
      "Epoch: 950,Discriminator Loss: 0.37050807476, Generator Loss: 0.00934461317956\n",
      "Epoch: 951,Discriminator Loss: 0.347031414509, Generator Loss: 3.50347763742e-05\n",
      "Epoch: 952,Discriminator Loss: 0.18897254765, Generator Loss: 0.00373362679966\n",
      "Epoch: 953,Discriminator Loss: 0.183252871037, Generator Loss: 0.00266420422122\n",
      "Epoch: 954,Discriminator Loss: 1.16612195969, Generator Loss: 6.92849111557\n",
      "Epoch: 955,Discriminator Loss: 1.11764538288, Generator Loss: 0.0279144197702\n",
      "Epoch: 956,Discriminator Loss: 0.848670363426, Generator Loss: 3.57628380243e-07\n",
      "Epoch: 957,Discriminator Loss: -0.28181412816, Generator Loss: 0.966911911964\n",
      "Epoch: 958,Discriminator Loss: 0.58012008667, Generator Loss: 0.0135879712179\n",
      "Epoch: 959,Discriminator Loss: 0.139221832156, Generator Loss: 0.1309928298\n",
      "Epoch: 960,Discriminator Loss: 0.753193974495, Generator Loss: 0.0916647613049\n",
      "Epoch: 961,Discriminator Loss: 1.60329341888, Generator Loss: 9.28459739685\n",
      "Epoch: 962,Discriminator Loss: 0.431713759899, Generator Loss: 4.75134897232\n",
      "Epoch: 963,Discriminator Loss: -0.240363270044, Generator Loss: 0.686682641506\n",
      "Epoch: 964,Discriminator Loss: 3.83853507042, Generator Loss: 1.00894629955\n",
      "Epoch: 965,Discriminator Loss: -0.760938644409, Generator Loss: 7.43253040314\n",
      "Epoch: 966,Discriminator Loss: 0.235027879477, Generator Loss: 0.0\n",
      "Epoch: 967,Discriminator Loss: -0.271387934685, Generator Loss: 2.91525506973\n",
      "Epoch: 968,Discriminator Loss: 0.0567469187081, Generator Loss: 0.00849473662674\n",
      "Epoch: 969,Discriminator Loss: -0.913118243217, Generator Loss: 6.49866962433\n",
      "Epoch: 970,Discriminator Loss: -0.297259271145, Generator Loss: 2.56818890572\n",
      "Epoch: 971,Discriminator Loss: 0.352289110422, Generator Loss: 5.29925727844\n",
      "Epoch: 972,Discriminator Loss: -0.495901286602, Generator Loss: 0.832511007786\n",
      "Epoch: 973,Discriminator Loss: 2.13132953644, Generator Loss: 0.00499351834878\n",
      "Epoch: 974,Discriminator Loss: 0.675129413605, Generator Loss: 0.100551962852\n",
      "Epoch: 975,Discriminator Loss: -0.90173047781, Generator Loss: 8.57470321655\n",
      "Epoch: 976,Discriminator Loss: 0.0282318089157, Generator Loss: 0.0\n",
      "Epoch: 977,Discriminator Loss: 0.400458365679, Generator Loss: 0.0881901830435\n",
      "Epoch: 978,Discriminator Loss: -0.855842471123, Generator Loss: 11.512925148\n",
      "Epoch: 979,Discriminator Loss: 0.0795018970966, Generator Loss: 0.188958793879\n",
      "Epoch: 980,Discriminator Loss: 0.119000785053, Generator Loss: 0.0\n",
      "Epoch: 981,Discriminator Loss: 0.537053525448, Generator Loss: 0.0144504979253\n",
      "Epoch: 982,Discriminator Loss: -0.362316608429, Generator Loss: 2.10884690285\n",
      "Epoch: 983,Discriminator Loss: -0.490512549877, Generator Loss: 11.512925148\n",
      "Epoch: 984,Discriminator Loss: 0.0500854328275, Generator Loss: 0.758097231388\n",
      "Epoch: 985,Discriminator Loss: -0.138668850064, Generator Loss: 0.826910197735\n",
      "Epoch: 986,Discriminator Loss: -0.732630908489, Generator Loss: 10.2698640823\n",
      "Epoch: 987,Discriminator Loss: -0.235094204545, Generator Loss: 0.671402037144\n",
      "Epoch: 988,Discriminator Loss: 0.283121585846, Generator Loss: 0.00270742224529\n",
      "Epoch: 989,Discriminator Loss: -0.380680978298, Generator Loss: 5.70899868011\n",
      "Epoch: 990,Discriminator Loss: 0.550008714199, Generator Loss: 1.9596047423e-05\n",
      "Epoch: 991,Discriminator Loss: 0.389697104692, Generator Loss: 0.0489892736077\n",
      "Epoch: 992,Discriminator Loss: 1.65169978142, Generator Loss: 0.119784906507\n",
      "Epoch: 993,Discriminator Loss: -0.367805421352, Generator Loss: 0.613496899605\n",
      "Epoch: 994,Discriminator Loss: 0.0353000313044, Generator Loss: 3.83489727974\n",
      "Epoch: 995,Discriminator Loss: 0.0473011694849, Generator Loss: 0.107438877225\n",
      "Epoch: 996,Discriminator Loss: -0.164807349443, Generator Loss: 5.82863235474\n",
      "Epoch: 997,Discriminator Loss: -0.439758747816, Generator Loss: 9.33191490173\n",
      "Epoch: 998,Discriminator Loss: 0.136866509914, Generator Loss: 0.424317598343\n",
      "Epoch: 999,Discriminator Loss: 3.95931959152, Generator Loss: 2.08617143471e-06\n"
     ]
    }
   ],
   "source": [
    "optimize(epoch,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result():\n",
    "    real_data = pd.Series(gen_data_sample(1000).ravel())\n",
    "    generated_data = pd.Series( session.run(g_output,{x_g: gen_noise_sample(1000)}).ravel())\n",
    "    real_data.plot(kind = \"density\", label = \"real data\")\n",
    "    generated_data.plot(kind = \"density\", label = \"generated data\")\n",
    "    noise = pd.Series(gen_noise_sample(1000).ravel())\n",
    "    noise.plot(kind = \"density\", label = \"input noise\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6d4d650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
